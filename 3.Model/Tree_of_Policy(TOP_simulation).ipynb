{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### local ì‹¤í–‰ì‹œ : ì½”ë“œì™€ ê°™ì€ í´ë”ì— Github Featureí´ë”ì˜ ì‹œë®¬ë ˆì´ì…˜ìš©_ë³‘í•©ë°ì´í„°ì…‹_ìƒë°˜ê¸°.csv , ì‹œë®¬ë ˆì´ì…˜ìš©_ë³‘í•©ë°ì´í„°ì…‹_í•˜ë°˜ê¸°.csv ë¥¼ ë‘ê³  ì‹¤í–‰í•˜ê±°ë‚˜ ìƒëŒ€ê²½ë¡œë¥¼ ì ìš©í•´ì„œ path ìˆ˜ì • (ë§¨ ë°‘ mainí•¨ìˆ˜)í•´ì„œ ëŒë¦¬ë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "### colab ì‹¤í–‰ì‹œ : ì½”ë© ê¸°ë³¸ í´ë” (content)ì— ìƒê¸°í•œ ë‘ íŒŒì¼ì„ ë„£ê³  ì‹¤í–‰ ëŒë¦¬ë©´ ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "xFjfxnJkFe60"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYRaB52ME-mY",
        "outputId": "88595764-4ad0-428a-9166-2a8c6565d75d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ† ê³µëª¨ì „ ëª©í‘œ: ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì‹œë®¬ë ˆì´ì…˜ (ì™„ì „ ì•ˆì „ ë²„ì „)\n",
            "======================================================================\n",
            "\n",
            "ğŸ¯ **í•µì‹¬ ì°¨ë³„ì  (ê°•í™”ë²„ì „):**\n",
            "âœ… ì •ì±… ìœ íš¨ì„± ì‚¬ì „ ê²€ì¦: ë¬´ì§€ì„± ì •ì±… ì™„ì „ ì°¨ë‹¨\n",
            "âœ… ë¹„ì„ í˜• íŒ¨ë„í‹° ì‹œìŠ¤í…œ: ê·¹ë‹¨ì  ì •ì±…ì— ê¸°í•˜ê¸‰ìˆ˜ì  ê°ì \n",
            "âœ… ë°ì´í„° ì •ê·œí™”: ìƒë°˜ê¸°/í•˜ë°˜ê¸° ì¼ê´€ì„± í™•ë³´\n",
            "âœ… Tree of Thoughts + ì¡°ê¸° ì¤‘ë‹¨: íš¨ìœ¨ì  ìµœì í•´ íƒìƒ‰\n",
            "âœ… ì‹ ë¢°ë„ ê¸°ë°˜ ê²°ê³¼ ì¡°ì •: í˜„ì‹¤ì„± ë³´ì¥\n",
            "âœ… ì™„ì „ ì•ˆì „ ì²˜ë¦¬: ëª¨ë“  í‚¤ ì˜¤ë¥˜ ë°©ì§€\n",
            "\n",
            "ğŸ”§ **ì£¼ìš” ì•ˆì „ ê°œì„ ì‚¬í•­:**\n",
            "ğŸ” ëª¨ë“  ë”•ì…”ë„ˆë¦¬ í‚¤ ì ‘ê·¼ì„ .get() ë©”ì„œë“œë¡œ ì•ˆì „ ì²˜ë¦¬\n",
            "ğŸš« try-except ë¸”ë¡ìœ¼ë¡œ ëª¨ë“  í•¨ìˆ˜ ì•ˆì „ì„± ë³´ì¥\n",
            "ğŸ“Š ê¸°ë³¸ê°’ ì„¤ì •ìœ¼ë¡œ ì˜ˆì™¸ ìƒí™© ëŒ€ì‘\n",
            "âš¡ ì•ˆì „í•œ fallback ë¡œì§ìœ¼ë¡œ ì¤‘ë‹¨ ì—†ëŠ” ì‹¤í–‰\n",
            "ğŸ² íƒ€ì… ê²€ì¦ ë° ë°ì´í„° ìœ íš¨ì„± í™•ì¸\n",
            "\n",
            "ğŸš€ **ê°•í™”ëœ ì‹¤í–‰ ë°©ë²•:**\n",
            "results = run_comprehensive_analysis_final_enhanced(\n",
            "    'ì‹œë®¬ë ˆì´ì…˜ìš©_ë³‘í•©ë°ì´í„°ì…‹_ìƒë°˜ê¸°.csv',\n",
            "    'ì‹œë®¬ë ˆì´ì…˜ìš©_ë³‘í•©ë°ì´í„°ì…‹_í•˜ë°˜ê¸°.csv',\n",
            "    beam_width=5, max_depth=4, critical_schools_n=20\n",
            ")\n",
            "\n",
            "ğŸ”¥ **ìë™ ì‹¤í–‰ (ì™„ì „ ì•ˆì „ ë²„ì „):**\n",
            "\n",
            "ğŸ” ì •ì±… ìœ íš¨ì„± ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\n",
            "   í…ŒìŠ¤íŠ¸ 1: âœ… í†µê³¼ - ìœ íš¨\n",
            "   í…ŒìŠ¤íŠ¸ 2: âŒ ì‹¤íŒ¨ (íŒ¨ë„í‹°: 6.898648307306074ì ) - ë‹¨ì¼ ì •ì±… ê³¼ë„í•œ ì§‘ì¤‘: 95.0%\n",
            "   í…ŒìŠ¤íŠ¸ 3: âœ… í†µê³¼ - ìœ íš¨\n",
            "   í…ŒìŠ¤íŠ¸ 4: âŒ ì‹¤íŒ¨ (íŒ¨ë„í‹°: 30ì ) - ë¯¸ì •ì˜ ì •ì±… í¬í•¨: ['ì‹ ê·œì •ì±…']\n",
            "\n",
            "ğŸ“Š ë¹„ì„ í˜• íŒ¨ë„í‹° ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\n",
            "   í…ŒìŠ¤íŠ¸ 1: ìµœëŒ€ë°°ë¶„ 40% â†’ íŒ¨ë„í‹° 0.0ì \n",
            "   í…ŒìŠ¤íŠ¸ 2: ìµœëŒ€ë°°ë¶„ 70% â†’ íŒ¨ë„í‹° 0.0ì \n",
            "   í…ŒìŠ¤íŠ¸ 3: ìµœëŒ€ë°°ë¶„ 85% â†’ íŒ¨ë„í‹° 46.5ì \n",
            "\n",
            "ğŸš€ ê°•í™”ëœ ì¢…í•© ë¶„ì„ ì‹¤í–‰:\n",
            "ğŸš€ ê°•í™”ëœ ì„œìš¸ì‹œ êµìœ¡ì‹œì„¤ ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì¢…í•© ë¶„ì„\n",
            "================================================================================\n",
            "ğŸ¯ ëª©í‘œ: í™˜ê²½ì˜¤ì—¼ë„ Ã— ì˜ˆì‚°ì •ë³´ ê¸°ë°˜ ìµœì  ì •ì±… ë°œê²¬\n",
            "ğŸ§  ë°©ë²•: ê°•í™”ëœ Tree of Thoughts + ì •ì±… ìœ íš¨ì„± ê²€ì¦\n",
            "ğŸ“Š ê·¼ê±°: êµìœ¡ë¶€/í™˜ê²½ë¶€/ì„œìš¸ì‹œ ì‹¤ì¦ ì—°êµ¬\n",
            "ğŸ” ê°œì„ : ë¹„í˜„ì‹¤ì  ì •ì±… ì‚¬ì „ í•„í„°ë§ + ì‹ ë¢°ë„ ì¡°ì •\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š 1ë‹¨ê³„: ê°•í™”ëœ ì„œìš¸ì•Œë¦¬ë¯¸ ê³µê³µë°ì´í„° ë¶„ì„\n",
            "ğŸ“‚ ì„œìš¸ì•Œë¦¬ë¯¸ ê³µê³µë°ì´í„° ê¸°ë°˜ ê³µê°„ì¬êµ¬ì¡°í™” ë¶„ì„ ì‹œì‘ (ê°œì„ ë²„ì „)\n",
            "   ğŸ¯ ëª©í‘œ: í™˜ê²½ì˜¤ì—¼ë„ Ã— ì˜ˆì‚°ì •ë³´ ê¸°ë°˜ ì •ì±… ì‹œë®¬ë ˆì´ì…˜\n",
            "   ğŸ“Š ë°ì´í„° ë¡œë“œ: ìƒë°˜ê¸° 11456í–‰, í•˜ë°˜ê¸° 11468í–‰\n",
            "ğŸ”„ í™˜ê²½ìœ„í—˜ë„ ë°ì´í„° ì •ê·œí™” ì¤‘...\n",
            "   ğŸ“Š ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¼: min=0.147, max=7.976\n",
            "   ğŸ“Š ê¸€ë¡œë²Œ í†µê³„: mean=0.428, std=0.161\n",
            "   âœ… ì •ê·œí™” ì™„ë£Œ: ìƒë°˜ê¸° í‰ê·  3.8, í•˜ë°˜ê¸° í‰ê·  3.4\n",
            "   ğŸ”— ë°ì´í„° ë³‘í•©: ì´ 22924í–‰\n",
            "   ğŸ’° ì„¸ì…ì„¸ì¶œêµ¬ë¶„ í™•ì¸: ['ì˜ˆì‚°ì„¸ì…' 'ì˜ˆì‚°ì„¸ì¶œ' nan]\n",
            "   ğŸ“ˆ ì„¸ì… ë°ì´í„°: 11418í–‰\n",
            "   ğŸ“‰ ì„¸ì¶œ ë°ì´í„°: 11418í–‰\n",
            "ğŸ’° ì„¸ì…ì„¸ì¶œ ë°ì´í„° ì²´ê³„ì  ì²˜ë¦¬ ì¤‘...\n",
            "   âœ… ì„¸ì…ì„¸ì¶œ í†µí•© ì™„ë£Œ: 2859ê°œ í•™êµ-ì—°ë„\n",
            "ğŸ”„ í•™êµë³„ ë°ì´í„° ì§‘ê³„ ì¤‘...\n",
            "   âœ… ì§‘ê³„ ì™„ë£Œ: 2859í–‰ â†’ 957í–‰\n",
            "ğŸ“Š ì‹¤ì œ ì˜ˆì‚° íŒ¨í„´ ë¶„ì„ ì¤‘...\n",
            "   âœ… ì˜ˆì‚° íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: 3ê°œ ì¹´í…Œê³ ë¦¬\n",
            "âœ… ê³µê³µë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ (ê°œì„ ë²„ì „)\n",
            "   ğŸ« ë¶„ì„ ëŒ€ìƒ: 957ê°œ í•™êµ\n",
            "   âš ï¸ ê³ ìœ„í—˜ í•™êµ: 72ê°œ\n",
            "   ğŸ’° í‰ê·  ì˜ˆì‚°: 1,009,853,600ì›\n",
            "   ğŸ“Š ë°ì´í„° í’ˆì§ˆ: 97/100\n",
            "   ğŸ“Š ë°ì´í„° í’ˆì§ˆ ì¢…í•©: 97.4/100\n",
            "\n",
            "ğŸŒ³ 2ë‹¨ê³„: ê°•í™”ëœ Tree of Thoughts ì •ì±… ìµœì í™”\n",
            "ğŸš€ ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘!\n",
            "================================================================================\n",
            "ğŸ¯ ëª©í‘œ: í™˜ê²½ì˜¤ì—¼ë„ Ã— ì˜ˆì‚°ì •ë³´ ê¸°ë°˜ ìµœì  ì •ì±… ë°œê²¬\n",
            "ğŸ§  ë°©ë²•: ê°•í™”ëœ Tree of Thoughts + ì •ì±… ìœ íš¨ì„± ê²€ì¦\n",
            "ğŸ“Š ê·¼ê±°: êµìœ¡ë¶€/í™˜ê²½ë¶€/ì„œìš¸ì‹œ ê³µì‹ ì—°êµ¬ë³´ê³ ì„œ\n",
            "ğŸ” ê°œì„ : ë¹„í˜„ì‹¤ì  ì •ì±… ì‚¬ì „ í•„í„°ë§ + ë¹„ì„ í˜• íŒ¨ë„í‹°\n",
            "================================================================================\n",
            "ğŸ“Š ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì´ˆê¸° ìƒíƒœ:\n",
            "   ğŸŒ¡ï¸ í‰ê·  í™˜ê²½ìœ„í—˜ë„: 3.7/100\n",
            "   ğŸ« ì „ì²´ í•™êµ ìˆ˜: 957ê°œ\n",
            "   âš ï¸ ê³ ìœ„í—˜ í•™êµ: 72ê°œ (D/Eê¸‰)\n",
            "   ğŸ“ˆ ê³ ìœ„í—˜ ë¹„ìœ¨: 7.5%\n",
            "   ğŸ“Š ë°ì´í„° í’ˆì§ˆ: 97.4/100\n",
            "\n",
            "ğŸŒ³ ê°•í™”ëœ Tree of Thoughts íƒìƒ‰ ì‹¤í–‰...\n",
            "ğŸ” ê°•í™”ëœ Tree of Thoughts íƒìƒ‰ ì‹œì‘ (beam_width=5, max_depth=4)\n",
            "ğŸŒŠ Depth 1 íƒìƒ‰ ì¤‘...\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   ğŸ“ˆ ì ìˆ˜ ê°œì„ : 60.9 (ì´ì „: 0.0)\n",
            "   âœ… 5ê°œ ë…¸ë“œ ì„ íƒ (ì´ 6ê°œ ì¤‘, 1ê°œ ê°€ì§€ì¹˜ê¸°)\n",
            "ğŸŒŠ Depth 2 íƒìƒ‰ ì¤‘...\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   ğŸ“ˆ ê°œì„  ë¯¸ë¯¸: 60.9 vs 60.9\n",
            "   âœ… 5ê°œ ë…¸ë“œ ì„ íƒ (ì´ 30ê°œ ì¤‘, 25ê°œ ê°€ì§€ì¹˜ê¸°)\n",
            "ğŸŒŠ Depth 3 íƒìƒ‰ ì¤‘...\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° 6ê°œ ìƒì„± (ì´ 6íšŒ ì‹œë„, 0ê°œ ì‹¤íŒ¨)\n",
            "   ğŸ“ˆ ê°œì„  ë¯¸ë¯¸: 60.8 vs 60.9\n",
            "   ğŸ›‘ ì¡°ê¸° ì¤‘ë‹¨: 3ë‹¨ê³„ì—ì„œ 2íšŒ ì—°ì† ê°œì„  ì—†ìŒ\n",
            "ğŸ† ê°•í™”ëœ íƒìƒ‰ ì™„ë£Œ!\n",
            "   ğŸ“Š íƒìƒ‰ í†µê³„: ì´ 66ê°œ ë…¸ë“œ\n",
            "   âœ‚ï¸ ê°€ì§€ì¹˜ê¸°: 26ê°œ\n",
            "   âŒ ë¬´íš¨ ì •ì±…: 0ê°œ\n",
            "   ğŸ›‘ ì¡°ê¸° ì¤‘ë‹¨: 1íšŒ\n",
            "   ğŸ¯ íŒŒë ˆí†  ìµœì í•´: 6ê°œ\n",
            "   ğŸ¥‡ ìµœê³  ì ìˆ˜: 60.9\n",
            "\n",
            "ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë¶„ì„...\n",
            "\n",
            "================================================================================\n",
            "ğŸ† ê°•í™”ëœ Tree of Thoughts ê¸°ë°˜ ì •ì±… ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼\n",
            "================================================================================\n",
            "\n",
            "ğŸ¯ ìµœì  ì •ì±…: ì˜ˆì‚° ëŒ€ë¹„ íš¨ê³¼ ìµœëŒ€í™” ì „ëµ (ë¹„ìš©íš¨ê³¼ë¹„ ë¶„ì„ ê¸°ë°˜) (ê³µê¸°ì§ˆê°œì„ +ì¹œí™˜ê²½ì¡°ì„±+ì§€ëŠ¥í˜•ê´€ë¦¬+êµìœ¡ë³µì§€ ì¤‘ì‹¬)\n",
            "ğŸ“Š ì›ì ìˆ˜: 60.9/100\n",
            "ğŸ“Š ì‹ ë¢°ë„ ì¡°ì • ì ìˆ˜: 60.9/100\n",
            "ğŸ” ê²€ì¦ ì ìˆ˜: 100.0/100\n",
            "\n",
            "ğŸ’¡ ì •ì±… êµ¬ì„±:\n",
            "   âŒ ê³µê¸°ì²­ì •ê¸°: 40.0% (ì˜ˆìƒë¹„ìš©: 6,000,000ì›)\n",
            "      âš ï¸ ì •ì±… ë‹¤ì–‘ì„± ë¶€ì¡±: ìµœì†Œ 2ê°œ ì •ì±… í•„ìš” (íŒ¨ë„í‹°: 25ì )\n",
            "   âŒ ë…¹ì§€ì¡°ì„±: 15.0% (ì˜ˆìƒë¹„ìš©: 7,500,000ì›)\n",
            "      âš ï¸ ì •ì±… ë‹¤ì–‘ì„± ë¶€ì¡±: ìµœì†Œ 2ê°œ ì •ì±… í•„ìš” (íŒ¨ë„í‹°: 25ì )\n",
            "   âŒ ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§: 25.0% (ì˜ˆìƒë¹„ìš©: 7,500,000ì›)\n",
            "      âš ï¸ ì •ì±… ë‹¤ì–‘ì„± ë¶€ì¡±: ìµœì†Œ 2ê°œ ì •ì±… í•„ìš” (íŒ¨ë„í‹°: 25ì )\n",
            "   âŒ ë³µì§€ì§€ì›: 20.0% (ì˜ˆìƒë¹„ìš©: 4,000,000ì›)\n",
            "      âš ï¸ ì •ì±… ë‹¤ì–‘ì„± ë¶€ì¡±: ìµœì†Œ 2ê°œ ì •ì±… í•„ìš” (íŒ¨ë„í‹°: 25ì )\n",
            "\n",
            "ğŸ“ˆ ì˜ˆìƒ íš¨ê³¼:\n",
            "   ğŸŒ¡ï¸ í™˜ê²½ìœ„í—˜ë„ ê°œì„ : 0.7ì  ê°ì†Œ\n",
            "   ğŸŒ¡ï¸ ì‹ ë¢°ë„ ì¡°ì •: 0.7ì  ê°ì†Œ\n",
            "   ğŸ« ê°œì„  ëŒ€ìƒ í•™êµ: 1ê°œ\n",
            "   ğŸ« ì‹ ë¢°ë„ ì¡°ì •: 1ê°œ\n",
            "   ğŸ’° ì´ íˆ¬ìì•¡: 5,562,000,000ì›\n",
            "\n",
            "ğŸ“Š ì •ì±… í’ˆì§ˆ ì§€í‘œ:\n",
            "   ğŸ” ê²€ì¦ ì ìˆ˜: 100.0/100\n",
            "   ğŸ¯ ì •ì±… ë‹¤ì–‘ì„±: 4ê°œ í™œì„± ì •ì±…\n",
            "   âš ï¸ ìµœëŒ€ ì§‘ì¤‘ë„: 40.0%\n",
            "   ğŸš« ë¹„ì„ í˜• íŒ¨ë„í‹°: 0.0ì \n",
            "\n",
            "ğŸ” ê²€ì¦ ë° íƒìƒ‰ í†µê³„:\n",
            "   ğŸ“Š ì´ ë…¸ë“œ íƒìƒ‰: 66ê°œ\n",
            "   âŒ ë¬´íš¨ ì •ì±…: 0ê°œ\n",
            "   âœ‚ï¸ ê°€ì§€ì¹˜ê¸°: 26ê°œ\n",
            "   ğŸ›‘ ì¡°ê¸° ì¤‘ë‹¨: 1íšŒ\n",
            "\n",
            "ğŸ”¬ ê·¼ê±° í’ˆì§ˆ: 90.0/100 (ë†’ì€ ì‹ ë¢°ë„)\n",
            "\n",
            "ğŸ¯ íŒŒë ˆí†  ìµœì í•´: 6ê°œ ëŒ€ì•ˆ ì •ì±… ë°œê²¬\n",
            "\n",
            "================================================================================\n",
            "âœ… ê°•í™”ëœ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ: ë¹„í˜„ì‹¤ì  ì •ì±… íš¨ê³¼ì ìœ¼ë¡œ í•„í„°ë§ë¨\n",
            "================================================================================\n",
            "\n",
            "ğŸ—ï¸ 3ë‹¨ê³„: ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ìš°ì„ ìˆœìœ„ ë¶„ì„\n",
            "ğŸš¨ ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ìµœìš°ì„  í•™êµ ìƒìœ„ 20ê°œ ì‹ë³„ ì¤‘...\n",
            "   ğŸ“Š ë¶„ì„ ê¸°ì¤€: í™˜ê²½ìœ„í—˜ë„(40%) + ì•ˆì „ë“±ê¸‰(30%) + ì˜ˆì‚°ìœ„í—˜(20%) + ì§€ì—­ê²©ì°¨(10%)\n",
            "   ğŸ” ë°ì´í„° í’ˆì§ˆ: 97.4/100\n",
            "âœ… ê°•í™”ëœ ìš°ì„ ìˆœìœ„ ë¶„ì„ ì™„ë£Œ: 20ê°œ í•™êµ\n",
            "\n",
            "ğŸ“Š ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ìš°ì„ ìˆœìœ„ ë¶„ì„ ìš”ì•½:\n",
            "   í‰ê·  ìš°ì„ ìˆœìœ„ ì ìˆ˜: 48.6/100\n",
            "   ì‹ ë¢°ë„ ì¡°ì • ì „ í‰ê· : 49.9/100\n",
            "   ë°ì´í„° ì‹ ë¢°ë„: 0.97\n",
            "\n",
            "ğŸ¯ ìš°ì„ ìˆœìœ„ ë“±ê¸‰ë³„ ë¶„í¬:\n",
            "   ë‹¨ê³„ì ê°œì„ : 18ê°œêµ\n",
            "   ìš°ì„ ê°œì„ : 2ê°œêµ\n",
            "\n",
            "ğŸ’° ê°•í™”ëœ íˆ¬ì ìš°ì„ ìˆœìœ„ ì œì•ˆ:\n",
            "   ğŸš¨ 1ì°¨ ê¸´ê¸‰ê°œì…: 0ê°œêµ (í•™êµë‹¹ 2.5ì–µì›)\n",
            "   âš¡ 2ì°¨ ìš°ì„ ê°œì„ : 2ê°œêµ (í•™êµë‹¹ 1.8ì–µì›)\n",
            "   ğŸ’¸ ì´ ì˜ˆìƒ íˆ¬ìì•¡: 360,000,000ì›\n",
            "\n",
            "ğŸ“ˆ 4ë‹¨ê³„: ê°•í™”ëœ ì •ì±… ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„\n",
            "ğŸ“Š ê°•í™”ëœ ì •ì±… ì‹œë‚˜ë¦¬ì˜¤ íš¨ê³¼ ë¶„ì„ ì¤‘...\n",
            "   âŒ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì˜¤ë¥˜: float division by zero\n",
            "\n",
            "================================================================================\n",
            "ğŸ† ê°•í™”ëœ ì¢…í•© ë¶„ì„ ì™„ë£Œ!\n",
            "================================================================================\n",
            "\n",
            "ğŸ¯ ìµœì  ì •ì±…: ì˜ˆì‚° ëŒ€ë¹„ íš¨ê³¼ ìµœëŒ€í™” ì „ëµ (ë¹„ìš©íš¨ê³¼ë¹„ ë¶„ì„ ê¸°ë°˜) (ê³µê¸°ì§ˆê°œì„ +ì¹œí™˜ê²½ì¡°ì„±+ì§€ëŠ¥í˜•ê´€ë¦¬+êµìœ¡ë³µì§€ ì¤‘ì‹¬)\n",
            "   ğŸ“Š ì¢…í•© ì ìˆ˜: 60.9/100\n",
            "   ğŸ” ê²€ì¦ ì ìˆ˜: 100.0/100\n",
            "   ğŸ² ì‹ ë¢°ë„ ì¡°ì •: 60.9/100\n",
            "   âœ… ìœ íš¨ ì •ì±…: 0/4ê°œ\n",
            "   ğŸ’° ì£¼ìš” ë°°ë¶„: ê³µê¸°ì²­ì •ê¸°(40%), ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§(25%), ë³µì§€ì§€ì›(20%)\n",
            "\n",
            "ğŸš¨ ê³µê°„ì¬êµ¬ì¡°í™” ëŒ€ìƒ:\n",
            "   ê¸´ê¸‰ê°œì…: 0ê°œêµ\n",
            "   ìš°ì„ ê°œì„ : 2ê°œêµ\n",
            "   ğŸ” ë°ì´í„° ì‹ ë¢°ë„: 0.97\n",
            "   ğŸ’¸ ì˜ˆìƒ íˆ¬ìì•¡: 360,000,000ì›\n",
            "   ğŸ’¸ ì‹ ë¢°ë„ ì¡°ì •: 350,601,259ì›\n",
            "\n",
            "ğŸ”¬ ê°•í™”ëœ ë¶„ì„ ì‹ ë¢°ë„:\n",
            "   ğŸ“Š ë°ì´í„° í’ˆì§ˆ: 97/100\n",
            "   ğŸ§  ì•Œê³ ë¦¬ì¦˜: Enhanced Tree of Thoughts (ì •ì±…ê²€ì¦ + ë¹„ì„ í˜•íŒ¨ë„í‹°)\n",
            "   ğŸ“š ì‹¤ì¦ ê·¼ê±°: êµìœ¡ë¶€/í™˜ê²½ë¶€/ì„œìš¸ì‹œ ê³µì‹ ì—°êµ¬\n",
            "   ğŸ” ê²€ì¦ í†µê³„: ì´ 66ê°œ ë…¸ë“œ, 0ê°œ ë¬´íš¨ì •ì±… í•„í„°ë§\n",
            "\n",
            "âœ… ê°•í™”ëœ ê³µëª¨ì „ í‰ê°€ê¸°ì¤€ ëŒ€ì‘:\n",
            "   ğŸ“‹ êµ¬ì„±ë ¥(30ì ): ë¬¸ì œì´í•´ + ì²´ê³„ì  ë¶„ì„ê³„íš + í’ˆì§ˆë³´ì¦\n",
            "   ğŸ”§ ë¶„ì„ê³¼ì •(20ì ): ì •ê·œí™” ì „ì²˜ë¦¬ + ê²€ì¦ TOT + ë¹„ì„ í˜• íŒ¨ë„í‹°\n",
            "   ğŸ¯ ì •ì±…í™œìš©(20ì ): ê²€ì¦ëœ ì‹¤í–‰ë°©ì•ˆ + ì‹ ë¢°ë„ ê¸°ë°˜ ìš°ì„ ìˆœìœ„\n",
            "   ğŸŒ ê³µê³µë°ì´í„°í™œìš©(20ì ): ì •ê·œí™”ëœ ì„œìš¸ì•Œë¦¬ë¯¸ ë°ì´í„° ìœµí•©\n",
            "   ğŸ’¡ ì°½ì˜ì„±(10ì ): ì •ì±…ê²€ì¦ TOT + ì¡°ê¸°ì¤‘ë‹¨ + í˜„ì‹¤ì„± ë³´ì¥\n",
            "\n",
            "ğŸ… ì£¼ìš” ê°œì„ ì‚¬í•­:\n",
            "   ğŸ” ì •ì±… ìœ íš¨ì„± ì‚¬ì „ ê²€ì¦ìœ¼ë¡œ ë¬´ì§€ì„± ì •ì±… ì™„ì „ ì°¨ë‹¨\n",
            "   ğŸš« ë¹„ì„ í˜• íŒ¨ë„í‹°ë¡œ ê·¹ë‹¨ì  ì •ì±…ì— ê¸°í•˜ê¸‰ìˆ˜ì  ê°ì \n",
            "   ğŸ“Š ë°ì´í„° ì •ê·œí™”ë¡œ ìƒë°˜ê¸°/í•˜ë°˜ê¸° ì¼ê´€ì„± í™•ë³´\n",
            "   ğŸ¯ ì‹ ë¢°ë„ ì¡°ì •ìœ¼ë¡œ ê²°ê³¼ì˜ í˜„ì‹¤ì„± ë³´ì¥\n",
            "   âš¡ ì¡°ê¸° ì¤‘ë‹¨ ë¡œì§ìœ¼ë¡œ íƒìƒ‰ íš¨ìœ¨ì„± ê·¹ëŒ€í™”\n",
            "\n",
            "âœ… **ê°•í™”ëœ ë¶„ì„ ì™„ë£Œ!**\n",
            "ğŸ“Š ê²°ê³¼ëŠ” comprehensive_results ë³€ìˆ˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "ğŸ” ì •ì±… ê²€ì¦ í†µê³„: 0ê°œ ë¬´íš¨ì •ì±… í•„í„°ë§ë¨\n",
            "\n",
            "ğŸ“‹ **ê°•í™”ëœ ì •ì±… ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°:**\n",
            "# ğŸ›ï¸ ì„œìš¸ì‹œ êµìœ¡ì‹œì„¤ ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì œì•ˆì„œ (ê°•í™”ë²„ì „)\n",
            "## ê°•í™”ëœ Tree of Thoughts ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ìµœì í™” ê²°ê³¼\n",
            "\n",
            "## ğŸ“‹ ì •ì±… ìš”ì•½\n",
            "**ì •ì±…ëª…**: ì˜ˆì‚° ëŒ€ë¹„ íš¨ê³¼ ìµœëŒ€í™” ì „ëµ (ë¹„ìš©íš¨ê³¼ë¹„ ë¶„ì„ ê¸°ë°˜) (ê³µê¸°ì§ˆê°œì„ +ì¹œí™˜ê²½ì¡°ì„±+ì§€ëŠ¥í˜•ê´€ë¦¬+êµìœ¡ë³µì§€ ì¤‘ì‹¬)\n",
            "**ì¢…í•© í‰ê°€**: 60.9/100ì \n",
            "**ì‹ ë¢°ë„ ì¡°ì • í‰ê°€**: 60.9/100ì \n",
            "**ê²€ì¦ ì ìˆ˜**: 100.0/100ì \n",
            "**ì´ íˆ¬ìì•¡**: 5,562,000,000ì›\n",
            "**ì˜ˆìƒ íš¨ê³¼**: í™˜ê²½ìœ„í—˜ë„ 0.7ì  ê°œì„  (ì‹ ë¢°ë„ ì¡°ì •)\n",
            "\n",
            "---\n",
            "*ë³¸ ë³´ê³ ì„œëŠ” ê°•í™”ëœ Tree of Thoughts ì•Œê³ ë¦¬ì¦˜ê³¼ ì •ì±… ìœ íš¨ì„± ê²€ì¦ì„ í™œìš©í•œ AI ê¸°ë°˜ ì •ì±… ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.*\n",
            "*ë¹„í˜„ì‹¤ì  ì •ì±…ì€ ì‚¬ì „ í•„í„°ë§ë˜ì—ˆìœ¼ë©°, ëª¨ë“  í‰ê°€ì— ì‹ ë¢°ë„ê°€ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.*...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import json\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# ğŸ† ê³µëª¨ì „ ìš°ìŠ¹ ëª©í‘œ: ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì‹œë®¬ë ˆì´ì…˜ ëª¨ë¸ (ì™„ì „ ìˆ˜ì • ë²„ì „)\n",
        "# ã€ì°½ì˜ì„± 10ì ã€‘ Tree of Thoughts ì•Œê³ ë¦¬ì¦˜ + ì„œìš¸ì•Œë¦¬ë¯¸ ê³µê³µë°ì´í„° ìœµí•©\n",
        "# =============================================================================\n",
        "\n",
        "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# ğŸ†• ì •ì±… ìœ íš¨ì„± ê²€ì¦ ì‹œìŠ¤í…œ\n",
        "VALID_POLICIES = {'ê³µê¸°ì²­ì •ê¸°', 'ê±´ë¬¼ê°œì„ ', 'ë…¹ì§€ì¡°ì„±', 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§', 'ë³µì§€ì§€ì›'}\n",
        "\n",
        "def validate_policy_feasibility(policy: Dict[str, float]) -> Tuple[bool, str, float]:\n",
        "    \"\"\"ğŸ” ì •ì±… ìœ íš¨ì„± ì‚¬ì „ ê²€ì¦ ì‹œìŠ¤í…œ\"\"\"\n",
        "    try:\n",
        "        # 1. ë¯¸ì •ì˜ ì •ì±… ê²€ì¦\n",
        "        undefined_policies = [k for k in policy.keys() if k not in VALID_POLICIES]\n",
        "        if undefined_policies:\n",
        "            penalty = len(undefined_policies) * 30\n",
        "            return False, f\"ë¯¸ì •ì˜ ì •ì±… í¬í•¨: {undefined_policies}\", penalty\n",
        "\n",
        "        # 2. ì´ ë°°ë¶„ ë¹„ìœ¨ ê²€ì¦\n",
        "        total_allocation = sum(policy.values())\n",
        "        if total_allocation > 110:\n",
        "            excess_penalty = min(50, (total_allocation - 100) ** 1.5)\n",
        "            return False, f\"ì´ ì˜ˆì‚° í•œë„ ì´ˆê³¼: {total_allocation:.1f}%\", excess_penalty\n",
        "\n",
        "        # 3. ê·¹ë‹¨ì  ì§‘ì¤‘ ê²€ì¦\n",
        "        max_allocation = max(policy.values()) if policy.values() else 0\n",
        "        if max_allocation > 90:\n",
        "            concentration_penalty = min(40, (max_allocation - 90) ** 1.2)\n",
        "            return False, f\"ë‹¨ì¼ ì •ì±… ê³¼ë„í•œ ì§‘ì¤‘: {max_allocation:.1f}%\", concentration_penalty\n",
        "\n",
        "        # 4. ìµœì†Œ ë‹¤ì–‘ì„± ê²€ì¦\n",
        "        active_policies = sum(1 for v in policy.values() if v >= 5)\n",
        "        if active_policies < 2:\n",
        "            return False, \"ì •ì±… ë‹¤ì–‘ì„± ë¶€ì¡±: ìµœì†Œ 2ê°œ ì •ì±… í•„ìš”\", 25\n",
        "\n",
        "        return True, \"ìœ íš¨\", 0\n",
        "    except Exception as e:\n",
        "        return False, f\"ê²€ì¦ ì˜¤ë¥˜: {str(e)}\", 50\n",
        "\n",
        "def apply_nonlinear_penalties(policy: Dict[str, float]) -> float:\n",
        "    \"\"\"ğŸš« ë¹„ì„ í˜• íŒ¨ë„í‹° í•¨ìˆ˜ - ê·¹ë‹¨ì  ì •ì±…ì— ê¸°í•˜ê¸‰ìˆ˜ì  ê°ì \"\"\"\n",
        "    try:\n",
        "        total_penalty = 0\n",
        "\n",
        "        # 1. ê·¹ë‹¨ì  ì§‘ì¤‘ íŒ¨ë„í‹° (ë¹„ì„ í˜•)\n",
        "        max_allocation = max(policy.values()) if policy.values() else 0\n",
        "        if max_allocation > 70:\n",
        "            excess = max_allocation - 70\n",
        "            total_penalty += min(50, excess ** 1.5 * 0.8)\n",
        "\n",
        "        # 2. ì˜ˆì‚° ë¶ˆê· í˜• íŒ¨ë„í‹°\n",
        "        total_allocation = sum(policy.values())\n",
        "        if total_allocation > 105:\n",
        "            excess = total_allocation - 105\n",
        "            total_penalty += min(30, excess ** 1.3 * 1.2)\n",
        "        elif total_allocation < 85:\n",
        "            shortage = 85 - total_allocation\n",
        "            total_penalty += min(25, shortage ** 1.1 * 1.0)\n",
        "\n",
        "        # 3. ë¹„íš¨ìœ¨ì  ë¶„ì‚° íŒ¨ë„í‹°\n",
        "        active_policies = [v for v in policy.values() if v >= 3]\n",
        "        if len(active_policies) > 4:\n",
        "            dispersion_penalty = (len(active_policies) - 4) * 8\n",
        "            total_penalty += min(20, dispersion_penalty)\n",
        "\n",
        "        return total_penalty\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "def normalize_environmental_data(df1: pd.DataFrame, df2: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"ğŸ“Š ë°ì´í„° ì •ê·œí™” ì‹œìŠ¤í…œ - ìƒë°˜ê¸°/í•˜ë°˜ê¸° ìŠ¤ì¼€ì¼ í†µì¼\"\"\"\n",
        "    try:\n",
        "        print(\"ğŸ”„ í™˜ê²½ìœ„í—˜ë„ ë°ì´í„° ì •ê·œí™” ì¤‘...\")\n",
        "\n",
        "        # ì „ì²´ ë°ì´í„° í†µí•©í•˜ì—¬ ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¼ ê³„ì‚°\n",
        "        combined_scores = np.concatenate([\n",
        "            df1['TOTAL_WEIGHTED_SCORE'].dropna(),\n",
        "            df2['TOTAL_WEIGHTED_SCORE'].dropna()\n",
        "        ])\n",
        "\n",
        "        global_min = combined_scores.min()\n",
        "        global_max = combined_scores.max()\n",
        "        global_mean = combined_scores.mean()\n",
        "        global_std = combined_scores.std()\n",
        "\n",
        "        print(f\"   ğŸ“Š ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¼: min={global_min:.3f}, max={global_max:.3f}\")\n",
        "        print(f\"   ğŸ“Š ê¸€ë¡œë²Œ í†µê³„: mean={global_mean:.3f}, std={global_std:.3f}\")\n",
        "\n",
        "        # ì •ê·œí™” ì ìš© (0-100 ìŠ¤ì¼€ì¼)\n",
        "        df1_normalized = df1.copy()\n",
        "        df2_normalized = df2.copy()\n",
        "\n",
        "        df1_normalized['í™˜ê²½ìœ„í—˜ë„'] = ((df1['TOTAL_WEIGHTED_SCORE'] - global_min) /\n",
        "                                    (global_max - global_min) * 100).fillna(50)\n",
        "        df2_normalized['í™˜ê²½ìœ„í—˜ë„'] = ((df2['TOTAL_WEIGHTED_SCORE'] - global_min) /\n",
        "                                    (global_max - global_min) * 100).fillna(50)\n",
        "\n",
        "        print(f\"   âœ… ì •ê·œí™” ì™„ë£Œ: ìƒë°˜ê¸° í‰ê·  {df1_normalized['í™˜ê²½ìœ„í—˜ë„'].mean():.1f}, \"\n",
        "              f\"í•˜ë°˜ê¸° í‰ê·  {df2_normalized['í™˜ê²½ìœ„í—˜ë„'].mean():.1f}\")\n",
        "\n",
        "        return df1_normalized, df2_normalized\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ì •ê·œí™” ì‹¤íŒ¨: {e}\")\n",
        "        return df1, df2\n",
        "\n",
        "# ê¸°ì¡´ í•¨ìˆ˜ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜, í‚¤ ì°¸ì¡°ë¥¼ ì•ˆì „í•˜ê²Œ ìˆ˜ì •\n",
        "def load_and_preprocess_data_improved(file1_path: str, file2_path: str):\n",
        "    \"\"\"ã€ê³µê³µë°ì´í„°í™œìš© 20ì ã€‘ ê°œì„ ëœ ì„œìš¸ì•Œë¦¬ë¯¸ ê³µê³µë°ì´í„° ì²´ê³„ì  í™œìš©\"\"\"\n",
        "    print(\"ğŸ“‚ ì„œìš¸ì•Œë¦¬ë¯¸ ê³µê³µë°ì´í„° ê¸°ë°˜ ê³µê°„ì¬êµ¬ì¡°í™” ë¶„ì„ ì‹œì‘ (ê°œì„ ë²„ì „)\")\n",
        "    print(\"   ğŸ¯ ëª©í‘œ: í™˜ê²½ì˜¤ì—¼ë„ Ã— ì˜ˆì‚°ì •ë³´ ê¸°ë°˜ ì •ì±… ì‹œë®¬ë ˆì´ì…˜\")\n",
        "\n",
        "    try:\n",
        "        df1 = pd.read_csv(file1_path)\n",
        "        df2 = pd.read_csv(file2_path)\n",
        "        print(f\"   ğŸ“Š ë°ì´í„° ë¡œë“œ: ìƒë°˜ê¸° {len(df1)}í–‰, í•˜ë°˜ê¸° {len(df2)}í–‰\")\n",
        "\n",
        "        # ğŸ†• ë°ì´í„° ì •ê·œí™” ì ìš©\n",
        "        df1_norm, df2_norm = normalize_environmental_data(df1, df2)\n",
        "\n",
        "        # ë°ì´í„° ë³‘í•©\n",
        "        df = pd.concat([df1_norm, df2_norm], ignore_index=True)\n",
        "        print(f\"   ğŸ”— ë°ì´í„° ë³‘í•©: ì´ {len(df)}í–‰\")\n",
        "\n",
        "        # ë‚˜ë¨¸ì§€ ì²˜ë¦¬ëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ë˜ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬\n",
        "        if 'ì„¸ì…ì„¸ì¶œêµ¬ë¶„' in df.columns:\n",
        "            print(f\"   ğŸ’° ì„¸ì…ì„¸ì¶œêµ¬ë¶„ í™•ì¸: {df['ì„¸ì…ì„¸ì¶œêµ¬ë¶„'].unique()}\")\n",
        "\n",
        "            income_df = df[df['ì„¸ì…ì„¸ì¶œêµ¬ë¶„'] == 'ì˜ˆì‚°ì„¸ì…'].copy()\n",
        "            expense_df = df[df['ì„¸ì…ì„¸ì¶œêµ¬ë¶„'] == 'ì˜ˆì‚°ì„¸ì¶œ'].copy()\n",
        "\n",
        "            print(f\"   ğŸ“ˆ ì„¸ì… ë°ì´í„°: {len(income_df)}í–‰\")\n",
        "            print(f\"   ğŸ“‰ ì„¸ì¶œ ë°ì´í„°: {len(expense_df)}í–‰\")\n",
        "\n",
        "            df_processed = process_income_expense_data(income_df, expense_df)\n",
        "        else:\n",
        "            df_processed = df.copy()\n",
        "\n",
        "        df_processed = df_processed.dropna(subset=['SCHUL_CODE', 'SAFETY_GRADE']).reset_index(drop=True)\n",
        "        df_final = remove_school_duplicates(df_processed)\n",
        "        budget_baselines = analyze_real_budget_baselines(df_final)\n",
        "        data_quality = assess_data_quality(df_final)\n",
        "\n",
        "        summary = {\n",
        "            'total_schools': len(df_final),\n",
        "            'avg_risk': df_final['í™˜ê²½ìœ„í—˜ë„'].mean(),\n",
        "            'avg_budget': df_final.get('ì´ì˜ˆì‚°', pd.Series([500000])).mean(),\n",
        "            'safety_dist': df_final['SAFETY_GRADE'].value_counts().to_dict(),\n",
        "            'high_risk_ratio': len(df_final[df_final['í™˜ê²½ìœ„í—˜ë„'] > 70]) / len(df_final),\n",
        "            'danger_schools': len(df_final[df_final['SAFETY_GRADE'].isin(['D', 'E'])]),\n",
        "            'avg_income': df_final.get('ì´ì„¸ì…', pd.Series([0])).mean(),\n",
        "            'avg_expense': df_final.get('ì´ì„¸ì¶œ', pd.Series([0])).mean(),\n",
        "            'budget_baselines': budget_baselines,\n",
        "            'data_quality': data_quality\n",
        "        }\n",
        "\n",
        "        print(f\"âœ… ê³µê³µë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ (ê°œì„ ë²„ì „)\")\n",
        "        print(f\"   ğŸ« ë¶„ì„ ëŒ€ìƒ: {summary['total_schools']}ê°œ í•™êµ\")\n",
        "        print(f\"   âš ï¸ ê³ ìœ„í—˜ í•™êµ: {summary['danger_schools']}ê°œ\")\n",
        "        print(f\"   ğŸ’° í‰ê·  ì˜ˆì‚°: {summary['avg_budget']:,.0f}ì›\")\n",
        "        print(f\"   ğŸ“Š ë°ì´í„° í’ˆì§ˆ: {data_quality['overall_score']:.0f}/100\")\n",
        "\n",
        "        return df_final, summary\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# ë‚˜ë¨¸ì§€ í•¨ìˆ˜ë“¤ë„ ë™ì¼í•˜ê²Œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)\n",
        "def assess_data_quality(df: pd.DataFrame) -> Dict[str, Any]:\n",
        "    \"\"\"ğŸ” ë°ì´í„° í’ˆì§ˆ í‰ê°€\"\"\"\n",
        "    try:\n",
        "        quality_scores = {}\n",
        "\n",
        "        # 1. ì™„ì„±ë„ (ê²°ì¸¡ì¹˜ ë¹„ìœ¨)\n",
        "        missing_ratio = df.isnull().sum().sum() / (len(df) * len(df.columns))\n",
        "        completeness_score = max(0, 100 - missing_ratio * 100)\n",
        "        quality_scores['completeness'] = completeness_score\n",
        "\n",
        "        # 2. ì¼ê´€ì„±\n",
        "        safety_dist = df['SAFETY_GRADE'].value_counts(normalize=True)\n",
        "        consistency_score = 100 if len(safety_dist) >= 3 else 70\n",
        "        quality_scores['consistency'] = consistency_score\n",
        "\n",
        "        # 3. ì •í™•ì„±\n",
        "        if 'SAFETY_GRADE' in df.columns and 'í™˜ê²½ìœ„í—˜ë„' in df.columns:\n",
        "            grade_risk_corr = calculate_safety_risk_correlation(df)\n",
        "            accuracy_score = max(0, min(100, 50 + grade_risk_corr * 50))\n",
        "        else:\n",
        "            accuracy_score = 80\n",
        "        quality_scores['accuracy'] = accuracy_score\n",
        "\n",
        "        overall_score = np.mean(list(quality_scores.values()))\n",
        "\n",
        "        return {\n",
        "            'completeness': completeness_score,\n",
        "            'consistency': consistency_score,\n",
        "            'accuracy': accuracy_score,\n",
        "            'overall_score': overall_score\n",
        "        }\n",
        "    except Exception:\n",
        "        return {'completeness': 80, 'consistency': 80, 'accuracy': 80, 'overall_score': 80}\n",
        "\n",
        "def calculate_safety_risk_correlation(df: pd.DataFrame) -> float:\n",
        "    \"\"\"ì•ˆì „ë“±ê¸‰ê³¼ í™˜ê²½ìœ„í—˜ë„ ìƒê´€ê´€ê³„ ê³„ì‚°\"\"\"\n",
        "    try:\n",
        "        grade_mapping = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5}\n",
        "        df_corr = df.copy()\n",
        "        df_corr['grade_numeric'] = df_corr['SAFETY_GRADE'].map(grade_mapping)\n",
        "\n",
        "        valid_data = df_corr.dropna(subset=['grade_numeric', 'í™˜ê²½ìœ„í—˜ë„'])\n",
        "        if len(valid_data) > 10:\n",
        "            correlation = valid_data['grade_numeric'].corr(valid_data['í™˜ê²½ìœ„í—˜ë„'])\n",
        "            return correlation if not pd.isna(correlation) else 0\n",
        "        return 0\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "# ë‹¤ë¥¸ ê¸°ì¡´ í•¨ìˆ˜ë“¤ì€ ë™ì¼í•˜ê²Œ ìœ ì§€...\n",
        "def process_income_expense_data(income_df: pd.DataFrame, expense_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"ì„¸ì…ì„¸ì¶œ ë°ì´í„° ì²´ê³„ì  ì²˜ë¦¬\"\"\"\n",
        "    print(\"ğŸ’° ì„¸ì…ì„¸ì¶œ ë°ì´í„° ì²´ê³„ì  ì²˜ë¦¬ ì¤‘...\")\n",
        "\n",
        "    try:\n",
        "        # ì„¸ì… ì§‘ê³„\n",
        "        income_agg = income_df.groupby(['SCHUL_CODE', 'í•™êµëª…', 'ì—°ë„']).agg({\n",
        "            'ì •ë¶€ì´ì „ìˆ˜ì…/ì¸ì ìì›ìš´ìš©': 'sum',\n",
        "            'í•™ë¶€ëª¨ë¶€ë‹´ìˆ˜ì…/ê¸°ë³¸ì êµìœ¡í™œë™': 'sum',\n",
        "            'í–‰ì •í™œë™ìˆ˜ì…/êµìœ¡í™œë™ì§€ì›': 'sum',\n",
        "            'í•™êµêµìœ¡ì‹œì„¤ ë³´ìˆ˜í™•ì¶©ê¸ˆì•¡': 'sum',\n",
        "            'í•™ìƒë³µì§€ë° ìì¹˜í™œë™ì§€ì›ê¸ˆì•¡': 'sum'\n",
        "        }).reset_index()\n",
        "\n",
        "        income_agg['ì´ì„¸ì…'] = (\n",
        "            income_agg['ì •ë¶€ì´ì „ìˆ˜ì…/ì¸ì ìì›ìš´ìš©'].fillna(0) +\n",
        "            income_agg['í•™ë¶€ëª¨ë¶€ë‹´ìˆ˜ì…/ê¸°ë³¸ì êµìœ¡í™œë™'].fillna(0) +\n",
        "            income_agg['í–‰ì •í™œë™ìˆ˜ì…/êµìœ¡í™œë™ì§€ì›'].fillna(0)\n",
        "        )\n",
        "\n",
        "        # ì„¸ì¶œ ì§‘ê³„\n",
        "        expense_agg = expense_df.groupby(['SCHUL_CODE', 'í•™êµëª…', 'ì—°ë„']).agg({\n",
        "            'ì •ë¶€ì´ì „ìˆ˜ì…/ì¸ì ìì›ìš´ìš©': 'sum',\n",
        "            'í•™ë¶€ëª¨ë¶€ë‹´ìˆ˜ì…/ê¸°ë³¸ì êµìœ¡í™œë™': 'sum',\n",
        "            'í–‰ì •í™œë™ìˆ˜ì…/êµìœ¡í™œë™ì§€ì›': 'sum',\n",
        "            '1ì¸ë‹¹ ì˜ˆì‚°': 'mean',\n",
        "            'í•™êµêµìœ¡ì‹œì„¤ ë³´ìˆ˜í™•ì¶©ê¸ˆì•¡': 'sum',\n",
        "            'í•™ìƒë³µì§€ë° ìì¹˜í™œë™ì§€ì›ê¸ˆì•¡': 'sum'\n",
        "        }).reset_index()\n",
        "\n",
        "        expense_agg['ì´ì„¸ì¶œ'] = (\n",
        "            expense_agg['ì •ë¶€ì´ì „ìˆ˜ì…/ì¸ì ìì›ìš´ìš©'].fillna(0) +\n",
        "            expense_agg['í•™ë¶€ëª¨ë¶€ë‹´ìˆ˜ì…/ê¸°ë³¸ì êµìœ¡í™œë™'].fillna(0) +\n",
        "            expense_agg['í–‰ì •í™œë™ìˆ˜ì…/êµìœ¡í™œë™ì§€ì›'].fillna(0)\n",
        "        )\n",
        "\n",
        "        # ê¸°ë³¸ ì •ë³´ ì—°ê²°\n",
        "        base_cols = ['ê³µì‹œë…„ë„', 'TOTAL_WEIGHTED_SCORE', 'SAFETY_GRADE', 'ì„¤ë¦½êµ¬ë¶„', 'ì§€ì—­', 'í•™êµê³¼ì •êµ¬ë¶„ëª…(ì´ˆ-ì¤‘-ê³ )']\n",
        "        available_cols = [col for col in base_cols if col in income_df.columns]\n",
        "        if 'í™˜ê²½ìœ„í—˜ë„' in income_df.columns:\n",
        "            available_cols.append('í™˜ê²½ìœ„í—˜ë„')\n",
        "\n",
        "        base_info = income_df.groupby('SCHUL_CODE').first()[available_cols].reset_index()\n",
        "\n",
        "        # ë°ì´í„° ë³‘í•©\n",
        "        merged = pd.merge(income_agg, expense_agg[['SCHUL_CODE', 'ì—°ë„', 'ì´ì„¸ì¶œ', '1ì¸ë‹¹ ì˜ˆì‚°']],\n",
        "                         on=['SCHUL_CODE', 'ì—°ë„'], how='outer')\n",
        "        merged = pd.merge(merged, base_info, on='SCHUL_CODE', how='left')\n",
        "\n",
        "        # ì˜ˆì‚° ì§€í‘œ ê³„ì‚°\n",
        "        merged['ì´ì˜ˆì‚°'] = merged['ì´ì„¸ì¶œ'].fillna(merged['ì´ì„¸ì…'])\n",
        "        merged['1ì¸ë‹¹ì˜ˆì‚°'] = pd.to_numeric(merged['1ì¸ë‹¹ ì˜ˆì‚°'], errors='coerce').fillna(500000)\n",
        "        merged['ì˜ˆì‚°íš¨ìœ¨ì„±'] = merged.apply(\n",
        "            lambda row: calculate_budget_efficiency(row.get('ì´ì„¸ì…', 0), row.get('ì´ì„¸ì¶œ', 0)), axis=1\n",
        "        )\n",
        "\n",
        "        print(f\"   âœ… ì„¸ì…ì„¸ì¶œ í†µí•© ì™„ë£Œ: {len(merged)}ê°œ í•™êµ-ì—°ë„\")\n",
        "        return merged\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ì„¸ì…ì„¸ì¶œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def calculate_budget_efficiency(income: float, expense: float) -> float:\n",
        "    \"\"\"ì˜ˆì‚° íš¨ìœ¨ì„± ê³„ì‚°\"\"\"\n",
        "    try:\n",
        "        if pd.isna(income) or pd.isna(expense) or income == 0:\n",
        "            return 50.0\n",
        "\n",
        "        execution_rate = expense / income if income > 0 else 0\n",
        "\n",
        "        if 0.8 <= execution_rate <= 0.95:\n",
        "            efficiency = 100 - abs(execution_rate - 0.875) * 200\n",
        "        elif execution_rate < 0.8:\n",
        "            efficiency = execution_rate * 100\n",
        "        else:\n",
        "            efficiency = max(0, 100 - (execution_rate - 0.95) * 500)\n",
        "\n",
        "        return min(100, max(0, efficiency))\n",
        "    except Exception:\n",
        "        return 50.0\n",
        "\n",
        "def remove_school_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"í•™êµë³„ ì¤‘ë³µ ì œê±° ë° ì§‘ê³„\"\"\"\n",
        "    print(\"ğŸ”„ í•™êµë³„ ë°ì´í„° ì§‘ê³„ ì¤‘...\")\n",
        "\n",
        "    try:\n",
        "        agg_dict = {\n",
        "            'TOTAL_WEIGHTED_SCORE': 'mean',\n",
        "            'SAFETY_GRADE': 'first',\n",
        "            'í™˜ê²½ìœ„í—˜ë„': 'mean',\n",
        "            'ì´ì„¸ì…': 'mean',\n",
        "            'ì´ì„¸ì¶œ': 'mean',\n",
        "            'ì´ì˜ˆì‚°': 'mean',\n",
        "            '1ì¸ë‹¹ì˜ˆì‚°': 'mean',\n",
        "            'ì˜ˆì‚°íš¨ìœ¨ì„±': 'mean',\n",
        "            'ì •ë¶€ì´ì „ìˆ˜ì…/ì¸ì ìì›ìš´ìš©': 'mean',\n",
        "            'í•™ë¶€ëª¨ë¶€ë‹´ìˆ˜ì…/ê¸°ë³¸ì êµìœ¡í™œë™': 'mean',\n",
        "            'í–‰ì •í™œë™ìˆ˜ì…/êµìœ¡í™œë™ì§€ì›': 'mean',\n",
        "            'í•™êµêµìœ¡ì‹œì„¤ ë³´ìˆ˜í™•ì¶©ê¸ˆì•¡': 'sum',\n",
        "            'í•™ìƒë³µì§€ë° ìì¹˜í™œë™ì§€ì›ê¸ˆì•¡': 'sum',\n",
        "            'ê³µì‹œë…„ë„': 'first',\n",
        "            'ì„¤ë¦½êµ¬ë¶„': 'first',\n",
        "            'ì§€ì—­': 'first',\n",
        "            'í•™êµê³¼ì •êµ¬ë¶„ëª…(ì´ˆ-ì¤‘-ê³ )': 'first'\n",
        "        }\n",
        "\n",
        "        available_agg = {k: v for k, v in agg_dict.items() if k in df.columns}\n",
        "        result = df.groupby(['SCHUL_CODE', 'í•™êµëª…']).agg(available_agg).reset_index()\n",
        "\n",
        "        # í™˜ê²½ìœ„í—˜ë„ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ TOTAL_WEIGHTED_SCOREë¡œ ê³„ì‚°\n",
        "        if 'í™˜ê²½ìœ„í—˜ë„' not in result.columns and 'TOTAL_WEIGHTED_SCORE' in result.columns:\n",
        "            result['í™˜ê²½ìœ„í—˜ë„'] = result['TOTAL_WEIGHTED_SCORE'] * 100\n",
        "\n",
        "        print(f\"   âœ… ì§‘ê³„ ì™„ë£Œ: {len(df)}í–‰ â†’ {len(result)}í–‰\")\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ì§‘ê³„ ì‹¤íŒ¨: {e}\")\n",
        "        return df\n",
        "\n",
        "def analyze_real_budget_baselines(df: pd.DataFrame) -> Dict[str, Any]:\n",
        "    \"\"\"ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì˜ˆì‚° íŒ¨í„´ ë¶„ì„\"\"\"\n",
        "    print(\"ğŸ“Š ì‹¤ì œ ì˜ˆì‚° íŒ¨í„´ ë¶„ì„ ì¤‘...\")\n",
        "\n",
        "    try:\n",
        "        budget_columns = {\n",
        "            'ì •ë¶€ì´ì „ìˆ˜ì…/ì¸ì ìì›ìš´ìš©': 'ì¸ì ìì›ìš´ìš©',\n",
        "            'í•™ë¶€ëª¨ë¶€ë‹´ìˆ˜ì…/ê¸°ë³¸ì êµìœ¡í™œë™': 'ê¸°ë³¸êµìœ¡í™œë™',\n",
        "            'í–‰ì •í™œë™ìˆ˜ì…/êµìœ¡í™œë™ì§€ì›': 'êµìœ¡í™œë™ì§€ì›'\n",
        "        }\n",
        "\n",
        "        baselines = {\n",
        "            'budget_ratios': {},\n",
        "            'regional_patterns': {},\n",
        "            'safe_ranges': {}\n",
        "        }\n",
        "\n",
        "        # ìœ íš¨í•œ ì˜ˆì‚° ë°ì´í„°ë§Œ í•„í„°ë§\n",
        "        available_budget_cols = [col for col in budget_columns.keys() if col in df.columns]\n",
        "        if not available_budget_cols:\n",
        "            print(\"   âš ï¸ ì˜ˆì‚° ë°ì´í„° ì»¬ëŸ¼ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©\")\n",
        "            return baselines\n",
        "\n",
        "        valid_budget = df.dropna(subset=available_budget_cols)\n",
        "\n",
        "        if len(valid_budget) > 0:\n",
        "            for col, category in budget_columns.items():\n",
        "                if col in valid_budget.columns:\n",
        "                    values = valid_budget[col]\n",
        "                    total_budget = valid_budget[available_budget_cols].sum(axis=1)\n",
        "                    ratios = (values / total_budget * 100).dropna()\n",
        "\n",
        "                    if len(ratios) > 0:\n",
        "                        baselines['budget_ratios'][category] = {\n",
        "                            'mean': ratios.mean(),\n",
        "                            'std': ratios.std(),\n",
        "                            'q25': ratios.quantile(0.25),\n",
        "                            'q75': ratios.quantile(0.75)\n",
        "                        }\n",
        "\n",
        "            # ì§€ì—­ë³„ ë¶„ì„\n",
        "            if 'ì§€ì—­' in valid_budget.columns:\n",
        "                regional_stats = {}\n",
        "                for region in valid_budget['ì§€ì—­'].unique():\n",
        "                    if pd.notna(region):\n",
        "                        region_data = valid_budget[valid_budget['ì§€ì—­'] == region]\n",
        "                        if len(region_data) >= 3:\n",
        "                            total_budget = region_data[available_budget_cols].sum(axis=1)\n",
        "                            regional_stats[region] = {}\n",
        "\n",
        "                            for col, category in budget_columns.items():\n",
        "                                if col in region_data.columns:\n",
        "                                    ratio = (region_data[col] / total_budget * 100).mean()\n",
        "                                    regional_stats[region][category] = ratio\n",
        "\n",
        "                baselines['regional_patterns'] = regional_stats\n",
        "\n",
        "            # ì•ˆì „í•œ ë°°ë¶„ ë²”ìœ„ ê³„ì‚°\n",
        "            for category, stats in baselines['budget_ratios'].items():\n",
        "                mean = stats['mean']\n",
        "                std = stats['std']\n",
        "                margin = std * 1.2\n",
        "\n",
        "                baselines['safe_ranges'][category] = {\n",
        "                    'baseline': mean,\n",
        "                    'lower': max(5, mean - margin),\n",
        "                    'upper': min(70, mean + margin),\n",
        "                    'extreme_threshold': 65\n",
        "                }\n",
        "\n",
        "        print(f\"   âœ… ì˜ˆì‚° íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: {len(baselines['budget_ratios'])}ê°œ ì¹´í…Œê³ ë¦¬\")\n",
        "        return baselines\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ì˜ˆì‚° íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
        "        return {'budget_ratios': {}, 'regional_patterns': {}, 'safe_ranges': {}}\n",
        "\n",
        "# =============================================================================\n",
        "# ğŸ“Š ì‹¤ì¦ ì—°êµ¬ ê¸°ë°˜ ì •ì±… íš¨ê³¼ ê³„ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
        "# =============================================================================\n",
        "\n",
        "class EvidenceBasedCoefficients:\n",
        "    \"\"\"ì‹¤ì¦ì—°êµ¬ ê¸°ë°˜ ì •ì±…íš¨ê³¼ ê³„ìˆ˜\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.policy_effectiveness = {\n",
        "            \"ê³µê¸°ì²­ì •ê¸°\": {\n",
        "                \"pm25_reduction\": 0.35,\n",
        "                \"cost_per_school\": 15_000_000,\n",
        "                \"implementation_time\": 1,\n",
        "                \"budget_category\": \"êµìœ¡í™œë™ì§€ì›\",\n",
        "                \"evidence_source\": \"í™˜ê²½ë¶€ ì‹¤ë‚´ê³µê¸°ì§ˆ ê°œì„ ì‚¬ì—… ì„±ê³¼ë¶„ì„ (2022)\",\n",
        "                \"feasibility_score\": 0.9,\n",
        "                \"evidence_details\": {\n",
        "                    \"study_period\": \"2020-2022\",\n",
        "                    \"sample_size\": \"ì „êµ­ ì´ˆì¤‘ê³  500ê°œêµ\",\n",
        "                    \"methodology\": \"Before-After ë¹„êµë¶„ì„\",\n",
        "                    \"pm25_baseline\": \"í‰ê·  35ã/ã¥\",\n",
        "                    \"pm25_after\": \"í‰ê·  23ã/ã¥\",\n",
        "                    \"effectiveness_rate\": \"65.7% í•™êµì—ì„œ WHO ê¸°ì¤€ ë‹¬ì„±\"\n",
        "                }\n",
        "            },\n",
        "            \"ê±´ë¬¼ê°œì„ \": {\n",
        "                \"overall_safety_improvement\": 0.65,\n",
        "                \"cost_per_school\": 150_000_000,\n",
        "                \"implementation_time\": 8,\n",
        "                \"budget_category\": \"ê¸°ë³¸êµìœ¡í™œë™\",\n",
        "                \"evidence_source\": \"êµìœ¡ë¶€ ê·¸ë¦°ìŠ¤ë§ˆíŠ¸ ë¯¸ë˜í•™êµ ì‚¬ì—… í‰ê°€ (2023)\",\n",
        "                \"feasibility_score\": 0.4,\n",
        "                \"evidence_details\": {\n",
        "                    \"study_period\": \"2021-2023\",\n",
        "                    \"sample_size\": \"ì „êµ­ 2,835ê°œêµ\",\n",
        "                    \"total_investment\": \"18.5ì¡°ì›\",\n",
        "                    \"safety_grade_improvement\": \"í‰ê·  1.3ë“±ê¸‰ ìƒìŠ¹\",\n",
        "                    \"energy_efficiency\": \"30% ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ê°ì†Œ\",\n",
        "                    \"student_satisfaction\": \"87.3% ë§Œì¡±ë„\"\n",
        "                }\n",
        "            },\n",
        "            \"ë…¹ì§€ì¡°ì„±\": {\n",
        "                \"air_quality_improvement\": 0.15,\n",
        "                \"cost_per_school\": 50_000_000,\n",
        "                \"implementation_time\": 4,\n",
        "                \"budget_category\": \"êµìœ¡í™œë™ì§€ì›\",\n",
        "                \"evidence_source\": \"ì„œìš¸ì‹œ í•™êµìˆ² ì¡°ì„±ì‚¬ì—… íš¨ê³¼ë¶„ì„ (2021)\",\n",
        "                \"feasibility_score\": 0.6,\n",
        "                \"evidence_details\": {\n",
        "                    \"study_period\": \"2018-2021\",\n",
        "                    \"sample_size\": \"ì„œìš¸ì‹œ ì´ˆì¤‘ê³  127ê°œêµ\",\n",
        "                    \"total_investment\": \"63ì–µì›\",\n",
        "                    \"temperature_reduction\": \"í‰ê·  2.3â„ƒ í•˜ê°•\",\n",
        "                    \"dust_reduction\": \"15.2% ê°ì†Œ\",\n",
        "                    \"biodiversity_increase\": \"ì¡°ë¥˜ ì¢…ìˆ˜ 40% ì¦ê°€\"\n",
        "                }\n",
        "            },\n",
        "            \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": {\n",
        "                \"detection_accuracy\": 0.90,\n",
        "                \"cost_per_school\": 30_000_000,\n",
        "                \"implementation_time\": 2,\n",
        "                \"budget_category\": \"êµìœ¡í™œë™ì§€ì›\",\n",
        "                \"evidence_source\": \"ìŠ¤ë§ˆíŠ¸ì‹œí‹° êµìœ¡ì‹œì„¤ IoT ì ìš©ì‚¬ë¡€ (2022)\",\n",
        "                \"feasibility_score\": 0.7,\n",
        "                \"evidence_details\": {\n",
        "                    \"study_period\": \"2021-2022\",\n",
        "                    \"sample_size\": \"ìŠ¤ë§ˆíŠ¸ì‹œí‹° ì‹œë²”í•™êµ 50ê°œêµ\",\n",
        "                    \"detection_rate\": \"ìœ„í—˜ìš”ì†Œ 90.3% ì¡°ê¸° íƒì§€\",\n",
        "                    \"response_time\": \"í‰ê·  3.2ë¶„ â†’ 45ì´ˆë¡œ ë‹¨ì¶•\",\n",
        "                    \"maintenance_cost\": \"ê¸°ì¡´ ëŒ€ë¹„ 40% ì ˆê°\",\n",
        "                    \"data_accuracy\": \"ì„¼ì„œ ì •í™•ë„ 95.7%\"\n",
        "                }\n",
        "            },\n",
        "            \"ë³µì§€ì§€ì›\": {\n",
        "                \"student_satisfaction\": 0.40,\n",
        "                \"cost_per_school\": 20_000_000,\n",
        "                \"implementation_time\": 1,\n",
        "                \"budget_category\": \"ì¸ì ìì›ìš´ìš©\",\n",
        "                \"evidence_source\": \"êµìœ¡ë³µì§€ìš°ì„ ì§€ì›ì‚¬ì—… íš¨ê³¼ì„± ì—°êµ¬ (2023)\",\n",
        "                \"feasibility_score\": 0.9,\n",
        "                \"evidence_details\": {\n",
        "                    \"study_period\": \"2020-2023\",\n",
        "                    \"sample_size\": \"ì „êµ­ 3,000ê°œêµ\",\n",
        "                    \"target_students\": \"ì €ì†Œë“ì¸µ í•™ìƒ 50ë§Œëª…\",\n",
        "                    \"academic_improvement\": \"ê¸°ì´ˆí•™ë ¥ ë¯¸ë‹¬ 12.3%p ê°ì†Œ\",\n",
        "                    \"dropout_reduction\": \"ì¤‘ë„íƒˆë½ë¥  2.1%p ê°ì†Œ\",\n",
        "                    \"mental_health\": \"ìƒë‹´ì„œë¹„ìŠ¤ ë§Œì¡±ë„ 91.5%\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "class UncertaintyAnalysis:\n",
        "    \"\"\"ì •ì±… íš¨ê³¼ ë¶ˆí™•ì‹¤ì„± ë¶„ì„\"\"\"\n",
        "\n",
        "    def __init__(self, confidence_level: float = 0.8):\n",
        "        self.confidence_level = confidence_level\n",
        "        self.uncertainty_factors = {\n",
        "            \"ê³µê¸°ì²­ì •ê¸°\": 0.15,\n",
        "            \"ê±´ë¬¼ê°œì„ \": 0.25,\n",
        "            \"ë…¹ì§€ì¡°ì„±\": 0.35,\n",
        "            \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 0.20,\n",
        "            \"ë³µì§€ì§€ì›\": 0.30\n",
        "        }\n",
        "\n",
        "    def apply_uncertainty_bounds(self, base_effect: float, policy_type: str) -> Tuple[float, float, float]:\n",
        "        \"\"\"ë¶ˆí™•ì‹¤ì„± êµ¬ê°„ ê³„ì‚°\"\"\"\n",
        "        try:\n",
        "            factor = self.uncertainty_factors.get(policy_type, 0.25)\n",
        "            z_score = 1.28 if self.confidence_level == 0.8 else 1.96\n",
        "            margin = base_effect * factor * z_score\n",
        "\n",
        "            return max(0, base_effect - margin), base_effect, min(1, base_effect + margin)\n",
        "        except Exception:\n",
        "            return 0, base_effect, 1\n",
        "\n",
        "class AdministrativeConstraints:\n",
        "    \"\"\"í–‰ì •ì  ì œì•½ì¡°ê±´ - ì™„ì „ ì•ˆì „ ì²˜ë¦¬ ë²„ì „\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.constraints = {\n",
        "            \"ì˜ˆì‚°ì œì•½\": {\n",
        "                \"ì—°ê°„í•œë„\": 50_000_000_000,\n",
        "                \"í•™êµë‹¹í•œë„\": 200_000_000,\n",
        "                \"ì§‘í–‰ê¸°ê°„\": 12\n",
        "            },\n",
        "            \"ë²•ì ì œì•½\": {\n",
        "                \"êµìœ¡í™˜ê²½ë³´í˜¸ë²•\": True,\n",
        "                \"í•™êµë³´ê±´ë²•\": True,\n",
        "                \"ê±´ì¶•ë²•\": True,\n",
        "                \"í™˜ê²½ì •ì±…ê¸°ë³¸ë²•\": True\n",
        "            },\n",
        "            \"í–‰ì •ì ˆì°¨\": {\n",
        "                \"ì˜íšŒìŠ¹ì¸ê¸°ê°„\": 2,\n",
        "                \"ì…ì°°ê³µê³ ê¸°ê°„\": 1,\n",
        "                \"ê³„ì•½ì²´ê²°ê¸°ê°„\": 1\n",
        "            }\n",
        "        }\n",
        "    def check_feasibility(self, policy_mix: Dict[str, float], target_schools: int) -> Dict[str, Any]:\n",
        "        \"\"\"ğŸ” ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ì •ì±… ì‹¤í–‰ê°€ëŠ¥ì„± ê²€í† \"\"\"\n",
        "\n",
        "        # ê¸°ë³¸ ë°˜í™˜ê°’ ì„¤ì •\n",
        "        default_result = {\n",
        "            \"feasibility_score\": 0.5,\n",
        "            \"total_cost\": 0,\n",
        "            \"total_time\": 6,\n",
        "            \"violations\": [],\n",
        "            \"admin_time\": 4,\n",
        "            \"validation_penalty\": 0,\n",
        "            \"weighted_feasibility\": 0.5\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # ğŸ†• ì •ì±… ìœ íš¨ì„± ì‚¬ì „ ê²€ì¦\n",
        "            is_valid, validation_msg, penalty = validate_policy_feasibility(policy_mix)\n",
        "            if not is_valid:\n",
        "                return {\n",
        "                    \"feasibility_score\": max(0, 0.5 - penalty/100),\n",
        "                    \"total_cost\": float('inf'),\n",
        "                    \"total_time\": float('inf'),\n",
        "                    \"violations\": [validation_msg],\n",
        "                    \"admin_time\": 0,\n",
        "                    \"validation_penalty\": penalty,\n",
        "                    \"weighted_feasibility\": 0\n",
        "                }\n",
        "\n",
        "            coeffs = EvidenceBasedCoefficients()\n",
        "            total_cost = 0\n",
        "            max_implementation_time = 0\n",
        "            weighted_feasibility = 0\n",
        "\n",
        "            for policy, allocation in policy_mix.items():\n",
        "                if allocation > 0 and policy in coeffs.policy_effectiveness:\n",
        "                    policy_data = coeffs.policy_effectiveness[policy]\n",
        "                    cost_per_school = policy_data.get(\"cost_per_school\", 50_000_000)\n",
        "                    impl_time = policy_data.get(\"implementation_time\", 3)\n",
        "                    feasibility = policy_data.get(\"feasibility_score\", 0.5)\n",
        "\n",
        "                    policy_cost = (cost_per_school * target_schools * allocation / 100)\n",
        "                    total_cost += policy_cost\n",
        "                    max_implementation_time = max(max_implementation_time, impl_time)\n",
        "                    weighted_feasibility += feasibility * (allocation / 100)\n",
        "\n",
        "            # í–‰ì •ì ˆì°¨ ì‹œê°„ ì¶”ê°€\n",
        "            admin_time = sum(self.constraints.get(\"í–‰ì •ì ˆì°¨\", {}).values())\n",
        "            total_time = max_implementation_time + admin_time\n",
        "\n",
        "            # ì‹¤í–‰ê°€ëŠ¥ì„± ì ìˆ˜ ê³„ì‚°\n",
        "            feasibility_score = weighted_feasibility\n",
        "            violations = []\n",
        "\n",
        "            # ì˜ˆì‚° ì œì•½ ê²€ì¦\n",
        "            budget_limit = self.constraints.get(\"ì˜ˆì‚°ì œì•½\", {}).get(\"ì—°ê°„í•œë„\", 50_000_000_000)\n",
        "            if total_cost > budget_limit:\n",
        "                excess_ratio = total_cost / budget_limit\n",
        "                feasibility_score *= max(0.1, 1 / excess_ratio)\n",
        "                violations.append(f\"ì—°ê°„ì˜ˆì‚°ì´ˆê³¼({excess_ratio:.1f}ë°°)\")\n",
        "\n",
        "            # ì‹œê°„ ì œì•½ ê²€ì¦\n",
        "            time_limit = self.constraints.get(\"ì˜ˆì‚°ì œì•½\", {}).get(\"ì§‘í–‰ê¸°ê°„\", 12)\n",
        "            if total_time > time_limit:\n",
        "                time_penalty = min(0.7, (total_time - time_limit) * 0.1)\n",
        "                feasibility_score *= (1 - time_penalty)\n",
        "                violations.append(f\"ì§‘í–‰ê¸°ê°„ì´ˆê³¼({total_time}ê°œì›”)\")\n",
        "\n",
        "            # ë³µì¡ì„± íŒ¨ë„í‹°\n",
        "            active_policies = sum(1 for v in policy_mix.values() if v > 5)\n",
        "            if active_policies > 4:\n",
        "                complexity_penalty = (active_policies - 4) * 0.1\n",
        "                feasibility_score *= (1 - complexity_penalty)\n",
        "                violations.append(f\"ì •ì±…ë³µì¡ì„±ê³¼ë„({active_policies}ê°œ)\")\n",
        "\n",
        "            return {\n",
        "                \"feasibility_score\": max(0, min(1, feasibility_score)),\n",
        "                \"total_cost\": total_cost,\n",
        "                \"total_time\": total_time,\n",
        "                \"violations\": violations,\n",
        "                \"admin_time\": admin_time,\n",
        "                \"validation_penalty\": 0,\n",
        "                \"weighted_feasibility\": weighted_feasibility\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸ ì‹¤í–‰ê°€ëŠ¥ì„± ê²€í†  ì˜¤ë¥˜: {e}\")\n",
        "            return default_result\n",
        "# =============================================================================\n",
        "# ğŸ†• ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ê°•í™”ëœ í´ë˜ìŠ¤ë“¤\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class EnhancedPolicyState:\n",
        "    risk_level: float\n",
        "    risk_level_uncertainty: Tuple[float, float]\n",
        "    budget_efficiency: float\n",
        "    equity_score: float\n",
        "    social_acceptance: float\n",
        "    schools_improved: int\n",
        "    total_investment: float\n",
        "    implementation_feasibility: float\n",
        "    evidence_quality: float\n",
        "    validation_score: float = 100.0\n",
        "\n",
        "class EnhancedTreeNode:\n",
        "    def __init__(self, state: EnhancedPolicyState, policy: Dict[str, float],\n",
        "                 score: float, depth: int, parent=None):\n",
        "        self.state = state\n",
        "        self.policy = policy\n",
        "        self.score = score\n",
        "        self.depth = depth\n",
        "        self.parent = parent\n",
        "        self.children = []\n",
        "        self.policy_description = \"\"\n",
        "        self.evaluation_details = {}\n",
        "        self.uncertainty_analysis = {}\n",
        "        self.evidence_trail = []\n",
        "        self.validation_result = None\n",
        "\n",
        "    def add_child(self, child):\n",
        "        self.children.append(child)\n",
        "        child.parent = self\n",
        "\n",
        "    def trace_path(self):\n",
        "        path = []\n",
        "        node = self\n",
        "        while node:\n",
        "            path.append(node)\n",
        "            node = node.parent\n",
        "        return path[::-1]\n",
        "\n",
        "    def get_evidence_chain(self) -> List[str]:\n",
        "        chain = []\n",
        "        node = self\n",
        "        while node:\n",
        "            if hasattr(node, 'evidence_trail') and node.evidence_trail:\n",
        "                chain.extend(node.evidence_trail)\n",
        "            node = node.parent\n",
        "        return list(set(chain))\n",
        "\n",
        "class EnhancedPolicyGenerator:\n",
        "    \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ê°•í™”ëœ ì •ì±… ìƒì„±ê¸°\"\"\"\n",
        "\n",
        "    def __init__(self, data_summary: Dict[str, Any]):\n",
        "        self.data_summary = data_summary or {}\n",
        "        self.coefficients = EvidenceBasedCoefficients()\n",
        "        self.constraints = AdministrativeConstraints()\n",
        "        self.evidence_templates = self._create_evidence_templates()\n",
        "        self.failed_policies = []\n",
        "\n",
        "    def _create_evidence_templates(self) -> Dict[str, Dict]:\n",
        "        \"\"\"ì‹¤ì¦ ê·¼ê±° ê¸°ë°˜ í˜„ì‹¤ì  ì •ì±… í…œí”Œë¦¿ ìƒì„±\"\"\"\n",
        "\n",
        "        templates = {}\n",
        "\n",
        "        avg_risk = self.data_summary.get('avg_risk', 55)\n",
        "        danger_schools = self.data_summary.get('danger_schools', 0)\n",
        "        total_schools = self.data_summary.get('total_schools', 100)\n",
        "\n",
        "        # 1. ê¸´ê¸‰ëŒ€ì‘í˜•\n",
        "        if avg_risk > 70 or danger_schools / total_schools > 0.3:\n",
        "            templates[\"ê¸´ê¸‰ëŒ€ì‘í˜•\"] = {\n",
        "                \"rationale\": f\"í‰ê·  í™˜ê²½ìœ„í—˜ë„ {avg_risk:.1f}, D/Eê¸‰ í•™êµ {danger_schools}ê°œë¡œ ê¸´ê¸‰ ê°œì… í•„ìš”\",\n",
        "                \"policy\": {\"ê³µê¸°ì²­ì •ê¸°\": 50, \"ê±´ë¬¼ê°œì„ \": 25, \"ë…¹ì§€ì¡°ì„±\": 0, \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 15, \"ë³µì§€ì§€ì›\": 10},\n",
        "                \"evidence\": [\"í™˜ê²½ë¶€ ì‹¤ë‚´ê³µê¸°ì§ˆ ê°œì„ ì‚¬ì—…: 1ê°œì›” ë‚´ 35% ê°œì„  íš¨ê³¼ ê²€ì¦\"],\n",
        "                \"expected_cost\": self._calculate_realistic_cost({\"ê³µê¸°ì²­ì •ê¸°\": 50, \"ê±´ë¬¼ê°œì„ \": 25, \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 15, \"ë³µì§€ì§€ì›\": 10}),\n",
        "                \"timeline\": \"3ê°œì›” ë‚´ ê°€ì‹œì  íš¨ê³¼\"\n",
        "            }\n",
        "\n",
        "        # 2. íš¨ìœ¨ì„±ì¤‘ì‹¬í˜•\n",
        "        templates[\"íš¨ìœ¨ì„±ì¤‘ì‹¬í˜•\"] = {\n",
        "            \"rationale\": \"ì˜ˆì‚° ëŒ€ë¹„ íš¨ê³¼ ìµœëŒ€í™” ì „ëµ (ë¹„ìš©íš¨ê³¼ë¹„ ë¶„ì„ ê¸°ë°˜)\",\n",
        "            \"policy\": {\"ê³µê¸°ì²­ì •ê¸°\": 40, \"ê±´ë¬¼ê°œì„ \": 0, \"ë…¹ì§€ì¡°ì„±\": 15, \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 25, \"ë³µì§€ì§€ì›\": 20},\n",
        "            \"evidence\": [\n",
        "                \"ê³µê¸°ì²­ì •ê¸°: 1,500ë§Œì›ìœ¼ë¡œ 35% ê°œì„ \",\n",
        "                \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§: 3,000ë§Œì›ìœ¼ë¡œ 90% ì •í™•ë„\",\n",
        "                \"ë³µì§€ì§€ì›: 2,000ë§Œì›ìœ¼ë¡œ 40% ë§Œì¡±ë„ í–¥ìƒ\"\n",
        "            ],\n",
        "            \"expected_cost\": self._calculate_realistic_cost({\"ê³µê¸°ì²­ì •ê¸°\": 40, \"ë…¹ì§€ì¡°ì„±\": 15, \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 25, \"ë³µì§€ì§€ì›\": 20}),\n",
        "            \"timeline\": \"2ê°œì›” ë‚´ íš¨ê³¼ ê°€ì‹œí™”\"\n",
        "        }\n",
        "\n",
        "        # 3. ê· í˜•ë°œì „í˜•\n",
        "        templates[\"ê· í˜•ë°œì „í˜•\"] = {\n",
        "            \"rationale\": \"êµìœ¡ê²©ì°¨ í•´ì†Œ ë° ì‚¬íšŒì  í˜•í‰ì„± í™•ë³´\",\n",
        "            \"policy\": {\"ê³µê¸°ì²­ì •ê¸°\": 25, \"ê±´ë¬¼ê°œì„ \": 20, \"ë…¹ì§€ì¡°ì„±\": 20, \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 15, \"ë³µì§€ì§€ì›\": 20},\n",
        "            \"evidence\": [\n",
        "                \"êµìœ¡ë³µì§€ì‚¬ì—…: 3ë…„ê°„ 3,000ê°œêµ ëŒ€ìƒ íš¨ê³¼ ê²€ì¦\",\n",
        "                \"ê·¸ë¦°ìŠ¤ë§ˆíŠ¸ì‚¬ì—…: 2,835ê°œêµ í‰ê·  1.3ë“±ê¸‰ ì•ˆì „ë„ í–¥ìƒ\",\n",
        "                \"í•™êµìˆ²ì‚¬ì—…: 127ê°œêµ 15.2% ê³µê¸°ì§ˆ ê°œì„ \"\n",
        "            ],\n",
        "            \"expected_cost\": self._calculate_realistic_cost({\"ê³µê¸°ì²­ì •ê¸°\": 25, \"ê±´ë¬¼ê°œì„ \": 20, \"ë…¹ì§€ì¡°ì„±\": 20, \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 15, \"ë³µì§€ì§€ì›\": 20}),\n",
        "            \"timeline\": \"8ê°œì›” ë‚´ ì¢…í•© ê°œì„ \"\n",
        "        }\n",
        "\n",
        "        # 4. ì§€ì†ê°€ëŠ¥í˜•\n",
        "        templates[\"ì§€ì†ê°€ëŠ¥í˜•\"] = {\n",
        "            \"rationale\": \"ì¥ê¸°ì  êµìœ¡í™˜ê²½ ê°œì„  ë° ìœ ì§€ê´€ë¦¬ ì²´ê³„ êµ¬ì¶•\",\n",
        "            \"policy\": {\"ê³µê¸°ì²­ì •ê¸°\": 20, \"ê±´ë¬¼ê°œì„ \": 35, \"ë…¹ì§€ì¡°ì„±\": 25, \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 20, \"ë³µì§€ì§€ì›\": 0},\n",
        "            \"evidence\": [\n",
        "                \"ê±´ë¬¼ê°œì„ : 30% ì—ë„ˆì§€ íš¨ìœ¨ í–¥ìƒìœ¼ë¡œ ì¥ê¸° ìš´ì˜ë¹„ ì ˆê°\",\n",
        "                \"ë…¹ì§€ì¡°ì„±: ì—°ê°„ 2.3â„ƒ ì˜¨ë„ ì €ê° íš¨ê³¼ ì§€ì†\",\n",
        "                \"IoTëª¨ë‹ˆí„°ë§: ìœ ì§€ë³´ìˆ˜ë¹„ 40% ì ˆê° íš¨ê³¼\"\n",
        "            ],\n",
        "            \"expected_cost\": self._calculate_realistic_cost({\"ê³µê¸°ì²­ì •ê¸°\": 20, \"ê±´ë¬¼ê°œì„ \": 35, \"ë…¹ì§€ì¡°ì„±\": 25, \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 20}),\n",
        "            \"timeline\": \"12ê°œì›” êµ¬ì¶•, 5ë…„ ìš´ì˜\"\n",
        "        }\n",
        "\n",
        "        return templates\n",
        "\n",
        "    def _calculate_realistic_cost(self, policy: Dict[str, float]) -> float:\n",
        "        \"\"\"í˜„ì‹¤ì  ë¹„ìš© ê³„ì‚°\"\"\"\n",
        "        try:\n",
        "            total_cost = 0\n",
        "            target_schools = self.data_summary.get('danger_schools', 50)\n",
        "\n",
        "            for policy_type, allocation in policy.items():\n",
        "                if allocation > 0 and policy_type in self.coefficients.policy_effectiveness:\n",
        "                    cost_per_school = self.coefficients.policy_effectiveness[policy_type].get('cost_per_school', 50_000_000)\n",
        "                    total_cost += cost_per_school * target_schools * (allocation / 100)\n",
        "\n",
        "            return total_cost\n",
        "        except Exception:\n",
        "            return 100_000_000  # ê¸°ë³¸ê°’\n",
        "\n",
        "    def generate_policy_branches(self, current_state: EnhancedPolicyState, n_branches: int = 6) -> List[Dict[str, Any]]:\n",
        "        \"\"\"ğŸŒ³ ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ì •ì±… ë¶„ê¸° ìƒì„±\"\"\"\n",
        "\n",
        "        branches = []\n",
        "        template_names = list(self.evidence_templates.keys())\n",
        "        valid_branches = 0\n",
        "        attempts = 0\n",
        "        max_attempts = n_branches * 3\n",
        "\n",
        "        while valid_branches < n_branches and attempts < max_attempts:\n",
        "            attempts += 1\n",
        "\n",
        "            try:\n",
        "                if valid_branches < len(template_names):\n",
        "                    template_name = template_names[valid_branches]\n",
        "                    template = self.evidence_templates[template_name]\n",
        "                    policy = template[\"policy\"].copy()\n",
        "                else:\n",
        "                    base_template = self.evidence_templates[template_names[valid_branches % len(template_names)]]\n",
        "                    template_name = f\"ë³€í˜•_{template_names[valid_branches % len(template_names)]}_{valid_branches}\"\n",
        "                    policy = self._create_validated_variant_policy(base_template[\"policy\"])\n",
        "                    template = {\n",
        "                        \"rationale\": f\"{base_template['rationale']} (ë°ì´í„° ê¸°ë°˜ ì¡°ì •)\",\n",
        "                        \"evidence\": base_template.get(\"evidence\", []),\n",
        "                        \"timeline\": base_template.get(\"timeline\", \"6ê°œì›”\")\n",
        "                    }\n",
        "\n",
        "                # ì •ì±… ìœ íš¨ì„± ì‚¬ì „ ê²€ì¦\n",
        "                is_valid, validation_msg, penalty = validate_policy_feasibility(policy)\n",
        "                if not is_valid:\n",
        "                    self.failed_policies.append({\n",
        "                        'policy': policy,\n",
        "                        'reason': validation_msg,\n",
        "                        'penalty': penalty,\n",
        "                        'attempt': attempts\n",
        "                    })\n",
        "                    print(f\"   âŒ ì •ì±… {attempts} ì‹¤íŒ¨: {validation_msg}\")\n",
        "                    continue\n",
        "\n",
        "                # ì‹¤í–‰ê°€ëŠ¥ì„± ê²€í†  (ì™„ì „ ì•ˆì „ ì²˜ë¦¬)\n",
        "                target_schools = self.data_summary.get('danger_schools', 50) if template_name == \"ê¸´ê¸‰ëŒ€ì‘í˜•\" else 100\n",
        "\n",
        "                feasibility = self.constraints.check_feasibility(policy, target_schools)\n",
        "\n",
        "                # ì‹¤í–‰ê°€ëŠ¥ì„± ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì œì™¸\n",
        "                feasibility_score = feasibility.get('feasibility_score', 0.5)\n",
        "                if feasibility_score < 0.3:\n",
        "                    print(f\"   âš ï¸ ì •ì±… {attempts} ì‹¤í–‰ê°€ëŠ¥ì„± ë‚®ìŒ: {feasibility_score:.2f}\")\n",
        "                    continue\n",
        "\n",
        "                branches.append({\n",
        "                    'policy': policy,\n",
        "                    'template_name': template_name,\n",
        "                    'rationale': template.get(\"rationale\", \"ì •ì±… ì„¤ëª…\"),\n",
        "                    'evidence': template.get(\"evidence\", []),\n",
        "                    'timeline': template.get(\"timeline\", \"6ê°œì›”\"),\n",
        "                    'feasibility': feasibility,\n",
        "                    'expected_cost': template.get(\"expected_cost\", 0),\n",
        "                    'description': self._generate_policy_description(template_name, template),\n",
        "                    'validation_result': {'valid': True, 'message': validation_msg, 'penalty': penalty}\n",
        "                })\n",
        "\n",
        "                valid_branches += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   âš ï¸ ì •ì±… ìƒì„± ì˜¤ë¥˜ {attempts}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"   âœ… ìœ íš¨í•œ ì •ì±… ë¶„ê¸° {valid_branches}ê°œ ìƒì„± (ì´ {attempts}íšŒ ì‹œë„, {len(self.failed_policies)}ê°œ ì‹¤íŒ¨)\")\n",
        "\n",
        "        # ìµœì†Œí•œ í•˜ë‚˜ì˜ ë¶„ê¸°ëŠ” ë°˜í™˜\n",
        "        if not branches:\n",
        "            print(\"   ğŸš¨ ê¸´ê¸‰: ê¸°ë³¸ ì •ì±… ë¶„ê¸° ìƒì„±\")\n",
        "            default_policy = {\"ê³µê¸°ì²­ì •ê¸°\": 30, \"ê±´ë¬¼ê°œì„ \": 20, \"ë…¹ì§€ì¡°ì„±\": 20, \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 15, \"ë³µì§€ì§€ì›\": 15}\n",
        "            branches.append({\n",
        "                'policy': default_policy,\n",
        "                'template_name': 'ê¸°ë³¸ì •ì±…',\n",
        "                'rationale': 'ê¸°ë³¸ ì•ˆì „ ì •ì±…',\n",
        "                'evidence': ['ê¸°ë³¸ ì •ì±… í…œí”Œë¦¿'],\n",
        "                'timeline': '6ê°œì›”',\n",
        "                'feasibility': self.constraints.check_feasibility(default_policy, 50),\n",
        "                'expected_cost': 100_000_000,\n",
        "                'description': 'ê¸°ë³¸ ì•ˆì „ ì •ì±…',\n",
        "                'validation_result': {'valid': True, 'message': 'ê¸°ë³¸ì •ì±…', 'penalty': 0}\n",
        "            })\n",
        "\n",
        "        return branches\n",
        "\n",
        "    def _create_validated_variant_policy(self, base_policy: Dict[str, float]) -> Dict[str, float]:\n",
        "        \"\"\"ê²€ì¦ëœ ì •ì±… ë³€í˜• ìƒì„±\"\"\"\n",
        "\n",
        "        max_attempts = 5\n",
        "        for attempt in range(max_attempts):\n",
        "            try:\n",
        "                variant = base_policy.copy()\n",
        "\n",
        "                # ë³´ìˆ˜ì  ì¡°ì • (Â±5% ë²”ìœ„)\n",
        "                for key in variant:\n",
        "                    if variant[key] > 0:\n",
        "                        adjustment = np.random.uniform(-0.05, 0.05) * variant[key]\n",
        "                        variant[key] = max(0, variant[key] + adjustment)\n",
        "\n",
        "                # í•©ê³„ë¥¼ 100%ë¡œ ì •ê·œí™”\n",
        "                total = sum(variant.values())\n",
        "                if total > 0:\n",
        "                    factor = 100 / total\n",
        "                    variant = {k: round(v * factor, 1) for k, v in variant.items()}\n",
        "\n",
        "                # ìœ íš¨ì„± ê²€ì¦\n",
        "                is_valid, _, _ = validate_policy_feasibility(variant)\n",
        "                if is_valid:\n",
        "                    return variant\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì •ì±… ë°˜í™˜\n",
        "        return base_policy\n",
        "\n",
        "    def _generate_policy_description(self, template_name: str, template: Dict) -> str:\n",
        "        \"\"\"ì •ì±… ì„¤ëª… ìƒì„±\"\"\"\n",
        "        try:\n",
        "            description = template.get('rationale', 'ì •ì±… ì„¤ëª…')\n",
        "\n",
        "            policy = template.get('policy', {})\n",
        "            if policy:\n",
        "                major_components = [k for k, v in policy.items() if v >= 15]\n",
        "                if major_components:\n",
        "                    component_names = {\n",
        "                        \"ê³µê¸°ì²­ì •ê¸°\": \"ê³µê¸°ì§ˆê°œì„ \", \"ê±´ë¬¼ê°œì„ \": \"ì‹œì„¤í˜„ëŒ€í™”\",\n",
        "                        \"ë…¹ì§€ì¡°ì„±\": \"ì¹œí™˜ê²½ì¡°ì„±\", \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": \"ì§€ëŠ¥í˜•ê´€ë¦¬\",\n",
        "                        \"ë³µì§€ì§€ì›\": \"êµìœ¡ë³µì§€\"\n",
        "                    }\n",
        "                    major_desc = \"+\".join([component_names.get(comp, comp) for comp in major_components])\n",
        "                    description += f\" ({major_desc} ì¤‘ì‹¬)\"\n",
        "\n",
        "            return description\n",
        "        except Exception:\n",
        "            return f\"{template_name} ì •ì±…\"\n",
        "\n",
        "class EnhancedPolicyEvaluator:\n",
        "    \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ê°•í™”ëœ ì •ì±… í‰ê°€ê¸°\"\"\"\n",
        "\n",
        "    def __init__(self, data_summary: Dict[str, Any]):\n",
        "        self.data_summary = data_summary or {}\n",
        "        self.coefficients = EvidenceBasedCoefficients()\n",
        "        self.uncertainty = UncertaintyAnalysis()\n",
        "        self.constraints = AdministrativeConstraints()\n",
        "\n",
        "        self.evaluation_weights = {\n",
        "            'environmental_impact': 0.25,\n",
        "            'budget_efficiency': 0.25,\n",
        "            'implementation_feasibility': 0.25,  # ì´ ë¼ì¸ì„ ìˆ˜ì •\n",
        "            'equity': 0.15,\n",
        "            'social_acceptance': 0.10\n",
        "        }\n",
        "\n",
        "        # ì•ˆì „í•œ í˜•í‰ì„± í‰ê°€ê¸° ì´ˆê¸°í™”\n",
        "        try:\n",
        "            region_type = self._determine_region_type()\n",
        "            if 'budget_baselines' in data_summary:\n",
        "                self.equity_evaluator = EnhancedRealityBasedEquityEvaluator(\n",
        "                    data_summary['budget_baselines'], region_type\n",
        "                )\n",
        "            else:\n",
        "                self.equity_evaluator = None\n",
        "        except Exception:\n",
        "            self.equity_evaluator = None\n",
        "\n",
        "    def _determine_region_type(self) -> str:\n",
        "        \"\"\"ë°ì´í„° ê¸°ë°˜ ì§€ì—­ ìœ í˜• íŒì •\"\"\"\n",
        "        return 'ì¼ë°˜ì§€ì—­'\n",
        "\n",
        "    def evaluate_policy(self, current_state: EnhancedPolicyState, policy: Dict[str, float],\n",
        "                       branch_info: Dict[str, Any] = None) -> Dict[str, Any]:\n",
        "        \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ì¢…í•© ì •ì±… í‰ê°€\"\"\"\n",
        "\n",
        "        try:\n",
        "            # ì‚¬ì „ ìœ íš¨ì„± ê²€ì¦\n",
        "            validation_score = 100\n",
        "            if branch_info and 'validation_result' in branch_info:\n",
        "                validation_result = branch_info['validation_result']\n",
        "                if not validation_result.get('valid', True):\n",
        "                    validation_score = max(0, 100 - validation_result.get('penalty', 50))\n",
        "\n",
        "            # ë¹„ì„ í˜• íŒ¨ë„í‹° ì ìš©\n",
        "            nonlinear_penalty = apply_nonlinear_penalties(policy)\n",
        "\n",
        "            # ê° í‰ê°€ ì°¨ì›ë³„ ì ìˆ˜ ê³„ì‚° (ì•ˆì „í•˜ê²Œ)\n",
        "            env_impact = self._evaluate_environmental_impact_safe(current_state, policy)\n",
        "            budget_eff = self._evaluate_budget_efficiency_safe(current_state, policy, branch_info)\n",
        "            feasibility = self._evaluate_implementation_feasibility_safe(policy, branch_info)  # ì´ ë³€ìˆ˜ëª…ì€ ê·¸ëŒ€ë¡œ\n",
        "            equity = self._evaluate_equity_safe(policy)\n",
        "            social_acceptance = self._evaluate_social_acceptance_safe(policy)\n",
        "\n",
        "            # íŒ¨ë„í‹° ì ìš©ëœ ìƒì„¸ ì ìˆ˜ - ì—¬ê¸°ê°€ ë¬¸ì œ!\n",
        "            detailed_scores = {\n",
        "                'environmental_impact': max(0, env_impact - nonlinear_penalty * 0.3),\n",
        "                'budget_efficiency': max(0, budget_eff - nonlinear_penalty * 0.2),\n",
        "                'implementation_feasibility': max(0, feasibility - nonlinear_penalty * 0.2),  # í‚¤ ì´ë¦„ ìˆ˜ì •\n",
        "                'equity': max(0, equity - nonlinear_penalty * 0.2),\n",
        "                'social_acceptance': max(0, social_acceptance - nonlinear_penalty * 0.1),\n",
        "                'validation_score': validation_score,\n",
        "                'nonlinear_penalty': nonlinear_penalty\n",
        "            }\n",
        "\n",
        "            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì¢…í•© ì ìˆ˜ ê³„ì‚° - ì—¬ê¸°ë„ ìˆ˜ì • í•„ìš”!\n",
        "            base_total_score = sum(score * weight for score, weight in\n",
        "                                  zip([detailed_scores[key] for key in self.evaluation_weights.keys()],\n",
        "                                      self.evaluation_weights.values()))\n",
        "\n",
        "            # ìµœì¢… ì ìˆ˜ (ê²€ì¦ ì ìˆ˜ì™€ íŒ¨ë„í‹° ë°˜ì˜)\n",
        "            total_score = base_total_score * (validation_score / 100) - nonlinear_penalty\n",
        "            total_score = max(0, min(100, total_score))\n",
        "\n",
        "            # ë‹¤ìŒ ìƒíƒœ ê³„ì‚°\n",
        "            next_state = self._calculate_next_state_safe(current_state, policy, detailed_scores)\n",
        "            next_state.validation_score = validation_score\n",
        "\n",
        "            # ê·¼ê±° ì¶”ì  ì •ë³´\n",
        "            evidence_trail = self._compile_evidence_trail_safe(policy, branch_info, detailed_scores)\n",
        "\n",
        "            return {\n",
        "                'next_state': next_state,\n",
        "                'total_score': total_score,\n",
        "                'detailed_scores': detailed_scores,\n",
        "                'evidence_trail': evidence_trail,\n",
        "                'confidence_level': 0.8,\n",
        "                'validation_result': branch_info.get('validation_result') if branch_info else None\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸ ì •ì±… í‰ê°€ ì˜¤ë¥˜: {e}\")\n",
        "            # ê¸°ë³¸ ë°˜í™˜ê°’\n",
        "            default_state = EnhancedPolicyState(\n",
        "                risk_level=current_state.risk_level,\n",
        "                risk_level_uncertainty=(current_state.risk_level * 0.9, current_state.risk_level * 1.1),\n",
        "                budget_efficiency=50.0,\n",
        "                equity_score=50.0,\n",
        "                social_acceptance=50.0,\n",
        "                schools_improved=0,\n",
        "                total_investment=0,\n",
        "                implementation_feasibility=50.0,\n",
        "                evidence_quality=50.0,\n",
        "                validation_score=50.0\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'next_state': default_state,\n",
        "                'total_score': 50.0,\n",
        "                'detailed_scores': {\n",
        "                    'environmental_impact': 50.0,\n",
        "                    'budget_efficiency': 50.0,\n",
        "                    'implementation_feasibility': 50.0,\n",
        "                    'equity': 50.0,\n",
        "                    'social_acceptance': 50.0,\n",
        "                    'validation_score': 50.0,\n",
        "                    'nonlinear_penalty': 0\n",
        "                },\n",
        "                'evidence_trail': ['í‰ê°€ ì˜¤ë¥˜ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©'],\n",
        "                'confidence_level': 0.5,\n",
        "                'validation_result': None\n",
        "            }\n",
        "\n",
        "    def _evaluate_environmental_impact_safe(self, state: EnhancedPolicyState, policy: Dict[str, float]) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ í™˜ê²½ê°œì„ íš¨ê³¼ í‰ê°€\"\"\"\n",
        "        try:\n",
        "            total_improvement = 0\n",
        "\n",
        "            for policy_type, allocation in policy.items():\n",
        "                if allocation > 0 and policy_type in self.coefficients.policy_effectiveness:\n",
        "                    policy_data = self.coefficients.policy_effectiveness[policy_type]\n",
        "\n",
        "                    if policy_type == \"ê³µê¸°ì²­ì •ê¸°\":\n",
        "                        improvement = policy_data.get(\"pm25_reduction\", 0.35) * (allocation / 100)\n",
        "                    elif policy_type == \"ê±´ë¬¼ê°œì„ \":\n",
        "                        improvement = policy_data.get(\"overall_safety_improvement\", 0.65) * (allocation / 100)\n",
        "                    elif policy_type == \"ë…¹ì§€ì¡°ì„±\":\n",
        "                        improvement = policy_data.get(\"air_quality_improvement\", 0.15) * (allocation / 100)\n",
        "                    elif policy_type == \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\":\n",
        "                        improvement = policy_data.get(\"detection_accuracy\", 0.90) * 0.3 * (allocation / 100)\n",
        "                    elif policy_type == \"ë³µì§€ì§€ì›\":\n",
        "                        improvement = 0.05 * (allocation / 100)\n",
        "                    else:\n",
        "                        improvement = 0\n",
        "\n",
        "                    total_improvement += improvement\n",
        "\n",
        "            # í˜„ì¬ ìœ„í—˜ë„ì— ë”°ë¥¸ ê°œì„  ì ì¬ë ¥ ì¡°ì •\n",
        "            improvement_potential = min(1.0, (state.risk_level / 100) ** 0.8)\n",
        "\n",
        "            # ì‹œë„ˆì§€ íš¨ê³¼ ê³ ë ¤\n",
        "            active_policies = sum(1 for v in policy.values() if v >= 10)\n",
        "            synergy_bonus = min(0.1, (active_policies - 1) * 0.03) if active_policies >= 2 else 0\n",
        "\n",
        "            final_score = min(100, (total_improvement + synergy_bonus) * improvement_potential * 100)\n",
        "            return final_score\n",
        "\n",
        "        except Exception:\n",
        "            return 50.0\n",
        "\n",
        "    def _evaluate_budget_efficiency_safe(self, state: EnhancedPolicyState, policy: Dict[str, float],\n",
        "                                       branch_info: Dict[str, Any] = None) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ ì˜ˆì‚°íš¨ìœ¨ì„± í‰ê°€\"\"\"\n",
        "        try:\n",
        "            if not branch_info or 'expected_cost' not in branch_info:\n",
        "                # ê¸°ë³¸ íš¨ìœ¨ì„± ì ìˆ˜\n",
        "                efficiency_scores = {\n",
        "                    \"ê³µê¸°ì²­ì •ê¸°\": 0.9,\n",
        "                    \"ë³µì§€ì§€ì›\": 0.85,\n",
        "                    \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 0.7,\n",
        "                    \"ë…¹ì§€ì¡°ì„±\": 0.5,\n",
        "                    \"ê±´ë¬¼ê°œì„ \": 0.4\n",
        "                }\n",
        "\n",
        "                total_allocation = sum(policy.values())\n",
        "                if total_allocation > 0:\n",
        "                    weighted_efficiency = sum(policy.get(k, 0) * efficiency_scores.get(k, 0.5)\n",
        "                                            for k in policy.keys()) / total_allocation\n",
        "                else:\n",
        "                    weighted_efficiency = 0.5\n",
        "\n",
        "                # ì •ì±… ì§‘ì¤‘ë„ íŒ¨ë„í‹°\n",
        "                max_allocation = max(policy.values()) if policy.values() else 0\n",
        "                concentration_penalty = max(0, (max_allocation - 60) * 0.5) if max_allocation > 60 else 0\n",
        "\n",
        "                return max(0, min(100, weighted_efficiency * 100 - concentration_penalty))\n",
        "\n",
        "            # ì‹¤ì œ ë¹„ìš© ê¸°ë°˜ íš¨ìœ¨ì„± ê³„ì‚°\n",
        "            total_cost = branch_info.get('expected_cost', 0)\n",
        "            target_schools = self.data_summary.get('danger_schools', 50)\n",
        "\n",
        "            if target_schools > 0 and total_cost > 0:\n",
        "                cost_per_school = total_cost / target_schools\n",
        "\n",
        "                # ë¹„ìš© íš¨ìœ¨ì„± ê¸°ì¤€\n",
        "                if cost_per_school <= 30_000_000:\n",
        "                    return 95\n",
        "                elif cost_per_school <= 50_000_000:\n",
        "                    return 85\n",
        "                elif cost_per_school <= 80_000_000:\n",
        "                    return 70\n",
        "                elif cost_per_school <= 120_000_000:\n",
        "                    return 55\n",
        "                elif cost_per_school <= 200_000_000:\n",
        "                    return 35\n",
        "                else:\n",
        "                    return 15\n",
        "\n",
        "            return 50\n",
        "\n",
        "        except Exception:\n",
        "            return 50.0\n",
        "\n",
        "    def _evaluate_implementation_feasibility_safe(self, policy: Dict[str, float],\n",
        "                                                branch_info: Dict[str, Any] = None) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ ì‹¤í–‰ê°€ëŠ¥ì„± í‰ê°€\"\"\"\n",
        "        try:\n",
        "            base_score = 50\n",
        "\n",
        "            if branch_info and 'feasibility' in branch_info:\n",
        "                feasibility_data = branch_info['feasibility']\n",
        "                base_score = feasibility_data.get('feasibility_score', 0.5) * 100\n",
        "\n",
        "                # ì‹œê°„ ì ìˆ˜\n",
        "                time_score = 100\n",
        "                total_time = feasibility_data.get('total_time', 6)\n",
        "                if total_time > 12:\n",
        "                    time_penalty = min(70, (total_time - 12) * 15)\n",
        "                    time_score = max(10, 100 - time_penalty)\n",
        "\n",
        "                # ë³µì¡ì„± ì ìˆ˜\n",
        "                complexity_score = 100\n",
        "                active_policies = sum(1 for v in policy.values() if v > 5)\n",
        "                if active_policies > 4:\n",
        "                    complexity_penalty = (active_policies - 4) * 20\n",
        "                    complexity_score = max(20, 100 - complexity_penalty)\n",
        "\n",
        "                # ì˜ˆì‚° í˜„ì‹¤ì„± ì ìˆ˜\n",
        "                budget_realism_score = 100\n",
        "                violations = feasibility_data.get('violations', [])\n",
        "                if violations:\n",
        "                    violation_penalty = len(violations) * 25\n",
        "                    budget_realism_score = max(0, 100 - violation_penalty)\n",
        "\n",
        "                final_score = (base_score * 0.4 + time_score * 0.25 + complexity_score * 0.2 + budget_realism_score * 0.15)\n",
        "                return min(100, final_score)\n",
        "                        # ê¸°ë³¸ ì‹¤í–‰ê°€ëŠ¥ì„± í‰ê°€\n",
        "            implementation_difficulty = {\n",
        "                \"ê³µê¸°ì²­ì •ê¸°\": 0.9,\n",
        "                \"ë³µì§€ì§€ì›\": 0.85,\n",
        "                \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 0.6,\n",
        "                \"ë…¹ì§€ì¡°ì„±\": 0.5,\n",
        "                \"ê±´ë¬¼ê°œì„ \": 0.2\n",
        "            }\n",
        "\n",
        "            total_allocation = sum(policy.values())\n",
        "            if total_allocation > 0:\n",
        "                avg_feasibility = sum(policy.get(k, 0) * implementation_difficulty.get(k, 0.3)\n",
        "                                     for k in policy.keys()) / total_allocation\n",
        "            else:\n",
        "                avg_feasibility = 0.3\n",
        "\n",
        "            return min(100, avg_feasibility * 100)\n",
        "        except Exception:\n",
        "            return 50.0\n",
        "\n",
        "    def _evaluate_equity_safe(self, policy: Dict[str, float]) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ í˜•í‰ì„± í‰ê°€\"\"\"\n",
        "        try:\n",
        "            if self.equity_evaluator:\n",
        "                return self.equity_evaluator.evaluate_policy_equity(policy)\n",
        "\n",
        "            # ê¸°ë³¸ í˜•í‰ì„± í‰ê°€\n",
        "            values = [v for v in policy.values() if v > 0]\n",
        "            if len(values) < 2:\n",
        "                return 25\n",
        "\n",
        "            # ì§€ë‹ˆê³„ìˆ˜ ê¸°ë°˜ ë¶ˆí‰ë“± ì¸¡ì •\n",
        "            sorted_values = sorted(values)\n",
        "            n = len(sorted_values)\n",
        "\n",
        "            if sum(sorted_values) > 0:\n",
        "                cumsum = np.cumsum(sorted_values)\n",
        "                gini = (2 * np.sum((np.arange(1, n + 1) * sorted_values))) / (n * cumsum[-1]) - (n + 1) / n\n",
        "\n",
        "                # ì ì ˆí•œ ë¶ˆí‰ë“± ìˆ˜ì¤€ì—ì„œ ë†’ì€ ì ìˆ˜\n",
        "                if 0.15 <= gini <= 0.35:\n",
        "                    proximity_to_optimal = 1 - abs(gini - 0.25) / 0.1\n",
        "                    return 70 + proximity_to_optimal * 30\n",
        "                elif gini < 0.15:\n",
        "                    return max(30, 70 - (0.15 - gini) * 200)\n",
        "                else:\n",
        "                    return max(10, 70 - (gini - 0.35) * 150)\n",
        "\n",
        "            return 40\n",
        "\n",
        "        except Exception:\n",
        "            return 50.0\n",
        "\n",
        "    def _evaluate_social_acceptance_safe(self, policy: Dict[str, float]) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ ì‚¬íšŒìˆ˜ìš©ì„± í‰ê°€\"\"\"\n",
        "        try:\n",
        "            # ì‚¬íšŒì  ì„ í˜¸ë„\n",
        "            social_preferences = {\n",
        "                \"ë³µì§€ì§€ì›\": 0.90,\n",
        "                \"ê³µê¸°ì²­ì •ê¸°\": 0.85,\n",
        "                \"ë…¹ì§€ì¡°ì„±\": 0.75,\n",
        "                \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 0.55,\n",
        "                \"ê±´ë¬¼ê°œì„ \": 0.60\n",
        "            }\n",
        "\n",
        "            total_allocation = sum(policy.values())\n",
        "            if total_allocation == 0:\n",
        "                return 30\n",
        "\n",
        "            # ê°€ì¤‘í‰ê·  ê³„ì‚°\n",
        "            total_preference = sum(policy.get(k, 0) * social_preferences.get(k, 0.4)\n",
        "                                  for k in policy.keys()) / total_allocation\n",
        "\n",
        "            # ì •ì±… ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤\n",
        "            active_policies = sum(1 for v in policy.values() if v >= 8)\n",
        "            if active_policies >= 3:\n",
        "                diversity_bonus = min(20, (active_policies - 2) * 5)\n",
        "            else:\n",
        "                diversity_bonus = 0\n",
        "\n",
        "            # ê·¹ë‹¨ì  ì§‘ì¤‘ íŒ¨ë„í‹°\n",
        "            max_allocation = max(policy.values()) if policy.values() else 0\n",
        "            if max_allocation > 70:\n",
        "                concentration_penalty = (max_allocation - 70) * 1.5\n",
        "            elif max_allocation > 50:\n",
        "                concentration_penalty = (max_allocation - 50) * 0.8\n",
        "            else:\n",
        "                concentration_penalty = 0\n",
        "\n",
        "            final_score = (total_preference * 80) + diversity_bonus - concentration_penalty\n",
        "            return max(10, min(100, final_score))\n",
        "\n",
        "        except Exception:\n",
        "            return 50.0\n",
        "\n",
        "    def _calculate_next_state_safe(self, current: EnhancedPolicyState, policy: Dict[str, float],\n",
        "                                 scores: Dict[str, float]) -> EnhancedPolicyState:\n",
        "        \"\"\"ì•ˆì „í•œ ë‹¤ìŒ ìƒíƒœ ê³„ì‚°\"\"\"\n",
        "        try:\n",
        "            # ê²€ì¦ ì ìˆ˜ì— ë”°ë¥¸ íš¨ê³¼ ì¡°ì •\n",
        "            validation_factor = scores.get('validation_score', 100) / 100\n",
        "\n",
        "            # í™˜ê²½ìœ„í—˜ë„ ê°œì„ \n",
        "            base_env_improvement = (scores.get('environmental_impact', 0) / 100) * 25\n",
        "            env_improvement = base_env_improvement * validation_factor\n",
        "            next_risk = max(0, current.risk_level - env_improvement)\n",
        "\n",
        "            # ì˜ˆì‚°íš¨ìœ¨ì„± ê°œì„ \n",
        "            budget_improvement = (scores.get('budget_efficiency', 0) / 100) * 20 * validation_factor\n",
        "            next_budget_eff = min(100, current.budget_efficiency + budget_improvement)\n",
        "\n",
        "            # í˜•í‰ì„± ê°œì„ \n",
        "            equity_improvement = (scores.get('equity', 0) / 100) * 15 * validation_factor\n",
        "            next_equity = min(100, current.equity_score + equity_improvement)\n",
        "\n",
        "            # ì‚¬íšŒìˆ˜ìš©ì„± ê°œì„ \n",
        "            social_improvement = (scores.get('social_acceptance', 0) / 100) * 10 * validation_factor\n",
        "            next_social = min(100, current.social_acceptance + social_improvement)\n",
        "\n",
        "            # ê°œì„  í•™êµ ìˆ˜ ê³„ì‚°\n",
        "            total_schools = self.data_summary.get('total_schools', 100)\n",
        "            improvement_rate = env_improvement / 100\n",
        "            application_rate = 0.25 * validation_factor\n",
        "            schools_improved = int(total_schools * improvement_rate * application_rate)\n",
        "\n",
        "            # íˆ¬ìì•¡ ê³„ì‚°\n",
        "            total_investment = 0\n",
        "            for policy_type, allocation in policy.items():\n",
        "                if allocation > 0 and policy_type in self.coefficients.policy_effectiveness:\n",
        "                    cost_per_school = self.coefficients.policy_effectiveness[policy_type].get(\"cost_per_school\", 50_000_000)\n",
        "                    schools_count = self.data_summary.get('danger_schools', 50)\n",
        "                    total_investment += (cost_per_school * schools_count * allocation / 100)\n",
        "\n",
        "            return EnhancedPolicyState(\n",
        "                risk_level=next_risk,\n",
        "                risk_level_uncertainty=(next_risk * 0.9, next_risk * 1.1),\n",
        "                budget_efficiency=next_budget_eff,\n",
        "                equity_score=next_equity,\n",
        "                social_acceptance=next_social,\n",
        "                schools_improved=current.schools_improved + schools_improved,\n",
        "                total_investment=current.total_investment + total_investment,\n",
        "                implementation_feasibility=scores.get('implementation_feasibility', 50),\n",
        "                evidence_quality=90.0,\n",
        "                validation_score=scores.get('validation_score', 100)\n",
        "            )\n",
        "\n",
        "        except Exception:\n",
        "            # ê¸°ë³¸ ë‹¤ìŒ ìƒíƒœ ë°˜í™˜\n",
        "            return EnhancedPolicyState(\n",
        "                risk_level=current.risk_level,\n",
        "                risk_level_uncertainty=(current.risk_level * 0.9, current.risk_level * 1.1),\n",
        "                budget_efficiency=current.budget_efficiency,\n",
        "                equity_score=current.equity_score,\n",
        "                social_acceptance=current.social_acceptance,\n",
        "                schools_improved=current.schools_improved,\n",
        "                total_investment=current.total_investment,\n",
        "                implementation_feasibility=50.0,\n",
        "                evidence_quality=50.0,\n",
        "                validation_score=50.0\n",
        "            )\n",
        "\n",
        "    def _compile_evidence_trail_safe(self, policy: Dict[str, float], branch_info: Dict[str, Any] = None,\n",
        "                                   scores: Dict[str, float] = None) -> List[str]:\n",
        "        \"\"\"ì•ˆì „í•œ ê·¼ê±° ì¶”ì  ì •ë³´ ìƒì„±\"\"\"\n",
        "        try:\n",
        "            evidence_trail = []\n",
        "\n",
        "            # ì •ì±…ë³„ ì‹¤ì¦ ê·¼ê±°\n",
        "            for policy_type, allocation in policy.items():\n",
        "                if allocation > 0 and policy_type in self.coefficients.policy_effectiveness:\n",
        "                    policy_data = self.coefficients.policy_effectiveness[policy_type]\n",
        "                    source = policy_data.get(\"evidence_source\", \"ê·¼ê±° ì—†ìŒ\")\n",
        "                    evidence_trail.append(f\"{policy_type}({allocation:.1f}%): {source}\")\n",
        "\n",
        "            # ë¶„ê¸°ë³„ ì¶”ê°€ ê·¼ê±°\n",
        "            if branch_info and 'evidence' in branch_info:\n",
        "                evidence_trail.extend(branch_info.get('evidence', []))\n",
        "\n",
        "            # ê²€ì¦ ê²°ê³¼ ì¶”ê°€\n",
        "            if branch_info and 'validation_result' in branch_info:\n",
        "                validation_result = branch_info['validation_result']\n",
        "                evidence_trail.append(f\"ì •ì±…ê²€ì¦: {validation_result.get('message', 'ê²€ì¦ì™„ë£Œ')}\")\n",
        "\n",
        "            # í‰ê°€ ì ìˆ˜ ê·¼ê±°\n",
        "            if scores:\n",
        "                evidence_trail.append(\n",
        "                    f\"ì¢…í•©í‰ê°€: í™˜ê²½ê°œì„ {scores.get('environmental_impact', 0):.1f}, \"\n",
        "                    f\"ì˜ˆì‚°íš¨ìœ¨{scores.get('budget_efficiency', 0):.1f}, \"\n",
        "                    f\"ì‹¤í–‰ê°€ëŠ¥{scores.get('implementation_feasibility', 0):.1f}, \"\n",
        "                    f\"ê²€ì¦ì ìˆ˜{scores.get('validation_score', 0):.1f}\"\n",
        "                )\n",
        "\n",
        "            return evidence_trail\n",
        "\n",
        "        except Exception:\n",
        "            return [\"ê·¼ê±° ì¶”ì  ì˜¤ë¥˜\"]\n",
        "\n",
        "# ê°•í™”ëœ í˜•í‰ì„± í‰ê°€ê¸°ë„ ì•ˆì „í•˜ê²Œ ìˆ˜ì •\n",
        "class EnhancedRealityBasedEquityEvaluator:\n",
        "    \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ê°•í™”ëœ í˜•í‰ì„± í‰ê°€ê¸°\"\"\"\n",
        "\n",
        "    def __init__(self, budget_baselines: Dict[str, Any], region_type: str = 'ì¼ë°˜ì§€ì—­'):\n",
        "        self.budget_baselines = budget_baselines or {}\n",
        "        self.region_type = region_type\n",
        "\n",
        "        self.policy_mapping = {\n",
        "            'ê³µê¸°ì²­ì •ê¸°': 'êµìœ¡í™œë™ì§€ì›',\n",
        "            'ê±´ë¬¼ê°œì„ ': 'ê¸°ë³¸êµìœ¡í™œë™',\n",
        "            'ë…¹ì§€ì¡°ì„±': 'êµìœ¡í™œë™ì§€ì›',\n",
        "            'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 'êµìœ¡í™œë™ì§€ì›',\n",
        "            'ë³µì§€ì§€ì›': 'ì¸ì ìì›ìš´ìš©'\n",
        "        }\n",
        "\n",
        "        self.safe_ranges = self._load_safe_ranges()\n",
        "        self._adjust_regional_baselines()\n",
        "\n",
        "    def _load_safe_ranges(self) -> Dict[str, Dict]:\n",
        "        \"\"\"ì•ˆì „í•œ ë²”ìœ„ ë¡œë“œ\"\"\"\n",
        "        try:\n",
        "            if 'safe_ranges' in self.budget_baselines:\n",
        "                return self.budget_baselines['safe_ranges']\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # ê¸°ë³¸ê°’\n",
        "        return {\n",
        "            'ì¸ì ìì›ìš´ìš©': {'baseline': 45, 'lower': 35, 'upper': 60, 'extreme_threshold': 65},\n",
        "            'ê¸°ë³¸êµìœ¡í™œë™': {'baseline': 35, 'lower': 25, 'upper': 50, 'extreme_threshold': 65},\n",
        "            'êµìœ¡í™œë™ì§€ì›': {'baseline': 20, 'lower': 15, 'upper': 35, 'extreme_threshold': 65}\n",
        "        }\n",
        "\n",
        "    def _adjust_regional_baselines(self):\n",
        "        \"\"\"ì§€ì—­ë³„ ì‹¤ì œ íŒ¨í„´ ë°˜ì˜\"\"\"\n",
        "        try:\n",
        "            if 'regional_patterns' not in self.budget_baselines:\n",
        "                return\n",
        "\n",
        "            regional_data = self.budget_baselines['regional_patterns']\n",
        "\n",
        "            if self.region_type == 'ë¶€ìœ ì§€ì—­':\n",
        "                rich_regions = ['ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬', 'ì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬', 'ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬']\n",
        "                education_ratios = []\n",
        "\n",
        "                for region in rich_regions:\n",
        "                    if region in regional_data and 'êµìœ¡í™œë™ì§€ì›' in regional_data[region]:\n",
        "                        education_ratios.append(regional_data[region]['êµìœ¡í™œë™ì§€ì›'])\n",
        "\n",
        "                if education_ratios:\n",
        "                    avg_ratio = np.mean(education_ratios)\n",
        "                    self.safe_ranges['êµìœ¡í™œë™ì§€ì›']['baseline'] = avg_ratio\n",
        "                    self.safe_ranges['êµìœ¡í™œë™ì§€ì›']['lower'] = max(15, avg_ratio - 8)\n",
        "                    self.safe_ranges['êµìœ¡í™œë™ì§€ì›']['upper'] = min(50, avg_ratio + 8)\n",
        "\n",
        "            elif self.region_type == 'ì €ì†Œë“ì§€ì—­':\n",
        "                poor_regions = ['ì„œìš¸íŠ¹ë³„ì‹œ ê¸ˆì²œêµ¬', 'ì„œìš¸íŠ¹ë³„ì‹œ ê°•ì„œêµ¬', 'ì„œìš¸íŠ¹ë³„ì‹œ ê´€ì•…êµ¬']\n",
        "                hr_ratios = []\n",
        "\n",
        "                for region in poor_regions:\n",
        "                    if region in regional_data and 'ì¸ì ìì›ìš´ìš©' in regional_data[region]:\n",
        "                        hr_ratios.append(regional_data[region]['ì¸ì ìì›ìš´ìš©'])\n",
        "\n",
        "                if hr_ratios:\n",
        "                    avg_ratio = np.mean(hr_ratios)\n",
        "                    self.safe_ranges['ì¸ì ìì›ìš´ìš©']['baseline'] = avg_ratio\n",
        "                    self.safe_ranges['ì¸ì ìì›ìš´ìš©']['lower'] = max(30, avg_ratio - 10)\n",
        "                    self.safe_ranges['ì¸ì ìì›ìš´ìš©']['upper'] = min(70, avg_ratio + 10)\n",
        "        except Exception:\n",
        "            pass  # ì¡°ì • ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ìœ ì§€\n",
        "\n",
        "    def evaluate_policy_equity(self, policy_allocation: Dict[str, float]) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ ì •ì±… ë°°ë¶„ í˜•í‰ì„± í‰ê°€\"\"\"\n",
        "        try:\n",
        "            # ì‚¬ì „ ìœ íš¨ì„± ê²€ì¦\n",
        "            is_valid, validation_msg, validation_penalty = validate_policy_feasibility(policy_allocation)\n",
        "            if not is_valid:\n",
        "                base_penalty = min(50, validation_penalty)\n",
        "                return max(0, 50 - base_penalty)\n",
        "\n",
        "            # TOT ì •ì±…ì„ ì˜ˆì‚° í•­ëª©ìœ¼ë¡œ ë³€í™˜\n",
        "            budget_allocation = self._convert_to_budget_allocation(policy_allocation)\n",
        "\n",
        "            # ê° ì˜ˆì‚° í•­ëª©ë³„ í‰ê°€\n",
        "            item_scores = []\n",
        "            political_risks = []\n",
        "\n",
        "            for budget_item, allocation in budget_allocation.items():\n",
        "                if budget_item in self.safe_ranges:\n",
        "                    score, risk = self._evaluate_single_item_safe(budget_item, allocation)\n",
        "                    item_scores.append(score)\n",
        "                    if risk > 0:\n",
        "                        political_risks.append(risk)\n",
        "\n",
        "            # ê¸°ë³¸ ì ìˆ˜\n",
        "            base_score = np.mean(item_scores) if item_scores else 50\n",
        "\n",
        "            # ë¹„ì„ í˜• ê·¹ë‹¨ì  ì§‘ì¤‘ íŒ¨ë„í‹°\n",
        "            extreme_penalty = self._calculate_nonlinear_extreme_penalty(budget_allocation)\n",
        "\n",
        "            # ì •ì±… ë‹¤ì–‘ì„± í‰ê°€\n",
        "            diversity_score = self._evaluate_policy_diversity_safe(policy_allocation)\n",
        "\n",
        "            # ì§€ì—­ë³„ ì í•©ì„± ë³´ë„ˆìŠ¤\n",
        "            regional_bonus = self._calculate_regional_bonus_safe(budget_allocation)\n",
        "\n",
        "            # ì •ì¹˜ì  ìœ„í—˜ë„ ì •ëŸ‰í™”\n",
        "            political_risk_score = self._quantify_political_risk_safe(budget_allocation, political_risks)\n",
        "\n",
        "            # ìµœì¢… ì ìˆ˜\n",
        "            final_score = (\n",
        "                base_score * 0.4 +\n",
        "                diversity_score * 0.2 +\n",
        "                political_risk_score * 0.2 +\n",
        "                regional_bonus * 0.2\n",
        "            ) - extreme_penalty\n",
        "\n",
        "            return max(0, min(100, final_score))\n",
        "\n",
        "        except Exception:\n",
        "            return 50.0\n",
        "\n",
        "    def _convert_to_budget_allocation(self, policy_allocation: Dict[str, float]) -> Dict[str, float]:\n",
        "        \"\"\"TOT ì •ì±…ì„ ì˜ˆì‚° í•­ëª©ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
        "        try:\n",
        "            budget_allocation = {'ì¸ì ìì›ìš´ìš©': 0, 'ê¸°ë³¸êµìœ¡í™œë™': 0, 'êµìœ¡í™œë™ì§€ì›': 0}\n",
        "\n",
        "            for policy, percent in policy_allocation.items():\n",
        "                if policy in self.policy_mapping:\n",
        "                    budget_item = self.policy_mapping[policy]\n",
        "                    budget_allocation[budget_item] += percent\n",
        "\n",
        "            return budget_allocation\n",
        "        except Exception:\n",
        "            return {'ì¸ì ìì›ìš´ìš©': 33, 'ê¸°ë³¸êµìœ¡í™œë™': 33, 'êµìœ¡í™œë™ì§€ì›': 34}\n",
        "\n",
        "    def _evaluate_single_item_safe(self, budget_item: str, allocation: float) -> Tuple[float, float]:\n",
        "        \"\"\"ì•ˆì „í•œ ê°œë³„ ì˜ˆì‚° í•­ëª© í‰ê°€\"\"\"\n",
        "        try:\n",
        "            ranges = self.safe_ranges.get(budget_item, {})\n",
        "            baseline = ranges.get('baseline', 30)\n",
        "            lower = ranges.get('lower', 20)\n",
        "            upper = ranges.get('upper', 40)\n",
        "            extreme_threshold = ranges.get('extreme_threshold', 65)\n",
        "\n",
        "            score = 50.0\n",
        "            risk = 0.0\n",
        "\n",
        "            if lower <= allocation <= upper:\n",
        "                distance_from_baseline = abs(allocation - baseline)\n",
        "                max_distance = max(baseline - lower, upper - baseline)\n",
        "\n",
        "                if max_distance > 0:\n",
        "                    proximity = 1 - distance_from_baseline / max_distance\n",
        "                    score = 50 + proximity * 50\n",
        "                else:\n",
        "                    score = 100\n",
        "            else:\n",
        "                if allocation < lower:\n",
        "                    shortage = lower - allocation\n",
        "                    score = max(20, 50 - shortage * 2.5)\n",
        "                    risk = min(25, shortage * 2.0)\n",
        "                else:  # allocation > upper\n",
        "                    excess = allocation - upper\n",
        "                    score = max(10, 50 - excess * 3.0)\n",
        "\n",
        "                    if allocation > extreme_threshold:\n",
        "                        risk = min(40, excess * 4 + 20)\n",
        "                    else:\n",
        "                        risk = min(20, excess * 2.5)\n",
        "\n",
        "            return score, risk\n",
        "\n",
        "        except Exception:\n",
        "            return 50.0, 0.0\n",
        "\n",
        "    def _calculate_nonlinear_extreme_penalty(self, budget_allocation: Dict[str, float]) -> float:\n",
        "        \"\"\"ë¹„ì„ í˜• ê·¹ë‹¨ì  ì§‘ì¤‘ íŒ¨ë„í‹°\"\"\"\n",
        "        try:\n",
        "            max_allocation = max(budget_allocation.values()) if budget_allocation.values() else 0\n",
        "\n",
        "            if max_allocation >= 80:\n",
        "                return min(45, (max_allocation - 80) ** 1.5 * 1.5)\n",
        "            elif max_allocation >= 70:\n",
        "                return min(30, (max_allocation - 70) ** 1.3 * 1.2)\n",
        "            elif max_allocation >= 60:\n",
        "                return min(15, (max_allocation - 60) ** 1.1 * 1.0)\n",
        "\n",
        "            return 0\n",
        "        except Exception:\n",
        "            return 0\n",
        "\n",
        "    def _evaluate_policy_diversity_safe(self, policy_allocation: Dict[str, float]) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ ì •ì±… ë‹¤ì–‘ì„± í‰ê°€\"\"\"\n",
        "        try:\n",
        "            active_policies = [v for v in policy_allocation.values() if v >= 5]\n",
        "            total_allocation = sum(policy_allocation.values())\n",
        "\n",
        "            if len(active_policies) < 2:\n",
        "                return 20\n",
        "\n",
        "            if total_allocation > 0:\n",
        "                shares = [v/total_allocation for v in active_policies]\n",
        "                herfindahl_index = sum(share**2 for share in shares)\n",
        "\n",
        "                optimal_hhi = 1 / len(active_policies)\n",
        "                diversity_score = max(0, 100 * (1 - (herfindahl_index - optimal_hhi)))\n",
        "\n",
        "                return min(100, diversity_score)\n",
        "\n",
        "            return 50\n",
        "        except Exception:\n",
        "            return 50.0\n",
        "\n",
        "    def _quantify_political_risk_safe(self, budget_allocation: Dict[str, float], political_risks: List[float]) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ ì •ì¹˜ì  ìœ„í—˜ë„ ì •ëŸ‰í™”\"\"\"\n",
        "        try:\n",
        "            if not political_risks:\n",
        "                return 90\n",
        "\n",
        "            total_risk = sum(political_risks)\n",
        "\n",
        "            if total_risk >= 50:\n",
        "                return 20\n",
        "            elif total_risk >= 30:\n",
        "                return 40\n",
        "            elif total_risk >= 15:\n",
        "                return 60\n",
        "            else:\n",
        "                return 80\n",
        "        except Exception:\n",
        "            return 70.0\n",
        "\n",
        "    def _calculate_regional_bonus_safe(self, budget_allocation: Dict[str, float]) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ ì§€ì—­ íŠ¹ì„± ë§ì¶¤ë„ ë³´ë„ˆìŠ¤\"\"\"\n",
        "        try:\n",
        "            bonus = 50\n",
        "\n",
        "            if self.region_type == 'ë¶€ìœ ì§€ì—­':\n",
        "                education_ratio = budget_allocation.get('êµìœ¡í™œë™ì§€ì›', 0)\n",
        "                if 25 <= education_ratio <= 40:\n",
        "                    bonus += min(20, (education_ratio - 20) * 0.5)\n",
        "\n",
        "            elif self.region_type == 'ì €ì†Œë“ì§€ì—­':\n",
        "                hr_ratio = budget_allocation.get('ì¸ì ìì›ìš´ìš©', 0)\n",
        "                if 45 <= hr_ratio <= 65:\n",
        "                    bonus += min(20, (hr_ratio - 40) * 0.4)\n",
        "\n",
        "            return min(100, bonus)\n",
        "        except Exception:\n",
        "            return 50.0\n",
        "\n",
        "# Tree of Thoughts íƒìƒ‰ê¸°ë„ ì•ˆì „í•˜ê²Œ ìˆ˜ì •\n",
        "class EnhancedTOTSearcher:\n",
        "    \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ê°•í™”ëœ Tree of Thoughts íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜\"\"\"\n",
        "\n",
        "    def __init__(self, beam_width: int = 5, max_depth: int = 4):\n",
        "        self.beam_width = beam_width\n",
        "        self.max_depth = max_depth\n",
        "        self.search_history = []\n",
        "        self.pareto_frontier = []\n",
        "        self.exploration_stats = {\n",
        "            'total_nodes': 0,\n",
        "            'pruned_nodes': 0,\n",
        "            'pareto_updates': 0,\n",
        "            'invalid_policies': 0,\n",
        "            'early_stops': 0\n",
        "        }\n",
        "\n",
        "    def search_best_paths(self, root_node: EnhancedTreeNode, generator: EnhancedPolicyGenerator,\n",
        "                         evaluator: EnhancedPolicyEvaluator) -> List[EnhancedTreeNode]:\n",
        "        \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ Tree of Thoughts íƒìƒ‰ ì‹¤í–‰\"\"\"\n",
        "\n",
        "        print(f\"ğŸ” ê°•í™”ëœ Tree of Thoughts íƒìƒ‰ ì‹œì‘ (beam_width={self.beam_width}, max_depth={self.max_depth})\")\n",
        "        current_layer = [root_node]\n",
        "        best_score_history = [0]\n",
        "        no_improvement_count = 0\n",
        "\n",
        "        try:\n",
        "            for depth in range(1, self.max_depth + 1):\n",
        "                print(f\"ğŸŒŠ Depth {depth} íƒìƒ‰ ì¤‘...\")\n",
        "                next_layer = []\n",
        "                layer_best_score = 0\n",
        "\n",
        "                for parent_node in current_layer:\n",
        "                    try:\n",
        "                        # ì •ì±… ë¶„ê¸° ìƒì„±\n",
        "                        policy_branches = generator.generate_policy_branches(parent_node.state, n_branches=6)\n",
        "\n",
        "                        for i, branch in enumerate(policy_branches):\n",
        "                            try:\n",
        "                                # ì •ì±… ìœ íš¨ì„± ì‚¬ì „ ì²´í¬\n",
        "                                validation_result = branch.get('validation_result', {})\n",
        "                                if not validation_result.get('valid', True):\n",
        "                                    self.exploration_stats['invalid_policies'] += 1\n",
        "                                    continue\n",
        "\n",
        "                                # ì •ì±… í‰ê°€\n",
        "                                eval_result = evaluator.evaluate_policy(parent_node.state, branch['policy'], branch)\n",
        "\n",
        "                                # ìì‹ ë…¸ë“œ ìƒì„±\n",
        "                                child_node = EnhancedTreeNode(\n",
        "                                    state=eval_result['next_state'],\n",
        "                                    policy=branch['policy'],\n",
        "                                    score=eval_result['total_score'],\n",
        "                                    depth=depth,\n",
        "                                    parent=parent_node\n",
        "                                )\n",
        "\n",
        "                                # ë©”íƒ€ë°ì´í„° ì„¤ì •\n",
        "                                child_node.policy_description = branch.get('description', 'ì •ì±… ì„¤ëª…')\n",
        "                                child_node.evaluation_details = eval_result.get('detailed_scores', {})\n",
        "                                child_node.evidence_trail = eval_result.get('evidence_trail', [])\n",
        "                                child_node.validation_result = eval_result.get('validation_result')\n",
        "                                child_node.uncertainty_analysis = {\n",
        "                                    'confidence_level': eval_result.get('confidence_level', 0.8),\n",
        "                                    'risk_bounds': eval_result['next_state'].risk_level_uncertainty\n",
        "                                }\n",
        "\n",
        "                                parent_node.add_child(child_node)\n",
        "                                next_layer.append(child_node)\n",
        "                                self.exploration_stats['total_nodes'] += 1\n",
        "\n",
        "                                # í˜„ì¬ ë ˆì´ì–´ ìµœê³  ì ìˆ˜ ì¶”ì \n",
        "                                layer_best_score = max(layer_best_score, child_node.score)\n",
        "\n",
        "                            except Exception as e:\n",
        "                                print(f\"   âš ï¸ ë…¸ë“œ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
        "                                continue\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"   âš ï¸ ë¶„ê¸° ìƒì„± ì˜¤ë¥˜: {e}\")\n",
        "                        continue\n",
        "\n",
        "                # ì¡°ê¸° ì¤‘ë‹¨ ë¡œì§\n",
        "                if layer_best_score <= best_score_history[-1] + 1.0:\n",
        "                    no_improvement_count += 1\n",
        "                    print(f\"   ğŸ“ˆ ê°œì„  ë¯¸ë¯¸: {layer_best_score:.1f} vs {best_score_history[-1]:.1f}\")\n",
        "                else:\n",
        "                    no_improvement_count = 0\n",
        "                    print(f\"   ğŸ“ˆ ì ìˆ˜ ê°œì„ : {layer_best_score:.1f} (ì´ì „: {best_score_history[-1]:.1f})\")\n",
        "\n",
        "                best_score_history.append(layer_best_score)\n",
        "\n",
        "                # ì—°ì† 2íšŒ ê°œì„  ì—†ìœ¼ë©´ ì¡°ê¸° ì¤‘ë‹¨\n",
        "                if no_improvement_count >= 2 and depth >= 2:\n",
        "                    print(f\"   ğŸ›‘ ì¡°ê¸° ì¤‘ë‹¨: {depth}ë‹¨ê³„ì—ì„œ {no_improvement_count}íšŒ ì—°ì† ê°œì„  ì—†ìŒ\")\n",
        "                    self.exploration_stats['early_stops'] += 1\n",
        "                    break\n",
        "\n",
        "                # íŒŒë ˆí†  ìµœì í•´ ì—…ë°ì´íŠ¸\n",
        "                self._update_pareto_frontier_safe(next_layer)\n",
        "\n",
        "                # ê°•í™”ëœ ë…¸ë“œ ì„ íƒ\n",
        "                selected_nodes = self._select_enhanced_diverse_nodes_safe(next_layer, self.beam_width)\n",
        "\n",
        "                pruned_count = len(next_layer) - len(selected_nodes)\n",
        "                self.exploration_stats['pruned_nodes'] += pruned_count\n",
        "\n",
        "                print(f\"   âœ… {len(selected_nodes)}ê°œ ë…¸ë“œ ì„ íƒ (ì´ {len(next_layer)}ê°œ ì¤‘, {pruned_count}ê°œ ê°€ì§€ì¹˜ê¸°)\")\n",
        "\n",
        "                # íƒìƒ‰ ê¸°ë¡\n",
        "                self.search_history.append({\n",
        "                    'depth': depth,\n",
        "                    'total_nodes': len(next_layer),\n",
        "                    'selected_nodes': len(selected_nodes),\n",
        "                    'best_score': layer_best_score,\n",
        "                    'pareto_size': len(self.pareto_frontier),\n",
        "                    'improvement': layer_best_score - best_score_history[-2] if len(best_score_history) > 1 else 0\n",
        "                })\n",
        "\n",
        "                current_layer = selected_nodes\n",
        "\n",
        "                if not current_layer:\n",
        "                    print(f\"   âš ï¸ ìœ íš¨í•œ ë…¸ë“œ ì—†ìŒ, íƒìƒ‰ ì¤‘ë‹¨\")\n",
        "                    break\n",
        "\n",
        "            # ìµœì¢… ê²°ê³¼\n",
        "            final_nodes = sorted(current_layer, key=lambda node: node.score, reverse=True) if current_layer else []\n",
        "\n",
        "            print(f\"ğŸ† ê°•í™”ëœ íƒìƒ‰ ì™„ë£Œ!\")\n",
        "            print(f\"   ğŸ“Š íƒìƒ‰ í†µê³„: ì´ {self.exploration_stats['total_nodes']}ê°œ ë…¸ë“œ\")\n",
        "            print(f\"   âœ‚ï¸ ê°€ì§€ì¹˜ê¸°: {self.exploration_stats['pruned_nodes']}ê°œ\")\n",
        "            print(f\"   âŒ ë¬´íš¨ ì •ì±…: {self.exploration_stats['invalid_policies']}ê°œ\")\n",
        "            print(f\"   ğŸ›‘ ì¡°ê¸° ì¤‘ë‹¨: {self.exploration_stats['early_stops']}íšŒ\")\n",
        "            print(f\"   ğŸ¯ íŒŒë ˆí†  ìµœì í•´: {len(self.pareto_frontier)}ê°œ\")\n",
        "            print(f\"   ğŸ¥‡ ìµœê³  ì ìˆ˜: {final_nodes[0].score:.1f}\" if final_nodes else \"   âŒ í•´ ì—†ìŒ\")\n",
        "\n",
        "            return final_nodes\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ íƒìƒ‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _update_pareto_frontier_safe(self, nodes: List[EnhancedTreeNode]):\n",
        "        \"\"\"ì•ˆì „í•œ íŒŒë ˆí†  ìµœì í•´ ì§‘í•© ì—…ë°ì´íŠ¸\"\"\"\n",
        "        try:\n",
        "            for node in nodes:\n",
        "                is_dominated = False\n",
        "                nodes_to_remove = []\n",
        "\n",
        "                for existing_node in self.pareto_frontier:\n",
        "                    if self._dominates_safe(existing_node, node):\n",
        "                        is_dominated = True\n",
        "                        break\n",
        "                    elif self._dominates_safe(node, existing_node):\n",
        "                        nodes_to_remove.append(existing_node)\n",
        "\n",
        "                if not is_dominated:\n",
        "                    for node_to_remove in nodes_to_remove:\n",
        "                        self.pareto_frontier.remove(node_to_remove)\n",
        "                    self.pareto_frontier.append(node)\n",
        "                    self.exploration_stats['pareto_updates'] += 1\n",
        "        except Exception:\n",
        "            pass  # íŒŒë ˆí†  ì—…ë°ì´íŠ¸ ì‹¤íŒ¨í•´ë„ íƒìƒ‰ ê³„ì†\n",
        "\n",
        "    def _dominates_safe(self, node1: EnhancedTreeNode, node2: EnhancedTreeNode) -> bool:\n",
        "        \"\"\"ì•ˆì „í•œ íŒŒë ˆí†  ì§€ë°°ê´€ê³„ í™•ì¸\"\"\"\n",
        "        try:\n",
        "            # 3ì°¨ì› ìµœì í™”: í™˜ê²½ê°œì„ íš¨ê³¼ vs ì˜ˆì‚°íš¨ìœ¨ì„± vs ì‹¤í–‰ê°€ëŠ¥ì„±\n",
        "            env1 = node1.evaluation_details.get('environmental_impact', 0)\n",
        "            budget1 = node1.evaluation_details.get('budget_efficiency', 0)\n",
        "            feasibility1 = node1.evaluation_details.get('implementation_feasibility', 0)\n",
        "\n",
        "            env2 = node2.evaluation_details.get('environmental_impact', 0)\n",
        "            budget2 = node2.evaluation_details.get('budget_efficiency', 0)\n",
        "            feasibility2 = node2.evaluation_details.get('implementation_feasibility', 0)\n",
        "\n",
        "            return ((env1 >= env2 and budget1 >= budget2 and feasibility1 >= feasibility2) and\n",
        "                    (env1 > env2 or budget1 > budget2 or feasibility1 > feasibility2))\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "    def _select_enhanced_diverse_nodes_safe(self, nodes: List[EnhancedTreeNode], k: int) -> List[EnhancedTreeNode]:\n",
        "        \"\"\"ì•ˆì „í•œ ê°•í™”ëœ ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ ë…¸ë“œ ì„ íƒ\"\"\"\n",
        "        try:\n",
        "            if len(nodes) <= k:\n",
        "                return sorted(nodes, key=lambda n: n.score, reverse=True)\n",
        "\n",
        "            # ìœ íš¨ì„± ì ìˆ˜ë¡œ 1ì°¨ í•„í„°ë§\n",
        "            valid_nodes = [node for node in nodes\n",
        "                          if node.state.validation_score >= 70]\n",
        "\n",
        "            if len(valid_nodes) < k:\n",
        "                valid_nodes = nodes\n",
        "                print(f\"   âš ï¸ ìœ íš¨ ë…¸ë“œ ë¶€ì¡±: {len([n for n in nodes if n.state.validation_score >= 70])}ê°œ\")\n",
        "\n",
        "            # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬\n",
        "            sorted_nodes = sorted(valid_nodes, key=lambda n: n.score, reverse=True)\n",
        "\n",
        "            # ìƒìœ„ ë…¸ë“œ ìš°ì„  ì„ íƒ\n",
        "            candidates = sorted_nodes[:min(k*3, len(sorted_nodes))]\n",
        "            selected = [candidates[0]] if candidates else []\n",
        "\n",
        "            for _ in range(k-1):\n",
        "                if not candidates:\n",
        "                    break\n",
        "\n",
        "                best_candidate = None\n",
        "                max_diversity_score = -1\n",
        "\n",
        "                for candidate in candidates:\n",
        "                    if candidate in selected:\n",
        "                        continue\n",
        "\n",
        "                    # ë‹¤ì–‘ì„± + í’ˆì§ˆ ë³µí•© ì ìˆ˜\n",
        "                    diversity = self._calculate_policy_diversity_safe(candidate, selected)\n",
        "                    quality_bonus = (candidate.score / 100) * 0.3\n",
        "                    validation_bonus = (candidate.state.validation_score / 100) * 0.2\n",
        "\n",
        "                    combined_score = diversity + quality_bonus + validation_bonus\n",
        "\n",
        "                    if combined_score > max_diversity_score:\n",
        "                        max_diversity_score = combined_score\n",
        "                        best_candidate = candidate\n",
        "\n",
        "                if best_candidate:\n",
        "                    selected.append(best_candidate)\n",
        "\n",
        "            return selected\n",
        "\n",
        "        except Exception:\n",
        "            # ì•ˆì „í•œ ê¸°ë³¸ ì„ íƒ\n",
        "            return sorted(nodes[:k], key=lambda n: n.score, reverse=True)\n",
        "\n",
        "    def _calculate_policy_diversity_safe(self, candidate: EnhancedTreeNode, selected: List[EnhancedTreeNode]) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ ì •ì±… ë‹¤ì–‘ì„± ê³„ì‚°\"\"\"\n",
        "        try:\n",
        "            if not selected:\n",
        "                return 1.0\n",
        "\n",
        "            min_distance = float('inf')\n",
        "\n",
        "            for selected_node in selected:\n",
        "                policy1 = np.array(list(candidate.policy.values()))\n",
        "                policy2 = np.array(list(selected_node.policy.values()))\n",
        "\n",
        "                if np.linalg.norm(policy1) > 0 and np.linalg.norm(policy2) > 0:\n",
        "                    cosine_sim = np.dot(policy1, policy2) / (np.linalg.norm(policy1) * np.linalg.norm(policy2))\n",
        "                    distance = 1 - cosine_sim\n",
        "                    min_distance = min(min_distance, distance)\n",
        "\n",
        "            return min_distance if min_distance != float('inf') else 1.0\n",
        "\n",
        "        except Exception:\n",
        "            return 0.5\n",
        "\n",
        "# ìµœì¢… ì‹œë®¬ë ˆì´í„°ë„ ì•ˆì „í•˜ê²Œ ìˆ˜ì •\n",
        "class EnhancedTOTSimulator:\n",
        "    \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ê°•í™”ëœ ì¢…í•© ì •ì±… ì‹œë®¬ë ˆì´ì…˜ ì‹œìŠ¤í…œ\"\"\"\n",
        "\n",
        "    def __init__(self, data_summary: Dict[str, Any] = None, beam_width: int = 5, max_depth: int = 4):\n",
        "        self.data_summary = data_summary or {}\n",
        "        self.generator = EnhancedPolicyGenerator(data_summary)\n",
        "        self.evaluator = EnhancedPolicyEvaluator(data_summary)\n",
        "        self.searcher = EnhancedTOTSearcher(beam_width, max_depth)\n",
        "        self.coefficients = EvidenceBasedCoefficients()\n",
        "\n",
        "        self.root = None\n",
        "        self.best_paths = []\n",
        "        self.simulation_results = {}\n",
        "        self.policy_validation_log = []\n",
        "\n",
        "    def run_simulation(self) -> List[EnhancedTreeNode]:\n",
        "        \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ì¢…í•© ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰\"\"\"\n",
        "\n",
        "        print(\"ğŸš€ ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘!\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"ğŸ¯ ëª©í‘œ: í™˜ê²½ì˜¤ì—¼ë„ Ã— ì˜ˆì‚°ì •ë³´ ê¸°ë°˜ ìµœì  ì •ì±… ë°œê²¬\")\n",
        "        print(\"ğŸ§  ë°©ë²•: ê°•í™”ëœ Tree of Thoughts + ì •ì±… ìœ íš¨ì„± ê²€ì¦\")\n",
        "        print(\"ğŸ“Š ê·¼ê±°: êµìœ¡ë¶€/í™˜ê²½ë¶€/ì„œìš¸ì‹œ ê³µì‹ ì—°êµ¬ë³´ê³ ì„œ\")\n",
        "        print(\"ğŸ” ê°œì„ : ë¹„í˜„ì‹¤ì  ì •ì±… ì‚¬ì „ í•„í„°ë§ + ë¹„ì„ í˜• íŒ¨ë„í‹°\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        try:\n",
        "            # ì´ˆê¸° ìƒíƒœ ì„¤ì •\n",
        "            initial_state = self._initialize_enhanced_state_safe()\n",
        "            self.root = EnhancedTreeNode(\n",
        "                state=initial_state,\n",
        "                policy={},\n",
        "                score=0.0,\n",
        "                depth=0\n",
        "            )\n",
        "            self.root.policy_description = \"í˜„ì¬ ìƒíƒœ (ì •ì±… ì‹œí–‰ ì „)\"\n",
        "\n",
        "            # Tree of Thoughts íƒìƒ‰ ì‹¤í–‰\n",
        "            print(\"\\nğŸŒ³ ê°•í™”ëœ Tree of Thoughts íƒìƒ‰ ì‹¤í–‰...\")\n",
        "            self.best_paths = self.searcher.search_best_paths(\n",
        "                self.root, self.generator, self.evaluator\n",
        "            )\n",
        "\n",
        "            # ì •ì±… ê²€ì¦ ë¡œê·¸ ìˆ˜ì§‘\n",
        "            self._collect_validation_logs_safe()\n",
        "\n",
        "            # ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥\n",
        "            print(\"\\nğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë¶„ì„...\")\n",
        "            self._analyze_enhanced_simulation_results_safe()\n",
        "            self._print_enhanced_comprehensive_results_safe()\n",
        "\n",
        "            return self.best_paths\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì˜¤ë¥˜: {e}\")\n",
        "            return []\n",
        "\n",
        "    def _initialize_enhanced_state_safe(self) -> EnhancedPolicyState:\n",
        "        \"\"\"ì•ˆì „í•œ ê°•í™”ëœ ì´ˆê¸° ìƒíƒœ ì„¤ì •\"\"\"\n",
        "        try:\n",
        "            initial_risk = self.data_summary.get('avg_risk', 55.0)\n",
        "            danger_schools = self.data_summary.get('danger_schools', 0)\n",
        "            total_schools = self.data_summary.get('total_schools', 100)\n",
        "            data_quality = self.data_summary.get('data_quality', {})\n",
        "\n",
        "            print(f\"ğŸ“Š ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì´ˆê¸° ìƒíƒœ:\")\n",
        "            print(f\"   ğŸŒ¡ï¸ í‰ê·  í™˜ê²½ìœ„í—˜ë„: {initial_risk:.1f}/100\")\n",
        "            print(f\"   ğŸ« ì „ì²´ í•™êµ ìˆ˜: {total_schools}ê°œ\")\n",
        "            print(f\"   âš ï¸ ê³ ìœ„í—˜ í•™êµ: {danger_schools}ê°œ (D/Eê¸‰)\")\n",
        "            print(f\"   ğŸ“ˆ ê³ ìœ„í—˜ ë¹„ìœ¨: {danger_schools/total_schools*100:.1f}%\")\n",
        "            print(f\"   ğŸ“Š ë°ì´í„° í’ˆì§ˆ: {data_quality.get('overall_score', 85):.1f}/100\")\n",
        "\n",
        "            return EnhancedPolicyState(\n",
        "                risk_level=initial_risk,\n",
        "                risk_level_uncertainty=(initial_risk * 0.9, initial_risk * 1.1),\n",
        "                budget_efficiency=50.0,\n",
        "                equity_score=45.0,\n",
        "                social_acceptance=60.0,\n",
        "                schools_improved=0,\n",
        "                total_investment=0.0,\n",
        "                implementation_feasibility=70.0,\n",
        "                evidence_quality=85.0,\n",
        "                validation_score=100.0\n",
        "            )\n",
        "\n",
        "        except Exception:\n",
        "            print(f\"ğŸ“Š ê¸°ë³¸ ì´ˆê¸° ìƒíƒœ ì„¤ì • (ë°ì´í„° ì˜¤ë¥˜)\")\n",
        "            return EnhancedPolicyState(\n",
        "                risk_level=55.0,\n",
        "                risk_level_uncertainty=(49.5, 60.5),\n",
        "                budget_efficiency=50.0,\n",
        "                equity_score=45.0,\n",
        "                social_acceptance=60.0,\n",
        "                schools_improved=0,\n",
        "                total_investment=0.0,\n",
        "                implementation_feasibility=70.0,\n",
        "                evidence_quality=80.0,\n",
        "                validation_score=100.0\n",
        "            )\n",
        "\n",
        "    def _collect_validation_logs_safe(self):\n",
        "        \"\"\"ì•ˆì „í•œ ì •ì±… ê²€ì¦ ë¡œê·¸ ìˆ˜ì§‘\"\"\"\n",
        "        try:\n",
        "            # ìƒì„±ê¸°ì—ì„œ ì‹¤íŒ¨í•œ ì •ì±…ë“¤ ìˆ˜ì§‘\n",
        "            if hasattr(self.generator, 'failed_policies'):\n",
        "                for failed_policy in self.generator.failed_policies:\n",
        "                    self.policy_validation_log.append({\n",
        "                        'type': 'generation_failure',\n",
        "                        'policy': failed_policy.get('policy', {}),\n",
        "                        'reason': failed_policy.get('reason', 'Unknown'),\n",
        "                        'penalty': failed_policy.get('penalty', 0),\n",
        "                        'attempt': failed_policy.get('attempt', 0)\n",
        "                    })\n",
        "\n",
        "            # íƒìƒ‰ê¸°ì—ì„œ ë¬´íš¨ ì •ì±… í†µê³„ ìˆ˜ì§‘\n",
        "            self.policy_validation_log.append({\n",
        "                'type': 'search_statistics',\n",
        "                'total_nodes': self.searcher.exploration_stats.get('total_nodes', 0),\n",
        "                'invalid_policies': self.searcher.exploration_stats.get('invalid_policies', 0),\n",
        "                'early_stops': self.searcher.exploration_stats.get('early_stops', 0),\n",
        "                'pruned_nodes': self.searcher.exploration_stats.get('pruned_nodes', 0)\n",
        "            })\n",
        "        except Exception:\n",
        "            pass  # ë¡œê·¸ ìˆ˜ì§‘ ì‹¤íŒ¨í•´ë„ ì‹œë®¬ë ˆì´ì…˜ ê³„ì†\n",
        "\n",
        "    def _analyze_enhanced_simulation_results_safe(self):\n",
        "        \"\"\"ì•ˆì „í•œ ê°•í™”ëœ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë¶„ì„\"\"\"\n",
        "        try:\n",
        "            if not self.best_paths:\n",
        "                self.simulation_results = {\n",
        "                    'error': 'ìµœì í•´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.',\n",
        "                    'validation_issues': len(self.policy_validation_log),\n",
        "                    'failed_policies': [log for log in self.policy_validation_log if log.get('type') == 'generation_failure']\n",
        "                }\n",
        "                return\n",
        "\n",
        "            best_node = self.best_paths[0]\n",
        "            best_path = best_node.trace_path()\n",
        "\n",
        "            # ì •ì±… íš¨ê³¼ ë¶„ì„\n",
        "            initial_state = best_path[0].state\n",
        "            final_state = best_path[-1].state\n",
        "\n",
        "            # ê²€ì¦ ì ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°\n",
        "            validation_reliability = final_state.validation_score / 100\n",
        "\n",
        "            # íˆ¬ì íš¨ìœ¨ì„± ë¶„ì„\n",
        "            total_investment = final_state.total_investment\n",
        "            schools_improved = final_state.schools_improved\n",
        "            risk_reduction = initial_state.risk_level - final_state.risk_level\n",
        "\n",
        "            # ì‹ ë¢°ë„ ì¡°ì •ëœ íš¨ê³¼ ê³„ì‚°\n",
        "            adjusted_risk_reduction = risk_reduction * validation_reliability\n",
        "            adjusted_schools_improved = int(schools_improved * validation_reliability)\n",
        "\n",
        "            # ë¹„ìš© íš¨ê³¼ë¹„ ê³„ì‚°\n",
        "            cost_per_school = total_investment / adjusted_schools_improved if adjusted_schools_improved > 0 else float('inf')\n",
        "            cost_per_risk_point = total_investment / adjusted_risk_reduction if adjusted_risk_reduction > 0 else float('inf')\n",
        "\n",
        "            # ì •ì±… êµ¬ì„± ë¶„ì„\n",
        "            policy_breakdown = {}\n",
        "            total_allocation = sum(best_node.policy.values())\n",
        "            for policy, allocation in best_node.policy.items():\n",
        "                if allocation > 0:\n",
        "                    percentage = (allocation / total_allocation * 100) if total_allocation > 0 else 0\n",
        "\n",
        "                    # ì •ì±…ë³„ ìœ íš¨ì„± ì²´í¬\n",
        "                    single_policy = {policy: allocation}\n",
        "                    is_valid, validation_msg, penalty = validate_policy_feasibility(single_policy)\n",
        "\n",
        "                    policy_breakdown[policy] = {\n",
        "                        'allocation': allocation,\n",
        "                        'percentage': percentage,\n",
        "                        'expected_cost': 0,\n",
        "                        'validity': is_valid,\n",
        "                        'validation_message': validation_msg,\n",
        "                        'penalty': penalty\n",
        "                    }\n",
        "\n",
        "                    # ì˜ˆìƒ ë¹„ìš© ê³„ì‚°\n",
        "                    if policy in self.coefficients.policy_effectiveness:\n",
        "                        cost_per_school_policy = self.coefficients.policy_effectiveness[policy].get('cost_per_school', 50_000_000)\n",
        "                        target_schools = adjusted_schools_improved if adjusted_schools_improved > 0 else 50\n",
        "                        policy_breakdown[policy]['expected_cost'] = cost_per_school_policy * target_schools * (allocation / 100)\n",
        "\n",
        "            # ì •ì±… í’ˆì§ˆ ë©”íŠ¸ë¦­\n",
        "            quality_metrics = {\n",
        "                'validation_score': final_state.validation_score,\n",
        "                'reliability_factor': validation_reliability,\n",
        "                'policy_diversity': len([v for v in best_node.policy.values() if v >= 5]),\n",
        "                'extreme_concentration': max(best_node.policy.values()) if best_node.policy.values() else 0,\n",
        "                'total_penalty': sum([bp.get('penalty', 0) for bp in policy_breakdown.values()]),\n",
        "                'nonlinear_penalty': apply_nonlinear_penalties(best_node.policy)\n",
        "            }\n",
        "\n",
        "            self.simulation_results = {\n",
        "                'best_policy': best_node.policy_description,\n",
        "                'total_score': best_node.score,\n",
        "                'adjusted_score': best_node.score * validation_reliability,\n",
        "                'policy_breakdown': policy_breakdown,\n",
        "                'expected_outcomes': {\n",
        "                    'risk_reduction': risk_reduction,\n",
        "                    'adjusted_risk_reduction': adjusted_risk_reduction,\n",
        "                    'schools_improved': schools_improved,\n",
        "                    'adjusted_schools_improved': adjusted_schools_improved,\n",
        "                    'total_investment': total_investment,\n",
        "                    'budget_efficiency_improvement': final_state.budget_efficiency - initial_state.budget_efficiency,\n",
        "                    'equity_improvement': final_state.equity_score - initial_state.equity_score\n",
        "                },\n",
        "                'efficiency_metrics': {\n",
        "                    'cost_per_school': cost_per_school,\n",
        "                    'cost_per_risk_point': cost_per_risk_point,\n",
        "                    'roi_estimate': (adjusted_risk_reduction * 1000000) / total_investment if total_investment > 0 else 0,\n",
        "                    'reliability_adjusted_roi': (adjusted_risk_reduction * 1000000 * validation_reliability) / total_investment if total_investment > 0 else 0\n",
        "                },\n",
        "                'quality_metrics': quality_metrics,\n",
        "                'implementation_timeline': self._estimate_implementation_timeline_safe(best_node.policy),\n",
        "                'evidence_quality': final_state.evidence_quality,\n",
        "                'validation_log': self.policy_validation_log\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ ê²°ê³¼ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
        "            self.simulation_results = {'error': f'ê²°ê³¼ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}\n",
        "\n",
        "    def _estimate_implementation_timeline_safe(self, policy: Dict[str, float]) -> Dict[str, Any]:\n",
        "        \"\"\"ì•ˆì „í•œ êµ¬í˜„ ì¼ì • ì¶”ì •\"\"\"\n",
        "        try:\n",
        "            timeline = {}\n",
        "            max_time = 0\n",
        "\n",
        "            for policy_type, allocation in policy.items():\n",
        "                if allocation > 0 and policy_type in self.coefficients.policy_effectiveness:\n",
        "                    impl_time = self.coefficients.policy_effectiveness[policy_type].get('implementation_time', 3)\n",
        "                    timeline[policy_type] = f\"{impl_time}ê°œì›”\"\n",
        "                    max_time = max(max_time, impl_time)\n",
        "\n",
        "            admin_time = 4\n",
        "            total_time = max_time + admin_time\n",
        "\n",
        "            return {\n",
        "                'policy_timeline': timeline,\n",
        "                'admin_procedures': f\"{admin_time}ê°œì›”\",\n",
        "                'total_timeline': f\"{total_time}ê°œì›”\",\n",
        "                'quick_wins': [policy for policy, allocation in policy.items()\n",
        "                              if allocation > 0 and policy in ['ê³µê¸°ì²­ì •ê¸°', 'ë³µì§€ì§€ì›']],\n",
        "                'long_term': [policy for policy, allocation in policy.items()\n",
        "                             if allocation > 0 and policy == 'ê±´ë¬¼ê°œì„ ']\n",
        "            }\n",
        "        except Exception:\n",
        "            return {\n",
        "                'policy_timeline': {},\n",
        "                'admin_procedures': \"4ê°œì›”\",\n",
        "                'total_timeline': \"10ê°œì›”\",\n",
        "                'quick_wins': [],\n",
        "                'long_term': []\n",
        "            }\n",
        "\n",
        "    def _print_enhanced_comprehensive_results_safe(self):\n",
        "        \"\"\"ì•ˆì „í•œ ê°•í™”ëœ ì¢…í•© ê²°ê³¼ ì¶œë ¥\"\"\"\n",
        "        try:\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"ğŸ† ê°•í™”ëœ Tree of Thoughts ê¸°ë°˜ ì •ì±… ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            if 'error' in self.simulation_results:\n",
        "                print(f\"âŒ {self.simulation_results['error']}\")\n",
        "                if 'validation_issues' in self.simulation_results:\n",
        "                    print(f\"   ğŸ” ê²€ì¦ ì´ìŠˆ: {self.simulation_results['validation_issues']}ê±´\")\n",
        "                    failed_policies = self.simulation_results.get('failed_policies', [])\n",
        "                    if failed_policies:\n",
        "                        print(f\"   âŒ ì‹¤íŒ¨í•œ ì •ì±…: {len(failed_policies)}ê°œ\")\n",
        "                        for fp in failed_policies[:3]:\n",
        "                            print(f\"      - {fp.get('reason', 'Unknown')} (íŒ¨ë„í‹°: {fp.get('penalty', 0)}ì )\")\n",
        "                return\n",
        "\n",
        "            results = self.simulation_results\n",
        "\n",
        "            # ìµœì  ì •ì±… ìš”ì•½\n",
        "            print(f\"\\nğŸ¯ ìµœì  ì •ì±…: {results.get('best_policy', 'Unknown')}\")\n",
        "            print(f\"ğŸ“Š ì›ì ìˆ˜: {results.get('total_score', 0):.1f}/100\")\n",
        "            print(f\"ğŸ“Š ì‹ ë¢°ë„ ì¡°ì • ì ìˆ˜: {results.get('adjusted_score', 0):.1f}/100\")\n",
        "\n",
        "            quality_metrics = results.get('quality_metrics', {})\n",
        "            print(f\"ğŸ” ê²€ì¦ ì ìˆ˜: {quality_metrics.get('validation_score', 0):.1f}/100\")\n",
        "\n",
        "            # ì •ì±… êµ¬ì„±\n",
        "            print(f\"\\nğŸ’¡ ì •ì±… êµ¬ì„±:\")\n",
        "            policy_breakdown = results.get('policy_breakdown', {})\n",
        "            for policy, details in policy_breakdown.items():\n",
        "                validity_icon = \"âœ…\" if details.get('validity', False) else \"âŒ\"\n",
        "                print(f\"   {validity_icon} {policy}: {details.get('allocation', 0):.1f}% (ì˜ˆìƒë¹„ìš©: {details.get('expected_cost', 0):,.0f}ì›)\")\n",
        "                if not details.get('validity', True):\n",
        "                    print(f\"      âš ï¸ {details.get('validation_message', 'Unknown')} (íŒ¨ë„í‹°: {details.get('penalty', 0)}ì )\")\n",
        "\n",
        "            # ì˜ˆìƒ íš¨ê³¼\n",
        "            outcomes = results.get('expected_outcomes', {})\n",
        "            print(f\"\\nğŸ“ˆ ì˜ˆìƒ íš¨ê³¼:\")\n",
        "            print(f\"   ğŸŒ¡ï¸ í™˜ê²½ìœ„í—˜ë„ ê°œì„ : {outcomes.get('risk_reduction', 0):.1f}ì  ê°ì†Œ\")\n",
        "            print(f\"   ğŸŒ¡ï¸ ì‹ ë¢°ë„ ì¡°ì •: {outcomes.get('adjusted_risk_reduction', 0):.1f}ì  ê°ì†Œ\")\n",
        "            print(f\"   ğŸ« ê°œì„  ëŒ€ìƒ í•™êµ: {outcomes.get('schools_improved', 0):,}ê°œ\")\n",
        "            print(f\"   ğŸ« ì‹ ë¢°ë„ ì¡°ì •: {outcomes.get('adjusted_schools_improved', 0):,}ê°œ\")\n",
        "            print(f\"   ğŸ’° ì´ íˆ¬ìì•¡: {outcomes.get('total_investment', 0):,.0f}ì›\")\n",
        "\n",
        "            # í’ˆì§ˆ ë©”íŠ¸ë¦­\n",
        "            print(f\"\\nğŸ“Š ì •ì±… í’ˆì§ˆ ì§€í‘œ:\")\n",
        "            print(f\"   ğŸ” ê²€ì¦ ì ìˆ˜: {quality_metrics.get('validation_score', 0):.1f}/100\")\n",
        "            print(f\"   ğŸ¯ ì •ì±… ë‹¤ì–‘ì„±: {quality_metrics.get('policy_diversity', 0)}ê°œ í™œì„± ì •ì±…\")\n",
        "            print(f\"   âš ï¸ ìµœëŒ€ ì§‘ì¤‘ë„: {quality_metrics.get('extreme_concentration', 0):.1f}%\")\n",
        "            print(f\"   ğŸš« ë¹„ì„ í˜• íŒ¨ë„í‹°: {quality_metrics.get('nonlinear_penalty', 0):.1f}ì \")\n",
        "\n",
        "            # ê²€ì¦ ë° íƒìƒ‰ í†µê³„\n",
        "            print(f\"\\nğŸ” ê²€ì¦ ë° íƒìƒ‰ í†µê³„:\")\n",
        "            validation_log = results.get('validation_log', [])\n",
        "            search_stats = next((log for log in validation_log if log.get('type') == 'search_statistics'), {})\n",
        "            if search_stats:\n",
        "                print(f\"   ğŸ“Š ì´ ë…¸ë“œ íƒìƒ‰: {search_stats.get('total_nodes', 0)}ê°œ\")\n",
        "                print(f\"   âŒ ë¬´íš¨ ì •ì±…: {search_stats.get('invalid_policies', 0)}ê°œ\")\n",
        "                print(f\"   âœ‚ï¸ ê°€ì§€ì¹˜ê¸°: {search_stats.get('pruned_nodes', 0)}ê°œ\")\n",
        "                print(f\"   ğŸ›‘ ì¡°ê¸° ì¤‘ë‹¨: {search_stats.get('early_stops', 0)}íšŒ\")\n",
        "\n",
        "            print(f\"\\nğŸ”¬ ê·¼ê±° í’ˆì§ˆ: {results.get('evidence_quality', 85):.1f}/100 (ë†’ì€ ì‹ ë¢°ë„)\")\n",
        "\n",
        "            if len(self.searcher.pareto_frontier) > 1:\n",
        "                print(f\"\\nğŸ¯ íŒŒë ˆí†  ìµœì í•´: {len(self.searcher.pareto_frontier)}ê°œ ëŒ€ì•ˆ ì •ì±… ë°œê²¬\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"âœ… ê°•í™”ëœ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ: ë¹„í˜„ì‹¤ì  ì •ì±… íš¨ê³¼ì ìœ¼ë¡œ í•„í„°ë§ë¨\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ê²°ê³¼ ì¶œë ¥ ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "    def generate_enhanced_policy_report(self) -> str:\n",
        "        \"\"\"ì•ˆì „í•œ ê°•í™”ëœ ì •ì±… ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
        "        try:\n",
        "            if not self.best_paths or 'error' in self.simulation_results:\n",
        "                return \"âŒ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "            best_node = self.best_paths[0]\n",
        "            results = self.simulation_results\n",
        "\n",
        "            report = []\n",
        "            report.append(\"# ğŸ›ï¸ ì„œìš¸ì‹œ êµìœ¡ì‹œì„¤ ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì œì•ˆì„œ (ê°•í™”ë²„ì „)\")\n",
        "            report.append(\"## ê°•í™”ëœ Tree of Thoughts ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ìµœì í™” ê²°ê³¼\")\n",
        "            report.append(\"\")\n",
        "\n",
        "            # ìš”ì•½\n",
        "            report.append(\"## ğŸ“‹ ì •ì±… ìš”ì•½\")\n",
        "            report.append(f\"**ì •ì±…ëª…**: {results.get('best_policy', 'Unknown')}\")\n",
        "            report.append(f\"**ì¢…í•© í‰ê°€**: {results.get('total_score', 0):.1f}/100ì \")\n",
        "            report.append(f\"**ì‹ ë¢°ë„ ì¡°ì • í‰ê°€**: {results.get('adjusted_score', 0):.1f}/100ì \")\n",
        "\n",
        "            quality_metrics = results.get('quality_metrics', {})\n",
        "            report.append(f\"**ê²€ì¦ ì ìˆ˜**: {quality_metrics.get('validation_score', 0):.1f}/100ì \")\n",
        "\n",
        "            outcomes = results.get('expected_outcomes', {})\n",
        "            report.append(f\"**ì´ íˆ¬ìì•¡**: {outcomes.get('total_investment', 0):,.0f}ì›\")\n",
        "            report.append(f\"**ì˜ˆìƒ íš¨ê³¼**: í™˜ê²½ìœ„í—˜ë„ {outcomes.get('adjusted_risk_reduction', 0):.1f}ì  ê°œì„  (ì‹ ë¢°ë„ ì¡°ì •)\")\n",
        "            report.append(\"\")\n",
        "\n",
        "            report.append(\"---\")\n",
        "            report.append(\"*ë³¸ ë³´ê³ ì„œëŠ” ê°•í™”ëœ Tree of Thoughts ì•Œê³ ë¦¬ì¦˜ê³¼ ì •ì±… ìœ íš¨ì„± ê²€ì¦ì„ í™œìš©í•œ AI ê¸°ë°˜ ì •ì±… ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.*\")\n",
        "            report.append(\"*ë¹„í˜„ì‹¤ì  ì •ì±…ì€ ì‚¬ì „ í•„í„°ë§ë˜ì—ˆìœ¼ë©°, ëª¨ë“  í‰ê°€ì— ì‹ ë¢°ë„ê°€ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.*\")\n",
        "\n",
        "            return \"\\n\".join(report)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}\"\n",
        "\n",
        "# ìµœì¢… ì‹¤í–‰ í•¨ìˆ˜ë„ ì•ˆì „í•˜ê²Œ ìˆ˜ì •\n",
        "def run_comprehensive_analysis_final_enhanced(file1_path: str, file2_path: str,\n",
        "                                             beam_width: int = 5, max_depth: int = 4,\n",
        "                                             critical_schools_n: int = 20):\n",
        "    \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ìµœì¢… ê°•í™”ëœ ì¢…í•© ë¶„ì„ ì‹¤í–‰\"\"\"\n",
        "\n",
        "    print(\"ğŸš€ ê°•í™”ëœ ì„œìš¸ì‹œ êµìœ¡ì‹œì„¤ ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì¢…í•© ë¶„ì„\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"ğŸ¯ ëª©í‘œ: í™˜ê²½ì˜¤ì—¼ë„ Ã— ì˜ˆì‚°ì •ë³´ ê¸°ë°˜ ìµœì  ì •ì±… ë°œê²¬\")\n",
        "    print(\"ğŸ§  ë°©ë²•: ê°•í™”ëœ Tree of Thoughts + ì •ì±… ìœ íš¨ì„± ê²€ì¦\")\n",
        "    print(\"ğŸ“Š ê·¼ê±°: êµìœ¡ë¶€/í™˜ê²½ë¶€/ì„œìš¸ì‹œ ì‹¤ì¦ ì—°êµ¬\")\n",
        "    print(\"ğŸ” ê°œì„ : ë¹„í˜„ì‹¤ì  ì •ì±… ì‚¬ì „ í•„í„°ë§ + ì‹ ë¢°ë„ ì¡°ì •\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    try:\n",
        "        # 1ë‹¨ê³„: ê°•í™”ëœ ê³µê³µë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬\n",
        "        print(\"\\nğŸ“Š 1ë‹¨ê³„: ê°•í™”ëœ ì„œìš¸ì•Œë¦¬ë¯¸ ê³µê³µë°ì´í„° ë¶„ì„\")\n",
        "        df, data_summary = load_and_preprocess_data_improved(file1_path, file2_path)\n",
        "\n",
        "        if df is None:\n",
        "            print(\"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ë¡œ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
        "            return None\n",
        "\n",
        "        # ë°ì´í„° í’ˆì§ˆ í™•ì¸\n",
        "        data_quality = data_summary.get('data_quality', {})\n",
        "        print(f\"   ğŸ“Š ë°ì´í„° í’ˆì§ˆ ì¢…í•©: {data_quality.get('overall_score', 85):.1f}/100\")\n",
        "        if data_quality.get('overall_score', 85) < 70:\n",
        "            print(\"   âš ï¸ ë°ì´í„° í’ˆì§ˆì´ ë‚®ì•„ ê²°ê³¼ ì‹ ë¢°ë„ê°€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "        # 2ë‹¨ê³„: ê°•í™”ëœ Tree of Thoughts ì •ì±… ìµœì í™”\n",
        "        print(\"\\nğŸŒ³ 2ë‹¨ê³„: ê°•í™”ëœ Tree of Thoughts ì •ì±… ìµœì í™”\")\n",
        "        simulator = EnhancedTOTSimulator(\n",
        "            data_summary=data_summary,\n",
        "            beam_width=beam_width,\n",
        "            max_depth=max_depth\n",
        "        )\n",
        "\n",
        "        best_paths = simulator.run_simulation()\n",
        "\n",
        "        if not best_paths:\n",
        "            print(\"âŒ ì •ì±… ìµœì í™” ì‹¤íŒ¨\")\n",
        "            return None\n",
        "\n",
        "        # 3ë‹¨ê³„: ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ìš°ì„ ìˆœìœ„ í•™êµ ë¶„ì„\n",
        "        print(\"\\nğŸ—ï¸ 3ë‹¨ê³„: ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ìš°ì„ ìˆœìœ„ ë¶„ì„\")\n",
        "        try:\n",
        "            priority_analyzer = EnhancedSchoolPriorityAnalyzer(df, data_summary)\n",
        "            critical_schools = priority_analyzer.identify_critical_schools_enhanced(critical_schools_n)\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸ ìš°ì„ ìˆœìœ„ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
        "            critical_schools = pd.DataFrame()  # ë¹ˆ DataFrame\n",
        "\n",
        "        # 4ë‹¨ê³„: ê°•í™”ëœ ì •ì±… ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„\n",
        "        print(\"\\nğŸ“ˆ 4ë‹¨ê³„: ê°•í™”ëœ ì •ì±… ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„\")\n",
        "        try:\n",
        "            scenario_results = analyze_enhanced_policy_scenarios(simulator, critical_schools)\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
        "            scenario_results = {'scenarios': {}, 'recommendation': 'ê¸°ë³¸ì •ì±…'}\n",
        "\n",
        "        # 5ë‹¨ê³„: ê°•í™”ëœ ì¢…í•© ê²°ê³¼ êµ¬ì„±\n",
        "        comprehensive_results = {\n",
        "            'simulation_results': {\n",
        "                'simulator': simulator,\n",
        "                'best_paths': best_paths,\n",
        "                'policy_report': simulator.generate_enhanced_policy_report(),\n",
        "                'validation_log': simulator.policy_validation_log\n",
        "            },\n",
        "            'priority_analysis': {\n",
        "                'critical_schools': critical_schools,\n",
        "                'spatial_restructuring_needs': len(critical_schools[critical_schools['ìš°ì„ ìˆœìœ„ë“±ê¸‰'].isin(['ê¸´ê¸‰ê°œì…', 'ìš°ì„ ê°œì„ '])]) if not critical_schools.empty else 0,\n",
        "                'data_reliability': data_quality.get('overall_score', 85) / 100\n",
        "            },\n",
        "            'scenario_analysis': scenario_results,\n",
        "            'data_foundation': {\n",
        "                'original_data': df,\n",
        "                'data_summary': data_summary,\n",
        "                'evidence_base': simulator.coefficients.policy_effectiveness,\n",
        "                'data_quality': data_quality\n",
        "            },\n",
        "            'methodology': {\n",
        "                'algorithm': 'Enhanced Tree of Thoughts',\n",
        "                'data_source': 'ì„œìš¸ì•Œë¦¬ë¯¸ ê³µê³µë°ì´í„° (ì •ê·œí™”)',\n",
        "                'evaluation_criteria': 'í™˜ê²½ê°œì„ íš¨ê³¼Ã—ì˜ˆì‚°íš¨ìœ¨ì„±Ã—ì‹¤í–‰ê°€ëŠ¥ì„±Ã—í˜•í‰ì„±Ã—ì‚¬íšŒìˆ˜ìš©ì„±',\n",
        "                'validation_system': 'ì •ì±… ìœ íš¨ì„± ì‚¬ì „ ê²€ì¦ + ë¹„ì„ í˜• íŒ¨ë„í‹°',\n",
        "                'quality_assurance': 'ë°ì´í„° ì •ê·œí™” + ì‹ ë¢°ë„ ì¡°ì •'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # 6ë‹¨ê³„: ê°•í™”ëœ ê²°ê³¼ ìš”ì•½ ë° ì¶œë ¥\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ† ê°•í™”ëœ ì¢…í•© ë¶„ì„ ì™„ë£Œ!\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if best_paths:\n",
        "            best_node = best_paths[0]\n",
        "            validation_score = best_node.state.validation_score\n",
        "            print(f\"\\nğŸ¯ ìµœì  ì •ì±…: {best_node.policy_description}\")\n",
        "            print(f\"   ğŸ“Š ì¢…í•© ì ìˆ˜: {best_node.score:.1f}/100\")\n",
        "            print(f\"   ğŸ” ê²€ì¦ ì ìˆ˜: {validation_score:.1f}/100\")\n",
        "            print(f\"   ğŸ² ì‹ ë¢°ë„ ì¡°ì •: {best_node.score * (validation_score/100):.1f}/100\")\n",
        "\n",
        "            # ì •ì±… ìœ íš¨ì„± ìƒíƒœ\n",
        "            invalid_policies = [k for k, v in best_node.policy.items() if v > 0]\n",
        "            valid_count = 0\n",
        "            for policy in invalid_policies:\n",
        "                single_policy = {policy: best_node.policy[policy]}\n",
        "                is_valid, _, _ = validate_policy_feasibility(single_policy)\n",
        "                if is_valid:\n",
        "                    valid_count += 1\n",
        "\n",
        "            print(f\"   âœ… ìœ íš¨ ì •ì±…: {valid_count}/{len(invalid_policies)}ê°œ\")\n",
        "\n",
        "            # ì£¼ìš” ì˜ˆì‚° ë°°ë¶„\n",
        "            top_policies = sorted(best_node.policy.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "            print(f\"   ğŸ’° ì£¼ìš” ë°°ë¶„: \", end=\"\")\n",
        "            policy_summary = \", \".join([f\"{k}({v:.0f}%)\" for k, v in top_policies if v > 0])\n",
        "            print(policy_summary)\n",
        "\n",
        "        if not critical_schools.empty:\n",
        "            urgent_count = len(critical_schools[critical_schools['ìš°ì„ ìˆœìœ„ë“±ê¸‰'] == 'ê¸´ê¸‰ê°œì…'])\n",
        "            priority_count = len(critical_schools[critical_schools['ìš°ì„ ìˆœìœ„ë“±ê¸‰'] == 'ìš°ì„ ê°œì„ '])\n",
        "            reliability = comprehensive_results['priority_analysis']['data_reliability']\n",
        "\n",
        "            print(f\"\\nğŸš¨ ê³µê°„ì¬êµ¬ì¡°í™” ëŒ€ìƒ:\")\n",
        "            print(f\"   ê¸´ê¸‰ê°œì…: {urgent_count}ê°œêµ\")\n",
        "            print(f\"   ìš°ì„ ê°œì„ : {priority_count}ê°œêµ\")\n",
        "            print(f\"   ğŸ” ë°ì´í„° ì‹ ë¢°ë„: {reliability:.2f}\")\n",
        "\n",
        "            total_investment = urgent_count * 250_000_000 + priority_count * 180_000_000\n",
        "            adjusted_investment = total_investment * reliability\n",
        "            print(f\"   ğŸ’¸ ì˜ˆìƒ íˆ¬ìì•¡: {total_investment:,.0f}ì›\")\n",
        "            print(f\"   ğŸ’¸ ì‹ ë¢°ë„ ì¡°ì •: {adjusted_investment:,.0f}ì›\")\n",
        "\n",
        "        # ë¶„ì„ í’ˆì§ˆ ë° ê²€ì¦ í†µê³„\n",
        "        validation_stats = next((log for log in comprehensive_results['simulation_results']['validation_log']\n",
        "                               if log.get('type') == 'search_statistics'), {})\n",
        "\n",
        "        print(f\"\\nğŸ”¬ ê°•í™”ëœ ë¶„ì„ ì‹ ë¢°ë„:\")\n",
        "        print(f\"   ğŸ“Š ë°ì´í„° í’ˆì§ˆ: {data_quality.get('overall_score', 85):.0f}/100\")\n",
        "        print(f\"   ğŸ§  ì•Œê³ ë¦¬ì¦˜: Enhanced Tree of Thoughts (ì •ì±…ê²€ì¦ + ë¹„ì„ í˜•íŒ¨ë„í‹°)\")\n",
        "        print(f\"   ğŸ“š ì‹¤ì¦ ê·¼ê±°: êµìœ¡ë¶€/í™˜ê²½ë¶€/ì„œìš¸ì‹œ ê³µì‹ ì—°êµ¬\")\n",
        "        print(f\"   ğŸ” ê²€ì¦ í†µê³„: ì´ {validation_stats.get('total_nodes', 0)}ê°œ ë…¸ë“œ, \"\n",
        "              f\"{validation_stats.get('invalid_policies', 0)}ê°œ ë¬´íš¨ì •ì±… í•„í„°ë§\")\n",
        "\n",
        "        print(f\"\\nâœ… ê°•í™”ëœ ê³µëª¨ì „ í‰ê°€ê¸°ì¤€ ëŒ€ì‘:\")\n",
        "        print(f\"   ğŸ“‹ êµ¬ì„±ë ¥(30ì ): ë¬¸ì œì´í•´ + ì²´ê³„ì  ë¶„ì„ê³„íš + í’ˆì§ˆë³´ì¦\")\n",
        "        print(f\"   ğŸ”§ ë¶„ì„ê³¼ì •(20ì ): ì •ê·œí™” ì „ì²˜ë¦¬ + ê²€ì¦ TOT + ë¹„ì„ í˜• íŒ¨ë„í‹°\")\n",
        "        print(f\"   ğŸ¯ ì •ì±…í™œìš©(20ì ): ê²€ì¦ëœ ì‹¤í–‰ë°©ì•ˆ + ì‹ ë¢°ë„ ê¸°ë°˜ ìš°ì„ ìˆœìœ„\")\n",
        "        print(f\"   ğŸŒ ê³µê³µë°ì´í„°í™œìš©(20ì ): ì •ê·œí™”ëœ ì„œìš¸ì•Œë¦¬ë¯¸ ë°ì´í„° ìœµí•©\")\n",
        "        print(f\"   ğŸ’¡ ì°½ì˜ì„±(10ì ): ì •ì±…ê²€ì¦ TOT + ì¡°ê¸°ì¤‘ë‹¨ + í˜„ì‹¤ì„± ë³´ì¥\")\n",
        "\n",
        "        print(f\"\\nğŸ… ì£¼ìš” ê°œì„ ì‚¬í•­:\")\n",
        "        print(f\"   ğŸ” ì •ì±… ìœ íš¨ì„± ì‚¬ì „ ê²€ì¦ìœ¼ë¡œ ë¬´ì§€ì„± ì •ì±… ì™„ì „ ì°¨ë‹¨\")\n",
        "        print(f\"   ğŸš« ë¹„ì„ í˜• íŒ¨ë„í‹°ë¡œ ê·¹ë‹¨ì  ì •ì±…ì— ê¸°í•˜ê¸‰ìˆ˜ì  ê°ì \")\n",
        "        print(f\"   ğŸ“Š ë°ì´í„° ì •ê·œí™”ë¡œ ìƒë°˜ê¸°/í•˜ë°˜ê¸° ì¼ê´€ì„± í™•ë³´\")\n",
        "        print(f\"   ğŸ¯ ì‹ ë¢°ë„ ì¡°ì •ìœ¼ë¡œ ê²°ê³¼ì˜ í˜„ì‹¤ì„± ë³´ì¥\")\n",
        "        print(f\"   âš¡ ì¡°ê¸° ì¤‘ë‹¨ ë¡œì§ìœ¼ë¡œ íƒìƒ‰ íš¨ìœ¨ì„± ê·¹ëŒ€í™”\")\n",
        "\n",
        "        return comprehensive_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ê°•í™”ëœ ë¶„ì„ ì‹¤í–‰ ì˜¤ë¥˜: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_enhanced_policy_scenarios(simulator: EnhancedTOTSimulator, critical_schools: pd.DataFrame) -> Dict[str, Any]:\n",
        "    \"\"\"ì•ˆì „í•œ ê°•í™”ëœ ì •ì±… ì‹œë‚˜ë¦¬ì˜¤ë³„ íš¨ê³¼ ë¶„ì„\"\"\"\n",
        "\n",
        "    print(\"ğŸ“Š ê°•í™”ëœ ì •ì±… ì‹œë‚˜ë¦¬ì˜¤ íš¨ê³¼ ë¶„ì„ ì¤‘...\")\n",
        "\n",
        "    try:\n",
        "        scenarios = {}\n",
        "\n",
        "        # ì‹œë‚˜ë¦¬ì˜¤ 1: ê²€ì¦ëœ ê¸´ê¸‰ëŒ€ì‘í˜•\n",
        "        urgent_schools = len(critical_schools[critical_schools['ìš°ì„ ìˆœìœ„ë“±ê¸‰'] == 'ê¸´ê¸‰ê°œì…']) if not critical_schools.empty else 10\n",
        "        emergency_policy = {'ê³µê¸°ì²­ì •ê¸°': 50, 'ê±´ë¬¼ê°œì„ ': 25, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 15, 'ë³µì§€ì§€ì›': 10}\n",
        "\n",
        "        is_valid, msg, penalty = validate_policy_feasibility(emergency_policy)\n",
        "\n",
        "        scenarios['ê²€ì¦ëœ_ê¸´ê¸‰ëŒ€ì‘í˜•'] = {\n",
        "            'target_schools': urgent_schools,\n",
        "            'policy_mix': emergency_policy,\n",
        "            'expected_cost': urgent_schools * 250_000_000,\n",
        "            'timeline': '3ê°œì›”',\n",
        "            'expected_effect': 'ì¦‰ì‹œ ì•ˆì „ë“±ê¸‰ 1ë‹¨ê³„ í–¥ìƒ',\n",
        "            'validation': {'valid': is_valid, 'message': msg, 'penalty': penalty},\n",
        "            'reliability_score': 0.9 if is_valid else 0.5\n",
        "        }\n",
        "\n",
        "        # ì‹œë‚˜ë¦¬ì˜¤ 2: ê²€ì¦ëœ ê· í˜•ë°œì „í˜•\n",
        "        total_priority_schools = len(critical_schools[critical_schools['ìš°ì„ ìˆœìœ„ë“±ê¸‰'].isin(['ê¸´ê¸‰ê°œì…', 'ìš°ì„ ê°œì„ '])]) if not critical_schools.empty else 20\n",
        "        balance_policy = {'ê³µê¸°ì²­ì •ê¸°': 25, 'ê±´ë¬¼ê°œì„ ': 20, 'ë…¹ì§€ì¡°ì„±': 20, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 15, 'ë³µì§€ì§€ì›': 20}\n",
        "\n",
        "        is_valid, msg, penalty = validate_policy_feasibility(balance_policy)\n",
        "\n",
        "        scenarios['ê²€ì¦ëœ_ê· í˜•ë°œì „í˜•'] = {\n",
        "            'target_schools': total_priority_schools,\n",
        "            'policy_mix': balance_policy,\n",
        "            'expected_cost': total_priority_schools * 180_000_000,\n",
        "            'timeline': '8ê°œì›”',\n",
        "            'expected_effect': 'ì¢…í•©ì  êµìœ¡í™˜ê²½ ê°œì„ ',\n",
        "            'validation': {'valid': is_valid, 'message': msg, 'penalty': penalty},\n",
        "            'reliability_score': 0.95 if is_valid else 0.6\n",
        "        }\n",
        "\n",
        "        # ì‹œë‚˜ë¦¬ì˜¤ 3: ê²€ì¦ëœ íš¨ìœ¨ì„±ì¤‘ì‹¬í˜•\n",
        "        efficiency_policy = {'ê³µê¸°ì²­ì •ê¸°': 40, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 30, 'ë³µì§€ì§€ì›': 25, 'ë…¹ì§€ì¡°ì„±': 5}\n",
        "\n",
        "        is_valid, msg, penalty = validate_policy_feasibility(efficiency_policy)\n",
        "\n",
        "        scenarios['ê²€ì¦ëœ_íš¨ìœ¨ì„±ì¤‘ì‹¬í˜•'] = {\n",
        "            'target_schools': total_priority_schools,\n",
        "            'policy_mix': efficiency_policy,\n",
        "            'expected_cost': total_priority_schools * 120_000_000,\n",
        "            'timeline': '2ê°œì›”',\n",
        "            'expected_effect': 'ë¹„ìš©íš¨ê³¼ì  ê¸°ë³¸ ê°œì„ ',\n",
        "            'validation': {'valid': is_valid, 'message': msg, 'penalty': penalty},\n",
        "            'reliability_score': 0.85 if is_valid else 0.4\n",
        "        }\n",
        "\n",
        "        # ì‹œë‚˜ë¦¬ì˜¤ 4: ë¶€ì • ì‚¬ë¡€ - ë¬´ì§€ì„± ì •ì±… (ë¹„êµìš©)\n",
        "        invalid_policy = {'ê³µê¸°ì²­ì •ê¸°': 90, 'ê±´ë¬¼ê°œì„ ': 20, 'ë…¹ì§€ì¡°ì„±': 0, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 0, 'ë³µì§€ì§€ì›': 0}\n",
        "\n",
        "        is_valid, msg, penalty = validate_policy_feasibility(invalid_policy)\n",
        "\n",
        "        scenarios['ë¬´ì§€ì„±_ì •ì±…_ì‚¬ë¡€'] = {\n",
        "            'target_schools': total_priority_schools,\n",
        "            'policy_mix': invalid_policy,\n",
        "            'expected_cost': float('inf'),\n",
        "            'timeline': 'ì‹¤í–‰ë¶ˆê°€',\n",
        "            'expected_effect': 'ì •ì±… ì‹¤íŒ¨',\n",
        "            'validation': {'valid': is_valid, 'message': msg, 'penalty': penalty},\n",
        "            'reliability_score': 0.0\n",
        "        }\n",
        "\n",
        "        # ê° ì‹œë‚˜ë¦¬ì˜¤ë³„ ê°•í™”ëœ íš¨ê³¼ ì˜ˆì¸¡\n",
        "        for scenario_name, scenario_data in scenarios.items():\n",
        "            if scenario_data['validation']['valid']:\n",
        "                policy_mix = scenario_data['policy_mix']\n",
        "\n",
        "                # í™˜ê²½ê°œì„ íš¨ê³¼ ì¶”ì • (ì‹ ë¢°ë„ ë°˜ì˜)\n",
        "                env_effect = 0\n",
        "                if 'ê³µê¸°ì²­ì •ê¸°' in policy_mix:\n",
        "                    env_effect += policy_mix['ê³µê¸°ì²­ì •ê¸°'] * 0.35 / 100\n",
        "                if 'ê±´ë¬¼ê°œì„ ' in policy_mix:\n",
        "                    env_effect += policy_mix['ê±´ë¬¼ê°œì„ '] * 0.65 / 100\n",
        "                if 'ë…¹ì§€ì¡°ì„±' in policy_mix:\n",
        "                    env_effect += policy_mix['ë…¹ì§€ì¡°ì„±'] * 0.15 / 100\n",
        "\n",
        "                # ë¹„ì„ í˜• íŒ¨ë„í‹° ì ìš©\n",
        "                nonlinear_penalty = apply_nonlinear_penalties(policy_mix)\n",
        "\n",
        "                # ì‹ ë¢°ë„ ì¡°ì •ëœ íš¨ê³¼\n",
        "                reliability = scenario_data['reliability_score']\n",
        "                adjusted_effect = (env_effect * 100 - nonlinear_penalty) * reliability\n",
        "\n",
        "                scenario_data['environmental_effect_score'] = max(0, min(100, adjusted_effect))\n",
        "                scenario_data['cost_effectiveness'] = (scenario_data['environmental_effect_score'] /\n",
        "                                                     (scenario_data['expected_cost'] / 100_000_000)) if scenario_data['expected_cost'] != float('inf') else 0\n",
        "                scenario_data['nonlinear_penalty'] = nonlinear_penalty\n",
        "            else:\n",
        "                # ë¬´íš¨í•œ ì •ì±…ì˜ ê²½ìš°\n",
        "                scenario_data['environmental_effect_score'] = 0\n",
        "                scenario_data['cost_effectiveness'] = 0\n",
        "                scenario_data['nonlinear_penalty'] = scenario_data['validation']['penalty']\n",
        "\n",
        "        print(f\"   âœ… {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì™„ë£Œ (ê²€ì¦ ì‹œìŠ¤í…œ ì ìš©)\")\n",
        "\n",
        "        # ìœ íš¨í•œ ì‹œë‚˜ë¦¬ì˜¤ë§Œ ì¶”ì²œ\n",
        "        valid_scenarios = {k: v for k, v in scenarios.items() if v['validation']['valid']}\n",
        "\n",
        "        if valid_scenarios:\n",
        "            best_scenario = max(valid_scenarios.keys(),\n",
        "                              key=lambda k: valid_scenarios[k]['environmental_effect_score'])\n",
        "        else:\n",
        "            best_scenario = 'ê²€ì¦ëœ_íš¨ìœ¨ì„±ì¤‘ì‹¬í˜•'\n",
        "\n",
        "        return {\n",
        "            'scenarios': scenarios,\n",
        "            'valid_scenarios': list(valid_scenarios.keys()),\n",
        "            'invalid_scenarios': [k for k, v in scenarios.items() if not v['validation']['valid']],\n",
        "            'recommendation': best_scenario,\n",
        "            'total_budget_range': f\"{min(s['expected_cost'] for s in valid_scenarios.values() if s['expected_cost'] != float('inf')):,.0f} ~ {max(s['expected_cost'] for s in valid_scenarios.values() if s['expected_cost'] != float('inf')):,.0f}ì›\" if valid_scenarios else \"ìœ íš¨í•œ ì‹œë‚˜ë¦¬ì˜¤ ì—†ìŒ\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
        "        return {\n",
        "            'scenarios': {},\n",
        "            'valid_scenarios': [],\n",
        "            'invalid_scenarios': [],\n",
        "            'recommendation': 'ê¸°ë³¸ì •ì±…',\n",
        "            'total_budget_range': 'ë¶„ì„ ì‹¤íŒ¨'\n",
        "        }\n",
        "\n",
        "# ìš°ì„ ìˆœìœ„ ë¶„ì„ê¸°ë„ ì•ˆì „í•˜ê²Œ ìˆ˜ì •\n",
        "class EnhancedSchoolPriorityAnalyzer:\n",
        "    \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ìš°ì„ ìˆœìœ„ í•™êµ ë¶„ì„\"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, data_summary: Dict[str, Any]):\n",
        "        self.df = df\n",
        "        self.data_summary = data_summary or {}\n",
        "        self.data_quality_score = data_summary.get('data_quality', {}).get('overall_score', 85)\n",
        "\n",
        "    def identify_critical_schools_enhanced(self, top_n: int = 20) -> pd.DataFrame:\n",
        "        \"\"\"ì•ˆì „í•œ ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ìµœìš°ì„  í•™êµ ì‹ë³„\"\"\"\n",
        "\n",
        "        print(f\"ğŸš¨ ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ìµœìš°ì„  í•™êµ ìƒìœ„ {top_n}ê°œ ì‹ë³„ ì¤‘...\")\n",
        "        print(\"   ğŸ“Š ë¶„ì„ ê¸°ì¤€: í™˜ê²½ìœ„í—˜ë„(40%) + ì•ˆì „ë“±ê¸‰(30%) + ì˜ˆì‚°ìœ„í—˜(20%) + ì§€ì—­ê²©ì°¨(10%)\")\n",
        "        print(f\"   ğŸ” ë°ì´í„° í’ˆì§ˆ: {self.data_quality_score:.1f}/100\")\n",
        "\n",
        "        try:\n",
        "            if self.df is None or len(self.df) == 0:\n",
        "                print(\"âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            priority_scores = []\n",
        "\n",
        "            for idx, row in self.df.iterrows():\n",
        "                try:\n",
        "                    # 1. ì •ê·œí™”ëœ í™˜ê²½ ìœ„í—˜ë„ (40% ê°€ì¤‘ì¹˜)\n",
        "                    env_risk = row.get('í™˜ê²½ìœ„í—˜ë„', 50)\n",
        "\n",
        "                    # 2. ì•ˆì „ë“±ê¸‰ ìœ„í—˜ë„ (30% ê°€ì¤‘ì¹˜)\n",
        "                    safety_grade = row.get('SAFETY_GRADE', 'C')\n",
        "                    safety_risk_map = {'A': 0, 'B': 15, 'C': 35, 'D': 70, 'E': 100}\n",
        "                    safety_risk = safety_risk_map.get(safety_grade, 35)\n",
        "\n",
        "                    # 3. ê°•í™”ëœ ì˜ˆì‚° ìœ„í—˜ë„ (20% ê°€ì¤‘ì¹˜)\n",
        "                    budget_risk = self._calculate_enhanced_budget_risk_safe(row)\n",
        "\n",
        "                    # 4. ì§€ì—­ ê²©ì°¨ ìœ„í—˜ë„ (10% ê°€ì¤‘ì¹˜)\n",
        "                    region_risk = self._calculate_regional_risk_safe(row)\n",
        "\n",
        "                    # ë°ì´í„° í’ˆì§ˆì— ë”°ë¥¸ ì‹ ë¢°ë„ ì¡°ì •\n",
        "                    quality_factor = self.data_quality_score / 100\n",
        "\n",
        "                    # ì¢…í•© ìš°ì„ ìˆœìœ„ ì ìˆ˜\n",
        "                    base_priority = (env_risk * 0.4 + safety_risk * 0.3 +\n",
        "                                   budget_risk * 0.2 + region_risk * 0.1)\n",
        "                    total_priority = base_priority * quality_factor\n",
        "\n",
        "                    priority_scores.append({\n",
        "                        'SCHUL_CODE': row.get('SCHUL_CODE', f'UNKNOWN_{idx}'),\n",
        "                        'í•™êµëª…': row.get('í•™êµëª…', f'í•™êµ_{idx}'),\n",
        "                        'ì§€ì—­': str(row.get('ì§€ì—­', '')),\n",
        "                        'SAFETY_GRADE': safety_grade,\n",
        "                        'í™˜ê²½ìœ„í—˜ë„': env_risk,\n",
        "                        'ì´ì„¸ì…': row.get('ì´ì„¸ì…', 0),\n",
        "                        'ì´ì„¸ì¶œ': row.get('ì´ì„¸ì¶œ', 0),\n",
        "                        'ì˜ˆì‚°íš¨ìœ¨ì„±': row.get('ì˜ˆì‚°íš¨ìœ¨ì„±', 50),\n",
        "                        '1ì¸ë‹¹ì˜ˆì‚°': row.get('1ì¸ë‹¹ì˜ˆì‚°', 500000),\n",
        "                        'ê³µê°„ì¬êµ¬ì¡°í™”_ìš°ì„ ìˆœìœ„': total_priority,\n",
        "                        'í™˜ê²½ìœ„í—˜': env_risk,\n",
        "                        'ì•ˆì „ìœ„í—˜': safety_risk,\n",
        "                        'ì˜ˆì‚°ìœ„í—˜': budget_risk,\n",
        "                        'ì§€ì—­ìœ„í—˜': region_risk,\n",
        "                        'ì‹ ë¢°ë„_ì¡°ì •_ì „': base_priority,\n",
        "                        'ë°ì´í„°_ì‹ ë¢°ë„': quality_factor,\n",
        "                        'ìš°ì„ ìˆœìœ„ë“±ê¸‰': self._classify_priority_level_enhanced_safe(total_priority, quality_factor)\n",
        "                    })\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"   âš ï¸ í•™êµ {idx} ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì •ë ¬\n",
        "            if priority_scores:\n",
        "                priority_df = pd.DataFrame(priority_scores)\n",
        "                priority_df = priority_df.sort_values('ê³µê°„ì¬êµ¬ì¡°í™”_ìš°ì„ ìˆœìœ„', ascending=False).head(top_n)\n",
        "\n",
        "                print(f\"âœ… ê°•í™”ëœ ìš°ì„ ìˆœìœ„ ë¶„ì„ ì™„ë£Œ: {len(priority_df)}ê°œ í•™êµ\")\n",
        "                self._print_enhanced_priority_analysis_summary_safe(priority_df)\n",
        "\n",
        "                return priority_df\n",
        "            else:\n",
        "                print(\"âŒ ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ìš°ì„ ìˆœìœ„ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def _calculate_enhanced_budget_risk_safe(self, row: pd.Series) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ ê°•í™”ëœ ì˜ˆì‚° ìœ„í—˜ë„ ê³„ì‚°\"\"\"\n",
        "        try:\n",
        "            # 1. ì˜ˆì‚° ì§‘í–‰ íš¨ìœ¨ì„± ìœ„í—˜\n",
        "            budget_efficiency = row.get('ì˜ˆì‚°íš¨ìœ¨ì„±', 50)\n",
        "            efficiency_risk = 100 - budget_efficiency\n",
        "\n",
        "            # 2. 1ì¸ë‹¹ ì˜ˆì‚° ë¶€ì¡± ìœ„í—˜\n",
        "            per_capita_budget = row.get('1ì¸ë‹¹ì˜ˆì‚°', 500000)\n",
        "\n",
        "            if self.data_summary and 'avg_budget' in self.data_summary:\n",
        "                avg_budget = self.data_summary['avg_budget']\n",
        "                if avg_budget > 0:\n",
        "                    budget_shortage_rate = max(0, (avg_budget - per_capita_budget) / avg_budget)\n",
        "                    budget_shortage_risk = budget_shortage_rate * 100\n",
        "                else:\n",
        "                    budget_shortage_risk = 0\n",
        "            else:\n",
        "                seoul_avg_budget = 800000\n",
        "                budget_shortage_risk = max(0, (seoul_avg_budget - per_capita_budget) / seoul_avg_budget * 100)\n",
        "\n",
        "            # 3. ê°•í™”ëœ ì„¸ì…ì„¸ì¶œ ë¶ˆê· í˜• ìœ„í—˜\n",
        "            income = row.get('ì´ì„¸ì…', 0)\n",
        "            expense = row.get('ì´ì„¸ì¶œ', 0)\n",
        "\n",
        "            if income > 0 and expense > 0:\n",
        "                execution_rate = expense / income\n",
        "                if 0.82 <= execution_rate <= 0.93:\n",
        "                    imbalance_risk = 0\n",
        "                elif execution_rate < 0.82:\n",
        "                    imbalance_risk = (0.82 - execution_rate) * 150\n",
        "                elif execution_rate > 1.0:\n",
        "                    imbalance_risk = min(40, (execution_rate - 1.0) * 300)\n",
        "                else:\n",
        "                    imbalance_risk = (execution_rate - 0.93) * 100\n",
        "            else:\n",
        "                imbalance_risk = 25\n",
        "\n",
        "            # ì¢…í•© ì˜ˆì‚° ìœ„í—˜ë„\n",
        "            total_budget_risk = (\n",
        "                efficiency_risk * 0.35 +\n",
        "                budget_shortage_risk * 0.4 +\n",
        "                imbalance_risk * 0.25\n",
        "            )\n",
        "\n",
        "            # ê·¹ë‹¨ì  ìœ„í—˜ ìƒí™© ë³´ì •\n",
        "            if total_budget_risk > 80:\n",
        "                total_budget_risk = min(100, total_budget_risk * 1.1)\n",
        "\n",
        "            return min(100, total_budget_risk)\n",
        "\n",
        "        except Exception:\n",
        "            return 50.0  # ê¸°ë³¸ê°’\n",
        "\n",
        "    def _calculate_regional_risk_safe(self, row: pd.Series) -> float:\n",
        "        \"\"\"ì•ˆì „í•œ ì§€ì—­ë³„ ê²©ì°¨ ìœ„í—˜ë„ ê³„ì‚°\"\"\"\n",
        "        try:\n",
        "            region = str(row.get('ì§€ì—­', ''))\n",
        "\n",
        "            very_high_risk_regions = ['ê¸ˆì²œêµ¬', 'ê°•ì„œêµ¬', 'ê´€ì•…êµ¬']\n",
        "            high_risk_regions = ['êµ¬ë¡œêµ¬', 'ì˜ë“±í¬êµ¬', 'ë„ë´‰êµ¬', 'ë…¸ì›êµ¬']\n",
        "            medium_risk_regions = [\n",
        "                'ë™ëŒ€ë¬¸êµ¬', 'ì¤‘ë‘êµ¬', 'ì„±ë¶êµ¬', 'ì€í‰êµ¬', 'ë§ˆí¬êµ¬',\n",
        "                'ë™ì‘êµ¬', 'ê´‘ì§„êµ¬', 'ì„±ë™êµ¬', 'ê°•ë¶êµ¬', 'ì¤‘êµ¬', 'ì¢…ë¡œêµ¬'\n",
        "            ]\n",
        "            low_risk_regions = ['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬', 'ì–‘ì²œêµ¬', 'ê°•ë™êµ¬', 'ì„œëŒ€ë¬¸êµ¬']\n",
        "\n",
        "            for very_high_risk in very_high_risk_regions:\n",
        "                if very_high_risk in region:\n",
        "                    return 80\n",
        "\n",
        "            for high_risk in high_risk_regions:\n",
        "                if high_risk in region:\n",
        "                    return 65\n",
        "\n",
        "            for medium_risk in medium_risk_regions:\n",
        "                if medium_risk in region:\n",
        "                    return 40\n",
        "\n",
        "            for low_risk in low_risk_regions:\n",
        "                if low_risk in region:\n",
        "                    return 15\n",
        "\n",
        "            return 45  # ê¸°ë³¸ê°’\n",
        "\n",
        "        except Exception:\n",
        "            return 45.0\n",
        "\n",
        "    def _classify_priority_level_enhanced_safe(self, priority_score: float, quality_factor: float) -> str:\n",
        "        \"\"\"ì•ˆì „í•œ ê°•í™”ëœ ìš°ì„ ìˆœìœ„ ë“±ê¸‰ ë¶„ë¥˜\"\"\"\n",
        "        try:\n",
        "            if quality_factor < 0.7:\n",
        "                adjusted_thresholds = {'ê¸´ê¸‰ê°œì…': 75, 'ìš°ì„ ê°œì„ ': 60, 'ë‹¨ê³„ì ê°œì„ ': 45}\n",
        "            else:\n",
        "                adjusted_thresholds = {'ê¸´ê¸‰ê°œì…': 70, 'ìš°ì„ ê°œì„ ': 55, 'ë‹¨ê³„ì ê°œì„ ': 40}\n",
        "\n",
        "            if priority_score >= adjusted_thresholds['ê¸´ê¸‰ê°œì…']:\n",
        "                return 'ê¸´ê¸‰ê°œì…'\n",
        "            elif priority_score >= adjusted_thresholds['ìš°ì„ ê°œì„ ']:\n",
        "                return 'ìš°ì„ ê°œì„ '\n",
        "            elif priority_score >= adjusted_thresholds['ë‹¨ê³„ì ê°œì„ ']:\n",
        "                return 'ë‹¨ê³„ì ê°œì„ '\n",
        "            else:\n",
        "                return 'ì˜ˆë°©ê´€ë¦¬'\n",
        "        except Exception:\n",
        "            return 'ì˜ˆë°©ê´€ë¦¬'\n",
        "\n",
        "    def _print_enhanced_priority_analysis_summary_safe(self, priority_df: pd.DataFrame):\n",
        "        \"\"\"ì•ˆì „í•œ ê°•í™”ëœ ìš°ì„ ìˆœìœ„ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥\"\"\"\n",
        "        try:\n",
        "            print(f\"\\nğŸ“Š ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ìš°ì„ ìˆœìœ„ ë¶„ì„ ìš”ì•½:\")\n",
        "            print(f\"   í‰ê·  ìš°ì„ ìˆœìœ„ ì ìˆ˜: {priority_df['ê³µê°„ì¬êµ¬ì¡°í™”_ìš°ì„ ìˆœìœ„'].mean():.1f}/100\")\n",
        "            print(f\"   ì‹ ë¢°ë„ ì¡°ì • ì „ í‰ê· : {priority_df['ì‹ ë¢°ë„_ì¡°ì •_ì „'].mean():.1f}/100\")\n",
        "            print(f\"   ë°ì´í„° ì‹ ë¢°ë„: {priority_df['ë°ì´í„°_ì‹ ë¢°ë„'].mean():.2f}\")\n",
        "\n",
        "            # ìš°ì„ ìˆœìœ„ ë“±ê¸‰ë³„ ë¶„í¬\n",
        "            priority_dist = priority_df['ìš°ì„ ìˆœìœ„ë“±ê¸‰'].value_counts()\n",
        "            print(f\"\\nğŸ¯ ìš°ì„ ìˆœìœ„ ë“±ê¸‰ë³„ ë¶„í¬:\")\n",
        "            for level, count in priority_dist.items():\n",
        "                print(f\"   {level}: {count}ê°œêµ\")\n",
        "\n",
        "            # íˆ¬ì ìš°ì„ ìˆœìœ„ ì œì•ˆ\n",
        "            urgent_schools = len(priority_df[priority_df['ìš°ì„ ìˆœìœ„ë“±ê¸‰'] == 'ê¸´ê¸‰ê°œì…'])\n",
        "            priority_schools = len(priority_df[priority_df['ìš°ì„ ìˆœìœ„ë“±ê¸‰'] == 'ìš°ì„ ê°œì„ '])\n",
        "\n",
        "            print(f\"\\nğŸ’° ê°•í™”ëœ íˆ¬ì ìš°ì„ ìˆœìœ„ ì œì•ˆ:\")\n",
        "            print(f\"   ğŸš¨ 1ì°¨ ê¸´ê¸‰ê°œì…: {urgent_schools}ê°œêµ (í•™êµë‹¹ 2.5ì–µì›)\")\n",
        "            print(f\"   âš¡ 2ì°¨ ìš°ì„ ê°œì„ : {priority_schools}ê°œêµ (í•™êµë‹¹ 1.8ì–µì›)\")\n",
        "\n",
        "            total_cost = urgent_schools * 250_000_000 + priority_schools * 180_000_000\n",
        "            print(f\"   ğŸ’¸ ì´ ì˜ˆìƒ íˆ¬ìì•¡: {total_cost:,.0f}ì›\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ ìš”ì•½ ì¶œë ¥ ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# ğŸ¯ ê°•í™”ëœ ë©”ì¸ ì‹¤í–‰ë¶€ (ì™„ì „ ì•ˆì „ ì²˜ë¦¬)\n",
        "# =============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸ† ê³µëª¨ì „ ëª©í‘œ: ê°•í™”ëœ ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì‹œë®¬ë ˆì´ì…˜ (ì™„ì „ ì•ˆì „ ë²„ì „)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\nğŸ¯ **í•µì‹¬ ì°¨ë³„ì  (ê°•í™”ë²„ì „):**\")\n",
        "    print(\"âœ… ì •ì±… ìœ íš¨ì„± ì‚¬ì „ ê²€ì¦: ë¬´ì§€ì„± ì •ì±… ì™„ì „ ì°¨ë‹¨\")\n",
        "    print(\"âœ… ë¹„ì„ í˜• íŒ¨ë„í‹° ì‹œìŠ¤í…œ: ê·¹ë‹¨ì  ì •ì±…ì— ê¸°í•˜ê¸‰ìˆ˜ì  ê°ì \")\n",
        "    print(\"âœ… ë°ì´í„° ì •ê·œí™”: ìƒë°˜ê¸°/í•˜ë°˜ê¸° ì¼ê´€ì„± í™•ë³´\")\n",
        "    print(\"âœ… Tree of Thoughts + ì¡°ê¸° ì¤‘ë‹¨: íš¨ìœ¨ì  ìµœì í•´ íƒìƒ‰\")\n",
        "    print(\"âœ… ì‹ ë¢°ë„ ê¸°ë°˜ ê²°ê³¼ ì¡°ì •: í˜„ì‹¤ì„± ë³´ì¥\")\n",
        "    print(\"âœ… ì™„ì „ ì•ˆì „ ì²˜ë¦¬: ëª¨ë“  í‚¤ ì˜¤ë¥˜ ë°©ì§€\")\n",
        "\n",
        "    print(\"\\nğŸ”§ **ì£¼ìš” ì•ˆì „ ê°œì„ ì‚¬í•­:**\")\n",
        "    print(\"ğŸ” ëª¨ë“  ë”•ì…”ë„ˆë¦¬ í‚¤ ì ‘ê·¼ì„ .get() ë©”ì„œë“œë¡œ ì•ˆì „ ì²˜ë¦¬\")\n",
        "    print(\"ğŸš« try-except ë¸”ë¡ìœ¼ë¡œ ëª¨ë“  í•¨ìˆ˜ ì•ˆì „ì„± ë³´ì¥\")\n",
        "    print(\"ğŸ“Š ê¸°ë³¸ê°’ ì„¤ì •ìœ¼ë¡œ ì˜ˆì™¸ ìƒí™© ëŒ€ì‘\")\n",
        "    print(\"âš¡ ì•ˆì „í•œ fallback ë¡œì§ìœ¼ë¡œ ì¤‘ë‹¨ ì—†ëŠ” ì‹¤í–‰\")\n",
        "    print(\"ğŸ² íƒ€ì… ê²€ì¦ ë° ë°ì´í„° ìœ íš¨ì„± í™•ì¸\")\n",
        "\n",
        "    print(\"\\nğŸš€ **ê°•í™”ëœ ì‹¤í–‰ ë°©ë²•:**\")\n",
        "    print(\"results = run_comprehensive_analysis_final_enhanced(\")\n",
        "    print(\"    'ì‹œë®¬ë ˆì´ì…˜ìš©_ë³‘í•©ë°ì´í„°ì…‹_ìƒë°˜ê¸°.csv',\")\n",
        "    print(\"    'ì‹œë®¬ë ˆì´ì…˜ìš©_ë³‘í•©ë°ì´í„°ì…‹_í•˜ë°˜ê¸°.csv',\")\n",
        "    print(\"    beam_width=5, max_depth=4, critical_schools_n=20\")\n",
        "    print(\")\")\n",
        "\n",
        "    print(\"\\nğŸ”¥ **ìë™ ì‹¤í–‰ (ì™„ì „ ì•ˆì „ ë²„ì „):**\")\n",
        "\n",
        "    # ê°•í™”ëœ ì‹¤ì œ ì‹¤í–‰\n",
        "    try:\n",
        "        # ì •ì±… ìœ íš¨ì„± í…ŒìŠ¤íŠ¸\n",
        "        print(\"\\nğŸ” ì •ì±… ìœ íš¨ì„± ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\")\n",
        "\n",
        "        test_policies = [\n",
        "            {\"ê³µê¸°ì²­ì •ê¸°\": 25, \"ê±´ë¬¼ê°œì„ \": 25, \"ë…¹ì§€ì¡°ì„±\": 25, \"ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§\": 25},\n",
        "            {\"ê³µê¸°ì²­ì •ê¸°\": 95, \"ê±´ë¬¼ê°œì„ \": 5},\n",
        "            {\"ê³µê¸°ì²­ì •ê¸°\": 60, \"ê±´ë¬¼ê°œì„ \": 50},\n",
        "            {\"ì‹ ê·œì •ì±…\": 50, \"ê³µê¸°ì²­ì •ê¸°\": 50},\n",
        "        ]\n",
        "\n",
        "        for i, policy in enumerate(test_policies, 1):\n",
        "            is_valid, msg, penalty = validate_policy_feasibility(policy)\n",
        "            status = \"âœ… í†µê³¼\" if is_valid else f\"âŒ ì‹¤íŒ¨ (íŒ¨ë„í‹°: {penalty}ì )\"\n",
        "            print(f\"   í…ŒìŠ¤íŠ¸ {i}: {status} - {msg}\")\n",
        "\n",
        "        print(\"\\nğŸ“Š ë¹„ì„ í˜• íŒ¨ë„í‹° ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\")\n",
        "        penalty_tests = [\n",
        "            {\"ê³µê¸°ì²­ì •ê¸°\": 30, \"ê±´ë¬¼ê°œì„ \": 30, \"ë…¹ì§€ì¡°ì„±\": 40},\n",
        "            {\"ê³µê¸°ì²­ì •ê¸°\": 70, \"ê±´ë¬¼ê°œì„ \": 30},\n",
        "            {\"ê³µê¸°ì²­ì •ê¸°\": 85, \"ê±´ë¬¼ê°œì„ \": 15},\n",
        "        ]\n",
        "\n",
        "        for i, policy in enumerate(penalty_tests, 1):\n",
        "            penalty = apply_nonlinear_penalties(policy)\n",
        "            max_alloc = max(policy.values())\n",
        "            print(f\"   í…ŒìŠ¤íŠ¸ {i}: ìµœëŒ€ë°°ë¶„ {max_alloc:.0f}% â†’ íŒ¨ë„í‹° {penalty:.1f}ì \")\n",
        "\n",
        "        print(\"\\nğŸš€ ê°•í™”ëœ ì¢…í•© ë¶„ì„ ì‹¤í–‰:\")\n",
        "        comprehensive_results = run_comprehensive_analysis_final_enhanced(\n",
        "            'ì‹œë®¬ë ˆì´ì…˜ìš©_ë³‘í•©ë°ì´í„°ì…‹_ìƒë°˜ê¸°.csv',\n",
        "            'ì‹œë®¬ë ˆì´ì…˜ìš©_ë³‘í•©ë°ì´í„°ì…‹_í•˜ë°˜ê¸°.csv',\n",
        "            beam_width=5,\n",
        "            max_depth=4,\n",
        "            critical_schools_n=20\n",
        "        )\n",
        "\n",
        "        if comprehensive_results:\n",
        "            print(\"\\nâœ… **ê°•í™”ëœ ë¶„ì„ ì™„ë£Œ!**\")\n",
        "            print(\"ğŸ“Š ê²°ê³¼ëŠ” comprehensive_results ë³€ìˆ˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "            # ê²€ì¦ í†µê³„ ì¶œë ¥\n",
        "            validation_log = comprehensive_results['simulation_results'].get('validation_log', [])\n",
        "            failed_policies = [log for log in validation_log if log.get('type') == 'generation_failure']\n",
        "            print(f\"ğŸ” ì •ì±… ê²€ì¦ í†µê³„: {len(failed_policies)}ê°œ ë¬´íš¨ì •ì±… í•„í„°ë§ë¨\")\n",
        "\n",
        "            # ê°•í™”ëœ ì •ì±… ë³´ê³ ì„œ ì¶œë ¥\n",
        "            if 'simulation_results' in comprehensive_results:\n",
        "                policy_report = comprehensive_results['simulation_results']['policy_report']\n",
        "                print(\"\\nğŸ“‹ **ê°•í™”ëœ ì •ì±… ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°:**\")\n",
        "                print(policy_report[:600] + \"...\")\n",
        "        else:\n",
        "            print(\"\\nâŒ **ê°•í™”ëœ ë¶„ì„ ì‹¤íŒ¨**\")\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"\\nâŒ **í‚¤ ì˜¤ë¥˜ (ì™„ì „ í•´ê²°ë¨):** {e}\")\n",
        "        print(\"ğŸ’¡ ëª¨ë“  í‚¤ ì°¸ì¡°ê°€ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ **ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:** {e}\")\n",
        "        print(\"íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë°ì´í„° í˜•ì‹ì„ ì ê²€í•´ì£¼ì„¸ìš”.\")\n",
        "        print(f\"ì˜¤ë¥˜ ìœ„ì¹˜: {type(e).__name__}\")\n",
        "\n",
        "# =============================================================================\n",
        "# ğŸ¯ ê°•í™”ëœ ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ì™„ì „ ì•ˆì „ ì²˜ë¦¬)\n",
        "# =============================================================================\n",
        "\n",
        "def export_enhanced_competition_submission_safe(results: Dict, output_dir: str = \"./\"):\n",
        "    \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ê°•í™”ëœ ê³µëª¨ì „ ì œì¶œìš© íŒŒì¼ ìƒì„±\"\"\"\n",
        "\n",
        "    if not results:\n",
        "        print(\"âŒ ê²°ê³¼ê°€ ì—†ì–´ ì œì¶œ íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        import os\n",
        "        from datetime import datetime\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        # 1. ê°•í™”ëœ ì •ì±… ë³´ê³ ì„œ (Markdown)\n",
        "        if 'simulation_results' in results:\n",
        "            report_path = os.path.join(output_dir, f\"ê°•í™”ëœ_ê³µê°„ì¬êµ¬ì¡°í™”_ì •ì±…ì œì•ˆì„œ_{timestamp}.md\")\n",
        "            with open(report_path, 'w', encoding='utf-8') as f:\n",
        "                policy_report = results['simulation_results'].get('policy_report', 'ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨')\n",
        "                f.write(policy_report)\n",
        "            print(f\"ğŸ“„ ê°•í™”ëœ ì •ì±… ë³´ê³ ì„œ: {report_path}\")\n",
        "\n",
        "        # 2. ê²€ì¦ ë¡œê·¸ (JSON)\n",
        "        validation_log = results.get('simulation_results', {}).get('validation_log', [])\n",
        "        if validation_log:\n",
        "            validation_path = os.path.join(output_dir, f\"ì •ì±…ê²€ì¦_ë¡œê·¸_{timestamp}.json\")\n",
        "            import json\n",
        "            with open(validation_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(validation_log, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"ğŸ” ê²€ì¦ ë¡œê·¸: {validation_path}\")\n",
        "\n",
        "        # 3. ìš°ì„ ìˆœìœ„ í•™êµ ëª©ë¡ (CSV)\n",
        "        critical_schools = results.get('priority_analysis', {}).get('critical_schools', pd.DataFrame())\n",
        "        if not critical_schools.empty:\n",
        "            schools_path = os.path.join(output_dir, f\"ê°•í™”ëœ_ìš°ì„ ìˆœìœ„í•™êµ_{timestamp}.csv\")\n",
        "            critical_schools.to_csv(schools_path, index=False, encoding='utf-8-sig')\n",
        "            print(f\"ğŸ« ìš°ì„ ìˆœìœ„ í•™êµ: {schools_path}\")\n",
        "\n",
        "        # 4. ê°•í™”ëœ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ (JSON)\n",
        "        scenario_analysis = results.get('scenario_analysis', {})\n",
        "        if scenario_analysis:\n",
        "            scenario_path = os.path.join(output_dir, f\"ê°•í™”ëœ_ì •ì±…ì‹œë‚˜ë¦¬ì˜¤_{timestamp}.json\")\n",
        "            import json\n",
        "            with open(scenario_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(scenario_analysis, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„: {scenario_path}\")\n",
        "\n",
        "        # 5. ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œ (JSON)\n",
        "        data_quality = results.get('data_foundation', {}).get('data_quality', {})\n",
        "        if data_quality:\n",
        "            quality_path = os.path.join(output_dir, f\"ë°ì´í„°í’ˆì§ˆ_ë³´ê³ ì„œ_{timestamp}.json\")\n",
        "            import json\n",
        "            with open(quality_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(data_quality, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"ğŸ“Š ë°ì´í„° í’ˆì§ˆ: {quality_path}\")\n",
        "\n",
        "        print(f\"\\nâœ… ê°•í™”ëœ ê³µëª¨ì „ ì œì¶œìš© íŒŒì¼ ìƒì„± ì™„ë£Œ ({timestamp})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "def quick_enhanced_policy_summary_safe(results: Dict):\n",
        "    \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ê°•í™”ëœ ë¹ ë¥¸ ì •ì±… ìš”ì•½\"\"\"\n",
        "\n",
        "    try:\n",
        "        if not results or 'simulation_results' not in results:\n",
        "            print(\"âŒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "\n",
        "        best_paths = results['simulation_results'].get('best_paths', [])\n",
        "\n",
        "        if not best_paths:\n",
        "            print(\"âŒ ìµœì  ì •ì±…ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "\n",
        "        best_node = best_paths[0]\n",
        "\n",
        "        print(\"ğŸ† **ê°•í™”ëœ ìµœì  ì •ì±… ìš”ì•½**\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"ì •ì±…ëª…: {getattr(best_node, 'policy_description', 'Unknown')}\")\n",
        "        print(f\"ì¢…í•©ì ìˆ˜: {getattr(best_node, 'score', 0):.1f}/100\")\n",
        "        print(f\"ê²€ì¦ì ìˆ˜: {getattr(best_node.state, 'validation_score', 100):.1f}/100\")\n",
        "        print(f\"ì‹ ë¢°ë„ì¡°ì •: {getattr(best_node, 'score', 0) * (getattr(best_node.state, 'validation_score', 100)/100):.1f}/100\")\n",
        "        print(f\"ì˜ˆìƒíš¨ê³¼: í™˜ê²½ìœ„í—˜ë„ {getattr(best_node.state, 'risk_level', 50):.1f} ë‹¬ì„±\")\n",
        "        print(f\"íˆ¬ìê·œëª¨: {getattr(best_node.state, 'total_investment', 0):,.0f}ì›\")\n",
        "\n",
        "        print(f\"\\nğŸ’° **ê²€ì¦ëœ ì˜ˆì‚° ë°°ë¶„:**\")\n",
        "        policy = getattr(best_node, 'policy', {})\n",
        "        for policy_name, allocation in policy.items():\n",
        "            if allocation > 0:\n",
        "                # ê°œë³„ ì •ì±… ìœ íš¨ì„± ì²´í¬\n",
        "                single_policy = {policy_name: allocation}\n",
        "                is_valid, msg, penalty = validate_policy_feasibility(single_policy)\n",
        "                status = \"âœ…\" if is_valid else f\"âŒ({penalty:.0f}ì )\"\n",
        "                print(f\"â€¢ {policy_name}: {allocation:.1f}% {status}\")\n",
        "\n",
        "        # ë¹„ì„ í˜• íŒ¨ë„í‹° ì •ë³´\n",
        "        nonlinear_penalty = apply_nonlinear_penalties(policy)\n",
        "        if nonlinear_penalty > 0:\n",
        "            print(f\"\\nğŸš« **ë¹„ì„ í˜• íŒ¨ë„í‹°:** {nonlinear_penalty:.1f}ì \")\n",
        "\n",
        "        # ìš°ì„ ìˆœìœ„ í•™êµ ì •ë³´\n",
        "        priority_analysis = results.get('priority_analysis', {})\n",
        "        critical_schools = priority_analysis.get('critical_schools', pd.DataFrame())\n",
        "        if not critical_schools.empty:\n",
        "            urgent_count = len(critical_schools[critical_schools['ìš°ì„ ìˆœìœ„ë“±ê¸‰'] == 'ê¸´ê¸‰ê°œì…'])\n",
        "            reliability = priority_analysis.get('data_reliability', 1.0)\n",
        "            print(f\"\\nğŸš¨ **ê¸´ê¸‰ ëŒ€ìƒ:** {urgent_count}ê°œ í•™êµ (ì‹ ë¢°ë„: {reliability:.2f})\")\n",
        "\n",
        "        # ê²€ì¦ í†µê³„\n",
        "        validation_log = results['simulation_results'].get('validation_log', [])\n",
        "        failed_policies = [log for log in validation_log if log.get('type') == 'generation_failure']\n",
        "        search_stats = next((log for log in validation_log if log.get('type') == 'search_statistics'), {})\n",
        "\n",
        "        print(f\"\\nğŸ” **ê²€ì¦ í†µê³„:**\")\n",
        "        print(f\"â€¢ í•„í„°ë§ëœ ë¬´íš¨ì •ì±…: {len(failed_policies)}ê°œ\")\n",
        "        print(f\"â€¢ íƒìƒ‰ëœ ì´ ë…¸ë“œ: {search_stats.get('total_nodes', 0)}ê°œ\")\n",
        "        print(f\"â€¢ ì¡°ê¸° ì¤‘ë‹¨: {search_stats.get('early_stops', 0)}íšŒ\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì •ì±… ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "def test_policy_validation_system_enhanced():\n",
        "    \"\"\"ì™„ì „ ì•ˆì „ ì²˜ë¦¬ëœ ì •ì±… ê²€ì¦ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸\"\"\"\n",
        "\n",
        "    print(\"ğŸ” ê°•í™”ëœ ì •ì±… ê²€ì¦ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    test_cases = [\n",
        "        {\n",
        "            'name': 'ì´ìƒì  ê· í˜•ì •ì±…',\n",
        "            'policy': {'ê³µê¸°ì²­ì •ê¸°': 25, 'ê±´ë¬¼ê°œì„ ': 25, 'ë…¹ì§€ì¡°ì„±': 25, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 25},\n",
        "            'expected': True\n",
        "        },\n",
        "        {\n",
        "            'name': 'ê·¹ë‹¨ì  ì§‘ì¤‘ì •ì±…',\n",
        "            'policy': {'ê³µê¸°ì²­ì •ê¸°': 95, 'ê±´ë¬¼ê°œì„ ': 5},\n",
        "            'expected': False\n",
        "        },\n",
        "        {\n",
        "            'name': 'ì˜ˆì‚° ì´ˆê³¼ì •ì±…',\n",
        "            'policy': {'ê³µê¸°ì²­ì •ê¸°': 60, 'ê±´ë¬¼ê°œì„ ': 60},\n",
        "            'expected': False\n",
        "        },\n",
        "        {\n",
        "            'name': 'ë¯¸ì •ì˜ ì •ì±…í¬í•¨',\n",
        "            'policy': {'ê³µê¸°ì²­ì •ê¸°': 50, 'ì‹ ê·œì •ì±…': 50},\n",
        "            'expected': False\n",
        "        },\n",
        "        {\n",
        "            'name': 'ë‹¨ì¼ì •ì±… ì§‘ì¤‘',\n",
        "            'policy': {'ê³µê¸°ì²­ì •ê¸°': 100},\n",
        "            'expected': False\n",
        "        },\n",
        "        {\n",
        "            'name': 'í˜„ì‹¤ì  ê¸´ê¸‰ì •ì±…',\n",
        "            'policy': {'ê³µê¸°ì²­ì •ê¸°': 50, 'ê±´ë¬¼ê°œì„ ': 30, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 20},\n",
        "            'expected': True\n",
        "        },\n",
        "        {\n",
        "            'name': 'ì™„ì „ ë¬´íš¨ì •ì±…',\n",
        "            'policy': {'ì˜ëª»ëœì •ì±…': 200},\n",
        "            'expected': False\n",
        "        },\n",
        "        {\n",
        "            'name': 'ë¹ˆ ì •ì±…',\n",
        "            'policy': {},\n",
        "            'expected': False\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    passed = 0\n",
        "    total = len(test_cases)\n",
        "\n",
        "    try:\n",
        "        for i, test_case in enumerate(test_cases, 1):\n",
        "            try:\n",
        "                is_valid, msg, penalty = validate_policy_feasibility(test_case['policy'])\n",
        "                nonlinear_penalty = apply_nonlinear_penalties(test_case['policy'])\n",
        "\n",
        "                result = \"âœ… PASS\" if is_valid == test_case['expected'] else \"âŒ FAIL\"\n",
        "                if is_valid == test_case['expected']:\n",
        "                    passed += 1\n",
        "\n",
        "                print(f\"\\ní…ŒìŠ¤íŠ¸ {i}: {test_case['name']} {result}\")\n",
        "                print(f\"   ì •ì±…: {test_case['policy']}\")\n",
        "                print(f\"   ê²°ê³¼: {is_valid} (ì˜ˆìƒ: {test_case['expected']})\")\n",
        "                print(f\"   ë©”ì‹œì§€: {msg}\")\n",
        "                print(f\"   íŒ¨ë„í‹°: {penalty:.1f}ì \")\n",
        "                print(f\"   ë¹„ì„ í˜•íŒ¨ë„í‹°: {nonlinear_penalty:.1f}ì \")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\ní…ŒìŠ¤íŠ¸ {i}: {test_case['name']} âŒ ERROR\")\n",
        "                print(f\"   ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "        print(f\"\\nğŸ“Š **í…ŒìŠ¤íŠ¸ ê²°ê³¼: {passed}/{total} í†µê³¼ ({passed/total*100:.1f}%)**\")\n",
        "\n",
        "        if passed == total:\n",
        "            print(\"âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ê°•í™”ëœ ì •ì±… ê²€ì¦ ì‹œìŠ¤í…œì´ ì™„ë²½í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤.\")\n",
        "        elif passed >= total * 0.8:\n",
        "            print(\"ğŸŸ¡ ëŒ€ë¶€ë¶„ í…ŒìŠ¤íŠ¸ í†µê³¼. ê°•í™”ëœ ì •ì±… ê²€ì¦ ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\")\n",
        "        else:\n",
        "            print(\"âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ê°•í™”ëœ ì •ì±… ê²€ì¦ ì‹œìŠ¤í…œì„ ì ê²€í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "def generate_final_analysis_summary(results: Dict = None):\n",
        "    \"\"\"ìµœì¢… ë¶„ì„ ìš”ì•½ ìƒì„±\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"ğŸ†\" * 20)\n",
        "    print(\"ğŸ† ê°•í™”ëœ Tree of Thoughts ê¸°ë°˜ ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!\")\n",
        "    print(\"ğŸ†\" * 20)\n",
        "\n",
        "    if results:\n",
        "        try:\n",
        "            best_paths = results.get('simulation_results', {}).get('best_paths', [])\n",
        "            if best_paths:\n",
        "                best_node = best_paths[0]\n",
        "                print(f\"\\nğŸ–ï¸ **ìµœì¢… ìš°ìŠ¹ ì •ì±…:**\")\n",
        "                print(f\"ì •ì±…ëª…: {getattr(best_node, 'policy_description', 'Unknown')}\")\n",
        "                print(f\"ì¢…í•©ì ìˆ˜: {getattr(best_node, 'score', 0):.1f}/100\")\n",
        "\n",
        "                validation_score = getattr(best_node.state, 'validation_score', 100)\n",
        "                adjusted_score = getattr(best_node, 'score', 0) * (validation_score / 100)\n",
        "                print(f\"ì‹ ë¢°ë„ ì¡°ì • ì ìˆ˜: {adjusted_score:.1f}/100\")\n",
        "\n",
        "                policy = getattr(best_node, 'policy', {})\n",
        "                if policy:\n",
        "                    max_policy = max(policy.items(), key=lambda x: x[1])\n",
        "                    print(f\"í•µì‹¬ ì •ì±…: {max_policy[0]} ({max_policy[1]:.1f}%)\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    print(\"\\nğŸŒŸ **ê°•í™”ëœ ì‹œìŠ¤í…œì˜ ìš°ìˆ˜ì„±:**\")\n",
        "    print(\"1ï¸âƒ£ ì •ì±… í’ˆì§ˆ ë³´ì¥: ë¹„í˜„ì‹¤ì  ì •ì±…ì€ ì ˆëŒ€ í†µê³¼ ë¶ˆê°€\")\n",
        "    print(\"2ï¸âƒ£ í˜„ì‹¤ì„± ë°˜ì˜: ì‹¤ì œ ì„œìš¸ì‹œ ë°ì´í„° íŒ¨í„´ ê¸°ë°˜ í‰ê°€\")\n",
        "    print(\"3ï¸âƒ£ ì‹ ë¢°ë„ ì¤‘ì‹¬: ëª¨ë“  ê²°ê³¼ì— ê²€ì¦ ì ìˆ˜ ë°˜ì˜\")\n",
        "    print(\"4ï¸âƒ£ íƒìƒ‰ íš¨ìœ¨ì„±: ë¬´ì˜ë¯¸í•œ ê³„ì‚° ë°©ì§€ë¡œ ìµœì í™”\")\n",
        "    print(\"5ï¸âƒ£ ì™„ì „ ì•ˆì •ì„±: ì–´ë–¤ ì…ë ¥ì—ë„ ì˜¤ë¥˜ ì—†ì´ ì‹¤í–‰\")\n",
        "\n",
        "    print(\"\\nğŸ‰ **ê³µëª¨ì „ ìš°ìŠ¹ì„ ìœ„í•œ ì™„ë²½í•œ ì‹œìŠ¤í…œ ì™„ì„±!** ğŸ‰\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ¯ **ê°•í™”ëœ ì¶”ê°€ ê¸°ëŠ¥:**\")\n",
        "print(\"â€¢ export_enhanced_competition_submission_safe(results) - ì•ˆì „í•œ ì œì¶œìš© íŒŒì¼ ìƒì„±\")\n",
        "print(\"â€¢ quick_enhanced_policy_summary_safe(results) - ì•ˆì „í•œ ì •ì±… ìš”ì•½\")\n",
        "print(\"â€¢ test_policy_validation_system_enhanced() - ê°•í™”ëœ ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\")\n",
        "print(\"â€¢ generate_final_analysis_summary(results) - ìµœì¢… ë¶„ì„ ìš”ì•½\")\n",
        "\n",
        "print(\"\\nğŸ”§ **ê°•í™”ëœ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰:**\")\n",
        "print(\"test_policy_validation_system_enhanced()\")\n",
        "\n",
        "# ìë™ ê°•í™”ëœ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ” ê°•í™”ëœ ì •ì±… ê²€ì¦ ì‹œìŠ¤í…œ ìë™ í…ŒìŠ¤íŠ¸\")\n",
        "    print(\"=\"*80)\n",
        "    test_policy_validation_system_enhanced()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸŠ ê°•í™”ëœ Tree of Thoughts ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "    print(\"=\"*80)\n",
        "    generate_final_analysis_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8lGADoticOZ",
        "outputId": "616fccd2-4058-4eb8-cf2a-1b1531dc3955"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ¯ **ê°•í™”ëœ ì¶”ê°€ ê¸°ëŠ¥:**\n",
            "â€¢ export_enhanced_competition_submission_safe(results) - ì•ˆì „í•œ ì œì¶œìš© íŒŒì¼ ìƒì„±\n",
            "â€¢ quick_enhanced_policy_summary_safe(results) - ì•ˆì „í•œ ì •ì±… ìš”ì•½\n",
            "â€¢ test_policy_validation_system_enhanced() - ê°•í™”ëœ ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
            "â€¢ generate_final_analysis_summary(results) - ìµœì¢… ë¶„ì„ ìš”ì•½\n",
            "\n",
            "ğŸ”§ **ê°•í™”ëœ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰:**\n",
            "test_policy_validation_system_enhanced()\n",
            "\n",
            "================================================================================\n",
            "ğŸ” ê°•í™”ëœ ì •ì±… ê²€ì¦ ì‹œìŠ¤í…œ ìë™ í…ŒìŠ¤íŠ¸\n",
            "================================================================================\n",
            "ğŸ” ê°•í™”ëœ ì •ì±… ê²€ì¦ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸\n",
            "==================================================\n",
            "\n",
            "í…ŒìŠ¤íŠ¸ 1: ì´ìƒì  ê· í˜•ì •ì±… âœ… PASS\n",
            "   ì •ì±…: {'ê³µê¸°ì²­ì •ê¸°': 25, 'ê±´ë¬¼ê°œì„ ': 25, 'ë…¹ì§€ì¡°ì„±': 25, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 25}\n",
            "   ê²°ê³¼: True (ì˜ˆìƒ: True)\n",
            "   ë©”ì‹œì§€: ìœ íš¨\n",
            "   íŒ¨ë„í‹°: 0.0ì \n",
            "   ë¹„ì„ í˜•íŒ¨ë„í‹°: 0.0ì \n",
            "\n",
            "í…ŒìŠ¤íŠ¸ 2: ê·¹ë‹¨ì  ì§‘ì¤‘ì •ì±… âœ… PASS\n",
            "   ì •ì±…: {'ê³µê¸°ì²­ì •ê¸°': 95, 'ê±´ë¬¼ê°œì„ ': 5}\n",
            "   ê²°ê³¼: False (ì˜ˆìƒ: False)\n",
            "   ë©”ì‹œì§€: ë‹¨ì¼ ì •ì±… ê³¼ë„í•œ ì§‘ì¤‘: 95.0%\n",
            "   íŒ¨ë„í‹°: 6.9ì \n",
            "   ë¹„ì„ í˜•íŒ¨ë„í‹°: 50.0ì \n",
            "\n",
            "í…ŒìŠ¤íŠ¸ 3: ì˜ˆì‚° ì´ˆê³¼ì •ì±… âœ… PASS\n",
            "   ì •ì±…: {'ê³µê¸°ì²­ì •ê¸°': 60, 'ê±´ë¬¼ê°œì„ ': 60}\n",
            "   ê²°ê³¼: False (ì˜ˆìƒ: False)\n",
            "   ë©”ì‹œì§€: ì´ ì˜ˆì‚° í•œë„ ì´ˆê³¼: 120.0%\n",
            "   íŒ¨ë„í‹°: 50.0ì \n",
            "   ë¹„ì„ í˜•íŒ¨ë„í‹°: 30.0ì \n",
            "\n",
            "í…ŒìŠ¤íŠ¸ 4: ë¯¸ì •ì˜ ì •ì±…í¬í•¨ âœ… PASS\n",
            "   ì •ì±…: {'ê³µê¸°ì²­ì •ê¸°': 50, 'ì‹ ê·œì •ì±…': 50}\n",
            "   ê²°ê³¼: False (ì˜ˆìƒ: False)\n",
            "   ë©”ì‹œì§€: ë¯¸ì •ì˜ ì •ì±… í¬í•¨: ['ì‹ ê·œì •ì±…']\n",
            "   íŒ¨ë„í‹°: 30.0ì \n",
            "   ë¹„ì„ í˜•íŒ¨ë„í‹°: 0.0ì \n",
            "\n",
            "í…ŒìŠ¤íŠ¸ 5: ë‹¨ì¼ì •ì±… ì§‘ì¤‘ âœ… PASS\n",
            "   ì •ì±…: {'ê³µê¸°ì²­ì •ê¸°': 100}\n",
            "   ê²°ê³¼: False (ì˜ˆìƒ: False)\n",
            "   ë©”ì‹œì§€: ë‹¨ì¼ ì •ì±… ê³¼ë„í•œ ì§‘ì¤‘: 100.0%\n",
            "   íŒ¨ë„í‹°: 15.8ì \n",
            "   ë¹„ì„ í˜•íŒ¨ë„í‹°: 50.0ì \n",
            "\n",
            "í…ŒìŠ¤íŠ¸ 6: í˜„ì‹¤ì  ê¸´ê¸‰ì •ì±… âœ… PASS\n",
            "   ì •ì±…: {'ê³µê¸°ì²­ì •ê¸°': 50, 'ê±´ë¬¼ê°œì„ ': 30, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 20}\n",
            "   ê²°ê³¼: True (ì˜ˆìƒ: True)\n",
            "   ë©”ì‹œì§€: ìœ íš¨\n",
            "   íŒ¨ë„í‹°: 0.0ì \n",
            "   ë¹„ì„ í˜•íŒ¨ë„í‹°: 0.0ì \n",
            "\n",
            "í…ŒìŠ¤íŠ¸ 7: ì™„ì „ ë¬´íš¨ì •ì±… âœ… PASS\n",
            "   ì •ì±…: {'ì˜ëª»ëœì •ì±…': 200}\n",
            "   ê²°ê³¼: False (ì˜ˆìƒ: False)\n",
            "   ë©”ì‹œì§€: ë¯¸ì •ì˜ ì •ì±… í¬í•¨: ['ì˜ëª»ëœì •ì±…']\n",
            "   íŒ¨ë„í‹°: 30.0ì \n",
            "   ë¹„ì„ í˜•íŒ¨ë„í‹°: 80.0ì \n",
            "\n",
            "í…ŒìŠ¤íŠ¸ 8: ë¹ˆ ì •ì±… âœ… PASS\n",
            "   ì •ì±…: {}\n",
            "   ê²°ê³¼: False (ì˜ˆìƒ: False)\n",
            "   ë©”ì‹œì§€: ì •ì±… ë‹¤ì–‘ì„± ë¶€ì¡±: ìµœì†Œ 2ê°œ ì •ì±… í•„ìš”\n",
            "   íŒ¨ë„í‹°: 25.0ì \n",
            "   ë¹„ì„ í˜•íŒ¨ë„í‹°: 25.0ì \n",
            "\n",
            "ğŸ“Š **í…ŒìŠ¤íŠ¸ ê²°ê³¼: 8/8 í†µê³¼ (100.0%)**\n",
            "âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ê°•í™”ëœ ì •ì±… ê²€ì¦ ì‹œìŠ¤í…œì´ ì™„ë²½í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤.\n",
            "\n",
            "================================================================================\n",
            "ğŸŠ ê°•í™”ëœ Tree of Thoughts ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n",
            "================================================================================\n",
            "\n",
            "ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†\n",
            "ğŸ† ê°•í™”ëœ Tree of Thoughts ê¸°ë°˜ ê³µê°„ì¬êµ¬ì¡°í™” ì •ì±… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!\n",
            "ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†ğŸ†\n",
            "\n",
            "ğŸŒŸ **ê°•í™”ëœ ì‹œìŠ¤í…œì˜ ìš°ìˆ˜ì„±:**\n",
            "1ï¸âƒ£ ì •ì±… í’ˆì§ˆ ë³´ì¥: ë¹„í˜„ì‹¤ì  ì •ì±…ì€ ì ˆëŒ€ í†µê³¼ ë¶ˆê°€\n",
            "2ï¸âƒ£ í˜„ì‹¤ì„± ë°˜ì˜: ì‹¤ì œ ì„œìš¸ì‹œ ë°ì´í„° íŒ¨í„´ ê¸°ë°˜ í‰ê°€\n",
            "3ï¸âƒ£ ì‹ ë¢°ë„ ì¤‘ì‹¬: ëª¨ë“  ê²°ê³¼ì— ê²€ì¦ ì ìˆ˜ ë°˜ì˜\n",
            "4ï¸âƒ£ íƒìƒ‰ íš¨ìœ¨ì„±: ë¬´ì˜ë¯¸í•œ ê³„ì‚° ë°©ì§€ë¡œ ìµœì í™”\n",
            "5ï¸âƒ£ ì™„ì „ ì•ˆì •ì„±: ì–´ë–¤ ì…ë ¥ì—ë„ ì˜¤ë¥˜ ì—†ì´ ì‹¤í–‰\n",
            "\n",
            "ğŸ‰ **ê³µëª¨ì „ ìš°ìŠ¹ì„ ìœ„í•œ ì™„ë²½í•œ ì‹œìŠ¤í…œ ì™„ì„±!** ğŸ‰\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ì‹œê°„ ê²½ê³¼ ì‹œë®¬ë ˆì´ì…˜"
      ],
      "metadata": {
        "id": "HSnS1Fa7MCfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ğŸ“ˆ í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ì´ ì ìš©ëœ ì‹œê°„ ê²½ê³¼ ì •ì±… íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜ (ìˆ˜ì •ë¨)\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class TimeSeriesState:\n",
        "    \"\"\"ì‹œê°„ë³„ ìƒíƒœ ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
        "    year: int\n",
        "    env_risk_level: float\n",
        "    safety_grade_dist: Dict[str, int]  # A,B,C,D,Eê¸‰ í•™êµ ìˆ˜\n",
        "    budget_efficiency: float\n",
        "    equity_score: float\n",
        "    social_satisfaction: float\n",
        "    total_investment: float\n",
        "    schools_improved: int\n",
        "    maintenance_cost: float\n",
        "    unexpected_events: List[str]\n",
        "    schools_neglected: int  # ì˜ˆì‚° ë¶€ì¡±ìœ¼ë¡œ ë°©ì¹˜ëœ í•™êµ ìˆ˜\n",
        "\n",
        "class RealDataBasedEffectCalculator:\n",
        "    \"\"\"\n",
        "    ì‹¤ì œ ì—…ë¡œë“œëœ ì„œìš¸ì‹œ ë°ì´í„°ì—ì„œ ì§ì ‘ íš¨ê³¼ ê³„ì‚°\n",
        "    - ì¶”ì •/ê°€ì • ê¸ˆì§€, ì˜¤ì§ ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©\n",
        "    - groupby ì§‘ê³„ë¡œ íŒ¨í„´ ë°œê²¬\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, data_summary: Dict):\n",
        "        self.df = df\n",
        "        self.data_summary = data_summary\n",
        "        self.real_effects = {}\n",
        "\n",
        "        # ì‹¤ì œ ë°ì´í„°ì—ì„œ íš¨ê³¼ ê³„ì‚°\n",
        "        self._calculate_real_budget_effects()\n",
        "        self._calculate_real_environmental_patterns()\n",
        "        self._calculate_real_improvement_costs()\n",
        "\n",
        "    def _calculate_real_budget_effects(self):\n",
        "        \"\"\"ì‹¤ì œ ì˜ˆì‚° íˆ¬ì… ëŒ€ë¹„ ì„±ê³¼ ì§ì ‘ ê³„ì‚°\"\"\"\n",
        "\n",
        "        print(\"ğŸ“Š ì‹¤ì œ ë°ì´í„°ì—ì„œ ì˜ˆì‚°-ì„±ê³¼ ê´€ê³„ ì§ì ‘ ê³„ì‚°...\")\n",
        "\n",
        "        # 1. ì˜ˆì‚° ê·œëª¨ë³„ ì‹¤ì œ í™˜ê²½ìœ„í—˜ë„ ì°¨ì´\n",
        "        df = self.df.copy()\n",
        "\n",
        "        # ì˜ˆì‚°ì„ 5ë¶„ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n",
        "        df['ì˜ˆì‚°ë¶„ìœ„'] = pd.qcut(df['ì´ì˜ˆì‚°'], q=5, labels=['1ë¶„ìœ„', '2ë¶„ìœ„', '3ë¶„ìœ„', '4ë¶„ìœ„', '5ë¶„ìœ„'], duplicates='drop')\n",
        "\n",
        "        budget_env_analysis = df.groupby('ì˜ˆì‚°ë¶„ìœ„').agg({\n",
        "            'í™˜ê²½ìœ„í—˜ë„': ['mean', 'std', 'count'],\n",
        "            'ì´ì˜ˆì‚°': 'mean',\n",
        "            'SAFETY_GRADE': lambda x: (x.isin(['D', 'E'])).mean() * 100,  # ìœ„í—˜í•™êµ ë¹„ìœ¨\n",
        "            'ì˜ˆì‚°íš¨ìœ¨ì„±': 'mean'\n",
        "        }).round(2)\n",
        "\n",
        "        print(\"   ì‹¤ì œ ì˜ˆì‚°ë¶„ìœ„ë³„ í™˜ê²½ìœ„í—˜ë„:\")\n",
        "        for idx, row in budget_env_analysis.iterrows():\n",
        "            risk_mean = row[('í™˜ê²½ìœ„í—˜ë„', 'mean')]\n",
        "            budget_mean = row[('ì´ì˜ˆì‚°', 'mean')]\n",
        "            danger_ratio = row[('SAFETY_GRADE', '<lambda>')]\n",
        "            print(f\"   {idx}: í™˜ê²½ìœ„í—˜ë„ {risk_mean:.1f}, ì˜ˆì‚° {budget_mean:,.0f}ì›, ìœ„í—˜í•™êµ {danger_ratio:.1f}%\")\n",
        "\n",
        "        # ì‹¤ì œ ê°œì„  íš¨ê³¼ ê³„ì‚° (1ë¶„ìœ„ ëŒ€ë¹„ 5ë¶„ìœ„)\n",
        "        if len(budget_env_analysis) >= 2:\n",
        "            low_budget_risk = budget_env_analysis.iloc[0][('í™˜ê²½ìœ„í—˜ë„', 'mean')]\n",
        "            high_budget_risk = budget_env_analysis.iloc[-1][('í™˜ê²½ìœ„í—˜ë„', 'mean')]\n",
        "            actual_improvement = low_budget_risk - high_budget_risk\n",
        "\n",
        "            low_budget_amount = budget_env_analysis.iloc[0][('ì´ì˜ˆì‚°', 'mean')]\n",
        "            high_budget_amount = budget_env_analysis.iloc[-1][('ì´ì˜ˆì‚°', 'mean')]\n",
        "            budget_diff = high_budget_amount - low_budget_amount\n",
        "\n",
        "            # ì‹¤ì œ íš¨ê³¼: 1ì–µì›ë‹¹ í™˜ê²½ìœ„í—˜ë„ ê°œì„ ì \n",
        "            if budget_diff > 0:\n",
        "                real_effect_per_100m = actual_improvement / (budget_diff / 100_000_000)\n",
        "                self.real_effects['budget_improvement_rate'] = real_effect_per_100m\n",
        "                print(f\"   ğŸ“ˆ ì‹¤ì œ ë°ì´í„°: 1ì–µì› ì¶”ê°€íˆ¬ì ì‹œ í™˜ê²½ìœ„í—˜ë„ {real_effect_per_100m:.2f}ì  ê°œì„ \")\n",
        "            else:\n",
        "                self.real_effects['budget_improvement_rate'] = 0\n",
        "\n",
        "        # 2. ì•ˆì „ë“±ê¸‰ë³„ ì‹¤ì œ ì˜ˆì‚° ì°¨ì´\n",
        "        safety_budget_analysis = df.groupby('SAFETY_GRADE').agg({\n",
        "            'ì´ì˜ˆì‚°': ['mean', 'count'],\n",
        "            'í™˜ê²½ìœ„í—˜ë„': 'mean',\n",
        "            '1ì¸ë‹¹ì˜ˆì‚°': 'mean'\n",
        "        }).round(2)\n",
        "\n",
        "        print(\"   ì‹¤ì œ ì•ˆì „ë“±ê¸‰ë³„ í˜„í™©:\")\n",
        "        for grade, row in safety_budget_analysis.iterrows():\n",
        "            budget_mean = row[('ì´ì˜ˆì‚°', 'mean')]\n",
        "            count = row[('ì´ì˜ˆì‚°', 'count')]\n",
        "            risk_mean = row[('í™˜ê²½ìœ„í—˜ë„', 'mean')]\n",
        "            print(f\"   {grade}ê¸‰: {count}ê°œêµ, í‰ê· ì˜ˆì‚° {budget_mean:,.0f}ì›, í™˜ê²½ìœ„í—˜ë„ {risk_mean:.1f}\")\n",
        "\n",
        "        self.real_effects['safety_grade_stats'] = safety_budget_analysis\n",
        "\n",
        "        # Eê¸‰â†’Dê¸‰, Dê¸‰â†’Cê¸‰ ê°œì„ ì— í•„ìš”í•œ ì‹¤ì œ ì˜ˆì‚° ì°¨ì´\n",
        "        if 'E' in safety_budget_analysis.index and 'D' in safety_budget_analysis.index:\n",
        "            e_to_d_cost = safety_budget_analysis.loc['D'][('ì´ì˜ˆì‚°', 'mean')] - safety_budget_analysis.loc['E'][('ì´ì˜ˆì‚°', 'mean')]\n",
        "            self.real_effects['e_to_d_improvement_cost'] = e_to_d_cost\n",
        "            print(f\"   ğŸ’° Eê¸‰â†’Dê¸‰ ê°œì„  ì‹¤ì œ ì˜ˆì‚° ì°¨ì´: {e_to_d_cost:,.0f}ì›\")\n",
        "\n",
        "        if 'D' in safety_budget_analysis.index and 'C' in safety_budget_analysis.index:\n",
        "            d_to_c_cost = safety_budget_analysis.loc['C'][('ì´ì˜ˆì‚°', 'mean')] - safety_budget_analysis.loc['D'][('ì´ì˜ˆì‚°', 'mean')]\n",
        "            self.real_effects['d_to_c_improvement_cost'] = d_to_c_cost\n",
        "            print(f\"   ğŸ’° Dê¸‰â†’Cê¸‰ ê°œì„  ì‹¤ì œ ì˜ˆì‚° ì°¨ì´: {d_to_c_cost:,.0f}ì›\")\n",
        "\n",
        "    def _calculate_real_environmental_patterns(self):\n",
        "        \"\"\"ì‹¤ì œ í™˜ê²½ìœ„í—˜ë„ ë¶„í¬ì™€ íŒ¨í„´ ë¶„ì„\"\"\"\n",
        "\n",
        "        print(\"ğŸŒ¡ï¸ ì‹¤ì œ í™˜ê²½ìœ„í—˜ë„ íŒ¨í„´ ì§ì ‘ ë¶„ì„...\")\n",
        "\n",
        "        df = self.df.copy()\n",
        "\n",
        "        # 1. í™˜ê²½ìœ„í—˜ë„ êµ¬ê°„ë³„ ì‹¤ì œ ë¶„í¬\n",
        "        df['ìœ„í—˜ë„êµ¬ê°„'] = pd.cut(df['í™˜ê²½ìœ„í—˜ë„'],\n",
        "                                bins=[0, 30, 50, 70, 100],\n",
        "                                labels=['ì €ìœ„í—˜', 'ì¤‘ìœ„í—˜', 'ê³ ìœ„í—˜', 'ë§¤ìš°ìœ„í—˜'])\n",
        "\n",
        "        risk_distribution = df['ìœ„í—˜ë„êµ¬ê°„'].value_counts()\n",
        "        risk_budget_by_level = df.groupby('ìœ„í—˜ë„êµ¬ê°„').agg({\n",
        "            'ì´ì˜ˆì‚°': 'mean',\n",
        "            'ì˜ˆì‚°íš¨ìœ¨ì„±': 'mean',\n",
        "            'SAFETY_GRADE': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'C'\n",
        "        }).round(2)\n",
        "\n",
        "        print(\"   ì‹¤ì œ ìœ„í—˜ë„ êµ¬ê°„ë³„ í˜„í™©:\")\n",
        "        for level, count in risk_distribution.items():\n",
        "            if level in risk_budget_by_level.index:\n",
        "                budget = risk_budget_by_level.loc[level, 'ì´ì˜ˆì‚°']\n",
        "                efficiency = risk_budget_by_level.loc[level, 'ì˜ˆì‚°íš¨ìœ¨ì„±']\n",
        "                grade = risk_budget_by_level.loc[level, 'SAFETY_GRADE']\n",
        "                print(f\"   {level}: {count}ê°œêµ, í‰ê· ì˜ˆì‚° {budget:,.0f}ì›, íš¨ìœ¨ì„± {efficiency:.1f}, ì£¼ìš”ë“±ê¸‰ {grade}\")\n",
        "\n",
        "        self.real_effects['risk_level_stats'] = risk_budget_by_level\n",
        "\n",
        "        # 2. ì§€ì—­ë³„ ì‹¤ì œ í™˜ê²½ ì„±ê³¼\n",
        "        if 'ì§€ì—­' in df.columns:\n",
        "            region_analysis = df.groupby('ì§€ì—­').agg({\n",
        "                'í™˜ê²½ìœ„í—˜ë„': ['mean', 'std'],\n",
        "                'ì´ì˜ˆì‚°': 'mean',\n",
        "                'ì˜ˆì‚°íš¨ìœ¨ì„±': 'mean',\n",
        "                'SAFETY_GRADE': lambda x: (x.isin(['D', 'E'])).mean() * 100\n",
        "            }).round(2)\n",
        "\n",
        "            # ì§€ì—­ë³„ ì„±ê³¼ ìˆœìœ„ (í™˜ê²½ìœ„í—˜ë„ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
        "            region_analysis['í™˜ê²½ì„±ê³¼ìˆœìœ„'] = region_analysis[('í™˜ê²½ìœ„í—˜ë„', 'mean')].rank()\n",
        "            region_analysis['ì˜ˆì‚°íš¨ìœ¨ìˆœìœ„'] = region_analysis[('ì˜ˆì‚°íš¨ìœ¨ì„±', 'mean')].rank(ascending=False)\n",
        "\n",
        "            print(\"   ì§€ì—­ë³„ ì‹¤ì œ ì„±ê³¼ (ìƒìœ„ 5ê°œ):\")\n",
        "            top_regions = region_analysis.nsmallest(5, ('í™˜ê²½ìœ„í—˜ë„', 'mean'))\n",
        "            for region, row in top_regions.iterrows():\n",
        "                risk = row[('í™˜ê²½ìœ„í—˜ë„', 'mean')]\n",
        "                budget = row[('ì´ì˜ˆì‚°', 'mean')]\n",
        "                danger_ratio = row[('SAFETY_GRADE', '<lambda>')]\n",
        "                print(f\"   {region.split()[-1]}: í™˜ê²½ìœ„í—˜ë„ {risk:.1f}, ì˜ˆì‚° {budget:,.0f}ì›, ìœ„í—˜í•™êµ {danger_ratio:.1f}%\")\n",
        "\n",
        "            self.real_effects['regional_performance'] = region_analysis\n",
        "\n",
        "    def _calculate_real_improvement_costs(self):\n",
        "        \"\"\"ì‹¤ì œ ê°œì„ ì— í•„ìš”í•œ ë¹„ìš© ê³„ì‚°\"\"\"\n",
        "\n",
        "        print(\"ğŸ’¸ ì‹¤ì œ ê°œì„  ë¹„ìš© ì§ì ‘ ê³„ì‚°...\")\n",
        "\n",
        "        df = self.df.copy()\n",
        "\n",
        "        # 1. í˜„ì¬ ìœ„í—˜í•™êµë“¤ì˜ ì‹¤ì œ ì˜ˆì‚° í˜„í™©\n",
        "        danger_schools = df[df['SAFETY_GRADE'].isin(['D', 'E'])]\n",
        "        safe_schools = df[df['SAFETY_GRADE'].isin(['A', 'B'])]\n",
        "\n",
        "        if len(danger_schools) > 0 and len(safe_schools) > 0:\n",
        "            danger_avg_budget = danger_schools['ì´ì˜ˆì‚°'].mean()\n",
        "            safe_avg_budget = safe_schools['ì´ì˜ˆì‚°'].mean()\n",
        "            improvement_gap = safe_avg_budget - danger_avg_budget\n",
        "\n",
        "            danger_avg_risk = danger_schools['í™˜ê²½ìœ„í—˜ë„'].mean()\n",
        "            safe_avg_risk = safe_schools['í™˜ê²½ìœ„í—˜ë„'].mean()\n",
        "            risk_gap = danger_avg_risk - safe_avg_risk\n",
        "\n",
        "            print(f\"   ğŸš¨ ìœ„í—˜í•™êµ í˜„í™©: {len(danger_schools)}ê°œêµ\")\n",
        "            print(f\"   ğŸ’° ìœ„í—˜í•™êµ í‰ê· ì˜ˆì‚°: {danger_avg_budget:,.0f}ì›\")\n",
        "            print(f\"   ğŸ’° ì•ˆì „í•™êµ í‰ê· ì˜ˆì‚°: {safe_avg_budget:,.0f}ì›\")\n",
        "            print(f\"   ğŸ’¸ ê°œì„  í•„ìš” ì˜ˆì‚°: {improvement_gap:,.0f}ì›\")\n",
        "            print(f\"   ğŸŒ¡ï¸ ìœ„í—˜ë„ ê²©ì°¨: {risk_gap:.1f}ì \")\n",
        "\n",
        "            # ì‹¤ì œ ê°œì„  íš¨ìœ¨ì„± ê³„ì‚°\n",
        "            if improvement_gap > 0 and risk_gap > 0:\n",
        "                real_cost_per_point = improvement_gap / risk_gap\n",
        "                self.real_effects['real_cost_per_risk_point'] = real_cost_per_point\n",
        "                print(f\"   ğŸ“Š ì‹¤ì œ ë°ì´í„°: í™˜ê²½ìœ„í—˜ë„ 1ì  ê°œì„ ì— {real_cost_per_point:,.0f}ì› í•„ìš”\")\n",
        "\n",
        "        # 2. ì˜ˆì‚° íš¨ìœ¨ì„±ë³„ ì‹¤ì œ ì„±ê³¼\n",
        "        df['íš¨ìœ¨ì„±êµ¬ê°„'] = pd.cut(df['ì˜ˆì‚°íš¨ìœ¨ì„±'],\n",
        "                                bins=[0, 40, 60, 80, 100],\n",
        "                                labels=['ì €íš¨ìœ¨', 'ì¤‘íš¨ìœ¨', 'ê³ íš¨ìœ¨', 'ìµœê³ íš¨ìœ¨'])\n",
        "\n",
        "        efficiency_analysis = df.groupby('íš¨ìœ¨ì„±êµ¬ê°„').agg({\n",
        "            'í™˜ê²½ìœ„í—˜ë„': 'mean',\n",
        "            'ì´ì˜ˆì‚°': 'mean',\n",
        "            'SAFETY_GRADE': lambda x: (x.isin(['A', 'B'])).mean() * 100  # ìš°ìˆ˜í•™êµ ë¹„ìœ¨\n",
        "        }).round(2)\n",
        "\n",
        "        print(\"   ì˜ˆì‚° íš¨ìœ¨ì„±ë³„ ì‹¤ì œ ì„±ê³¼:\")\n",
        "        for level, row in efficiency_analysis.iterrows():\n",
        "            risk = row['í™˜ê²½ìœ„í—˜ë„']\n",
        "            budget = row['ì´ì˜ˆì‚°']\n",
        "            good_ratio = row['SAFETY_GRADE']\n",
        "            print(f\"   {level}: í™˜ê²½ìœ„í—˜ë„ {risk:.1f}, ì˜ˆì‚° {budget:,.0f}ì›, ìš°ìˆ˜í•™êµ {good_ratio:.1f}%\")\n",
        "\n",
        "        self.real_effects['efficiency_performance'] = efficiency_analysis\n",
        "\n",
        "    def get_policy_effects_from_real_data(self) -> Dict[str, Dict]:\n",
        "        \"\"\"ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì •ì±…ë³„ ì—°ê°„ íš¨ê³¼ ê³„ì‚°\"\"\"\n",
        "\n",
        "        print(\"ğŸ¯ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì •ì±…ë³„ íš¨ê³¼ ì‚°ì¶œ...\")\n",
        "\n",
        "        # ê¸°ë³¸ ê°œì„ ìœ¨ (ì‹¤ì œ ë°ì´í„°ì—ì„œ ê³„ì‚°ëœ ê°’)\n",
        "        base_improvement_rate = self.real_effects.get('budget_improvement_rate', 0.5)\n",
        "        real_cost_per_point = self.real_effects.get('real_cost_per_risk_point', 50_000_000)\n",
        "\n",
        "        # ì •ì±…ë³„ ë¹„ìš© (ì‹¤ì¦ ì—°êµ¬ ê¸°ë°˜)\n",
        "        policy_costs = {\n",
        "            'ê³µê¸°ì²­ì •ê¸°': 15_000_000,\n",
        "            'ê±´ë¬¼ê°œì„ ': 150_000_000,\n",
        "            'ë…¹ì§€ì¡°ì„±': 50_000_000,\n",
        "            'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 30_000_000,\n",
        "            'ë³µì§€ì§€ì›': 20_000_000\n",
        "        }\n",
        "\n",
        "        real_policy_effects = {}\n",
        "\n",
        "        for policy, cost in policy_costs.items():\n",
        "            # ì‹¤ì œ ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼ ê³„ì‚°\n",
        "            cost_ratio = cost / real_cost_per_point\n",
        "\n",
        "            if policy == 'ê³µê¸°ì²­ì •ê¸°':\n",
        "                # ì¦‰ì‹œ íš¨ê³¼, í•˜ì§€ë§Œ ì œí•œì \n",
        "                annual_effect = min(6.0, cost_ratio * 1.5)  # ìµœëŒ€ 6ì  (í˜„ì‹¤ì ìœ¼ë¡œ ì¡°ì •)\n",
        "                decay_rate = 0.1  # ì—°ê°„ 10% ê°ì†Œ\n",
        "                social_effect = 6.0  # ì¦‰ì‹œ ê°€ì‹œì  íš¨ê³¼ë¡œ ë§Œì¡±ë„ ë†’ìŒ\n",
        "\n",
        "            elif policy == 'ê±´ë¬¼ê°œì„ ':\n",
        "                # í° íš¨ê³¼, í•˜ì§€ë§Œ ì§€ì—°ë¨\n",
        "                annual_effect = min(4.0, cost_ratio * 0.8)  # ìµœëŒ€ 4ì  (í˜„ì‹¤ì ìœ¼ë¡œ ì¡°ì •)\n",
        "                decay_rate = 0.02  # ë‚´êµ¬ì„± ì¢‹ìŒ\n",
        "                social_effect = 2.0  # ê³µì‚¬ ë¶ˆí¸ìœ¼ë¡œ ì´ˆê¸° ë§Œì¡±ë„ ë§¤ìš° ë‚®ìŒ\n",
        "\n",
        "            elif policy == 'ë…¹ì§€ì¡°ì„±':\n",
        "                # ì ì§„ì  íš¨ê³¼\n",
        "                annual_effect = min(2.5, cost_ratio * 0.8)\n",
        "                decay_rate = -0.03  # ì‹œê°„ì´ ì§€ë‚˜ë©´ ë” ì¢‹ì•„ì§\n",
        "                social_effect = 7.0  # ì¹œí™˜ê²½ìœ¼ë¡œ ì„ í˜¸ë„ ë†’ìŒ\n",
        "\n",
        "            elif policy == 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§':\n",
        "                # ì¤‘ê°„ íš¨ê³¼ + ë‹¤ë¥¸ ì •ì±… ì‹œë„ˆì§€\n",
        "                annual_effect = min(3.5, cost_ratio * 1.0)\n",
        "                decay_rate = 0.12  # ê¸°ìˆ  ë…¸í›„í™” ë¹ ë¦„\n",
        "                social_effect = 3.0  # ê¸°ìˆ ì— ëŒ€í•œ ìš°ë ¤\n",
        "\n",
        "            elif policy == 'ë³µì§€ì§€ì›':\n",
        "                # í™˜ê²½ì— ì§ì ‘ íš¨ê³¼ ì‘ìŒ\n",
        "                annual_effect = min(1.0, cost_ratio * 0.2)\n",
        "                decay_rate = 0.05\n",
        "                social_effect = 9.0  # ë†’ì€ ë§Œì¡±ë„\n",
        "\n",
        "            real_policy_effects[policy] = {\n",
        "                'env_improvement': annual_effect,\n",
        "                'annual_decay': decay_rate,\n",
        "                'social_satisfaction': social_effect,\n",
        "                'cost_effectiveness': annual_effect / (cost / 10_000_000),  # ì²œë§Œì›ë‹¹ íš¨ê³¼\n",
        "                'schools_per_year': max(1, int(100_000_000 / cost * 5))  # 1ì–µìœ¼ë¡œ ê°œì„  ê°€ëŠ¥ í•™êµìˆ˜ (ë³´ìˆ˜ì )\n",
        "            }\n",
        "\n",
        "            print(f\"   {policy}: ì—°ê°„ {annual_effect:.1f}ì  ê°œì„ , ê°ì‡ ìœ¨ {decay_rate:.2f}, ë§Œì¡±ë„ {social_effect:.1f}\")\n",
        "\n",
        "        return real_policy_effects\n",
        "\n",
        "# =============================================================================\n",
        "# ğŸ”„ ì˜ˆì‚° ì œì•½ì´ ì ìš©ëœ ì •ì±… ì‹œë®¬ë ˆì´í„° (ìˆ˜ì •ë¨)\n",
        "# =============================================================================\n",
        "\n",
        "class PolicyTimeSeriesSimulator:\n",
        "    \"\"\"\n",
        "    í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ì´ ì ìš©ëœ ì •ì±… ì‹œê°„ ê²½ê³¼ íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜\n",
        "    - ì„œìš¸ì‹œêµìœ¡ì²­ ì‹¤ì œ ì˜ˆì‚° í•œë„ ì ìš©\n",
        "    - ì •ì±…ë³„ ë¹„ìš© ì°¨ì´ ë°˜ì˜\n",
        "    - ì˜ˆì‚° ë¶€ì¡±ì‹œ ì¼ë¶€ í•™êµë§Œ ê°œì„ \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, current_results: Dict):\n",
        "        self.current_results = current_results\n",
        "        self.baseline_year = 2023\n",
        "\n",
        "        # í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ (ì„œìš¸ì‹œêµìœ¡ì²­ ê¸°ì¤€)\n",
        "        self.annual_budget_limit = 40_000_000_000   # ì—°ê°„ 400ì–µì›\n",
        "        self.budget_5year = 200_000_000_000         # 5ë…„ê°„ 2000ì–µì›\n",
        "\n",
        "        # ì •ì±…ë³„ ì‹¤ì œ ë¹„ìš© (í•™êµë‹¹)\n",
        "        self.policy_costs = {\n",
        "            'ê³µê¸°ì²­ì •ê¸°': 15_000_000,      # 1,500ë§Œì›\n",
        "            'ê±´ë¬¼ê°œì„ ': 150_000_000,       # 1ì–µ5ì²œë§Œì›\n",
        "            'ë…¹ì§€ì¡°ì„±': 50_000_000,        # 5ì²œë§Œì›\n",
        "            'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 30_000_000,   # 3ì²œë§Œì›\n",
        "            'ë³µì§€ì§€ì›': 20_000_000         # 2ì²œë§Œì›\n",
        "        }\n",
        "\n",
        "        # ëŒ€ìƒ í•™êµ ì •ë³´ ë¨¼ì € ì„¤ì •\n",
        "        if 'priority_analysis' in current_results:\n",
        "            critical_schools = current_results['priority_analysis']['critical_schools']\n",
        "            self.urgent_schools = len(critical_schools[critical_schools['ìš°ì„ ìˆœìœ„ë“±ê¸‰'] == 'ê¸´ê¸‰ê°œì…'])\n",
        "            self.priority_schools = len(critical_schools[critical_schools['ìš°ì„ ìˆœìœ„ë“±ê¸‰'] == 'ìš°ì„ ê°œì„ '])\n",
        "            self.total_target_schools = len(critical_schools)\n",
        "        else:\n",
        "            self.urgent_schools = 7\n",
        "            self.priority_schools = 13\n",
        "            self.total_target_schools = 20\n",
        "\n",
        "        # í˜„ì¬ ìƒíƒœ ì¶”ì¶œ (ëŒ€ìƒ í•™êµ ì •ë³´ ì„¤ì • í›„)\n",
        "        self.current_state = self._extract_current_state()\n",
        "\n",
        "        print(f\"ğŸ’° í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½: 5ë…„ê°„ {self.budget_5year:,.0f}ì›\")\n",
        "        print(f\"ğŸ¯ ëŒ€ìƒ í•™êµ: ê¸´ê¸‰ {self.urgent_schools}ê°œ, ìš°ì„  {self.priority_schools}ê°œ\")\n",
        "\n",
        "    def _extract_current_state(self) -> TimeSeriesState:\n",
        "        \"\"\"í˜„ì¬ ìƒíƒœ ì¶”ì¶œ\"\"\"\n",
        "\n",
        "        if 'simulation_results' in self.current_results:\n",
        "            simulator = self.current_results['simulation_results']['simulator']\n",
        "            data_summary = simulator.data_summary\n",
        "\n",
        "            return TimeSeriesState(\n",
        "                year=self.baseline_year,\n",
        "                env_risk_level=data_summary['avg_risk'],\n",
        "                safety_grade_dist=data_summary['safety_dist'],\n",
        "                budget_efficiency=50.0,\n",
        "                equity_score=45.0,\n",
        "                social_satisfaction=60.0,\n",
        "                total_investment=0.0,\n",
        "                schools_improved=0,\n",
        "                maintenance_cost=0.0,\n",
        "                unexpected_events=[],\n",
        "                schools_neglected=self.total_target_schools  # ì´ˆê¸°ì—ëŠ” ëª¨ë“  í•™êµê°€ ë°©ì¹˜ìƒíƒœ\n",
        "            )\n",
        "        else:\n",
        "            return TimeSeriesState(\n",
        "                year=self.baseline_year,\n",
        "                env_risk_level=43.5,\n",
        "                safety_grade_dist={'A': 100, 'B': 200, 'C': 500, 'D': 100, 'E': 57},\n",
        "                budget_efficiency=50.0,\n",
        "                equity_score=45.0,\n",
        "                social_satisfaction=60.0,\n",
        "                total_investment=0.0,\n",
        "                schools_improved=0,\n",
        "                maintenance_cost=0.0,\n",
        "                unexpected_events=[],\n",
        "                schools_neglected=self.total_target_schools  # ì—¬ê¸°ì„œë„ ì‚¬ìš© ê°€ëŠ¥\n",
        "            )\n",
        "\n",
        "    def simulate_policy_timeline(self, policy: Dict[str, float], policy_name: str,\n",
        "                                years: List[int] = [1, 5]) -> Dict[int, TimeSeriesState]:\n",
        "        \"\"\"ì •ì±… ì ìš© í›„ ì‹œê°„ë³„ ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜ (ì˜ˆì‚° ì œì•½ ì ìš©)\"\"\"\n",
        "\n",
        "        print(f\"ğŸ“Š {policy_name} ì •ì±… ì‹œê°„ ê²½ê³¼ ì‹œë®¬ë ˆì´ì…˜ (í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½)\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        timeline_states = {self.baseline_year: self.current_state}\n",
        "        current_state = self.current_state\n",
        "\n",
        "        for target_year in years:\n",
        "            years_elapsed = target_year\n",
        "            print(f\"\\nğŸ”® {target_year}ë…„ í›„ ({self.baseline_year + target_year}ë…„) ì˜ˆì¸¡ ì¤‘...\")\n",
        "\n",
        "            # ì˜ˆì‚° ì œì•½ í•˜ì—ì„œ ì‹¤ì œ ê°œì„  ê°€ëŠ¥í•œ í•™êµ ìˆ˜ ê³„ì‚°\n",
        "            budget_available = self.budget_5year if years_elapsed == 5 else self.annual_budget_limit * years_elapsed\n",
        "            actual_results = self._calculate_budget_constrained_results(policy, budget_available, years_elapsed)\n",
        "\n",
        "            # ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ìƒíƒœ ë³€í™”\n",
        "            state = self._simulate_constrained_annual_change(current_state, actual_results, years_elapsed)\n",
        "\n",
        "            timeline_states[self.baseline_year + target_year] = state\n",
        "            self._print_constrained_state_summary(state, target_year, actual_results)\n",
        "\n",
        "        return timeline_states\n",
        "\n",
        "    def _calculate_budget_constrained_results(self, policy: Dict[str, float],\n",
        "                                            total_budget: float, years: int) -> Dict[str, Any]:\n",
        "        \"\"\"ì˜ˆì‚° ì œì•½ í•˜ì—ì„œ ì‹¤ì œ ê°œì„  ê°€ëŠ¥í•œ ê²°ê³¼ ê³„ì‚°\"\"\"\n",
        "\n",
        "        # ì •ì±…ë³„ ì˜ˆì‚° ë°°ë¶„\n",
        "        policy_budgets = {}\n",
        "        total_cost_used = 0\n",
        "        schools_by_policy = {}\n",
        "\n",
        "        for policy_type, percentage in policy.items():\n",
        "            if percentage > 0 and policy_type in self.policy_costs:\n",
        "                allocated_budget = total_budget * (percentage / 100)\n",
        "                cost_per_school = self.policy_costs[policy_type]\n",
        "\n",
        "                # ì˜ˆì‚°ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥í•œ ìµœëŒ€ í•™êµ ìˆ˜\n",
        "                max_schools_by_budget = int(allocated_budget / cost_per_school)\n",
        "\n",
        "                # ì‹¤ì œ ëŒ€ìƒ í•™êµ ìˆ˜ ì œí•œ (ê¸´ê¸‰ â†’ ìš°ì„  ìˆœìœ¼ë¡œ)\n",
        "                available_target_schools = min(max_schools_by_budget, self.total_target_schools)\n",
        "\n",
        "                actual_schools = available_target_schools\n",
        "                actual_cost = actual_schools * cost_per_school\n",
        "\n",
        "                schools_by_policy[policy_type] = {\n",
        "                    'schools': actual_schools,\n",
        "                    'cost': actual_cost,\n",
        "                    'budget_allocated': allocated_budget,\n",
        "                    'budget_unused': allocated_budget - actual_cost\n",
        "                }\n",
        "\n",
        "                total_cost_used += actual_cost\n",
        "\n",
        "        # ì¤‘ë³µ ì œê±° (í•œ í•™êµê°€ ì—¬ëŸ¬ ì •ì±… ë°›ëŠ” ê²½ìš°)\n",
        "        unique_schools_improved = min(sum([data['schools'] for data in schools_by_policy.values()]),\n",
        "                                     self.total_target_schools)\n",
        "\n",
        "        neglected_schools = max(0, self.total_target_schools - unique_schools_improved)\n",
        "\n",
        "        return {\n",
        "            'total_budget': total_budget,\n",
        "            'total_cost_used': total_cost_used,\n",
        "            'budget_unused': total_budget - total_cost_used,\n",
        "            'schools_by_policy': schools_by_policy,\n",
        "            'unique_schools_improved': unique_schools_improved,\n",
        "            'neglected_schools': neglected_schools,\n",
        "            'budget_efficiency': (total_cost_used / total_budget * 100) if total_budget > 0 else 0\n",
        "        }\n",
        "\n",
        "    def _simulate_constrained_annual_change(self, current_state: TimeSeriesState,\n",
        "                                          actual_results: Dict[str, Any], years_elapsed: int) -> TimeSeriesState:\n",
        "        \"\"\"ì˜ˆì‚° ì œì•½ì„ ê³ ë ¤í•œ ì—°ê°„ ë³€í™” ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
        "\n",
        "        # ì‹¤ì œ ê°œì„ ëœ í•™êµ ìˆ˜ ê¸°ë°˜ í™˜ê²½ ê°œì„  íš¨ê³¼\n",
        "        schools_improved = actual_results['unique_schools_improved']\n",
        "        total_seoul_schools = 957  # ì „ì²´ ì„œìš¸ì‹œ í•™êµ ìˆ˜\n",
        "\n",
        "        # ê°œì„  ë¹„ìœ¨ì— ë”°ë¥¸ ì „ì²´ í™˜ê²½ìœ„í—˜ë„ ê°œì„ \n",
        "        if schools_improved > 0:\n",
        "            # ê°œì„ ëœ í•™êµë“¤ì˜ í‰ê·  ìœ„í—˜ë„ ê°ì†Œ (ì •ì±…ë³„ íš¨ê³¼ ê°€ì¤‘í‰ê· )\n",
        "            weighted_improvement = 0\n",
        "            total_weight = 0\n",
        "\n",
        "            for policy_type, data in actual_results['schools_by_policy'].items():\n",
        "                if data['schools'] > 0:\n",
        "                    policy_effect = self._get_policy_environmental_effect(policy_type, years_elapsed)\n",
        "                    weighted_improvement += policy_effect * data['schools']\n",
        "                    total_weight += data['schools']\n",
        "\n",
        "            if total_weight > 0:\n",
        "                avg_school_improvement = weighted_improvement / total_weight\n",
        "                # ì „ì²´ ì‹œìŠ¤í…œ ê°œì„ ë„ = (ê°œì„ ëœ í•™êµ ìˆ˜ / ì „ì²´ í•™êµ ìˆ˜) Ã— í‰ê·  ê°œì„ ë„\n",
        "                system_improvement = (schools_improved / total_seoul_schools) * avg_school_improvement\n",
        "            else:\n",
        "                system_improvement = 0\n",
        "        else:\n",
        "            system_improvement = 0\n",
        "\n",
        "        # ì™¸ë¶€ í™˜ê²½ ì•…í™” (ì˜¤ì—¼ ì¦ê°€, ê¸°í›„ë³€í™” ë“±)\n",
        "        external_deterioration = years_elapsed * 0.5  # ì—°ê°„ 0.5ì ì”© ì•…í™”\n",
        "\n",
        "        # ìµœì¢… í™˜ê²½ìœ„í—˜ë„\n",
        "        new_risk = max(0, min(100, current_state.env_risk_level - system_improvement + external_deterioration))\n",
        "\n",
        "        # ì•ˆì „ë“±ê¸‰ ë¶„í¬ ì—…ë°ì´íŠ¸ (í˜„ì‹¤ì )\n",
        "        new_safety_dist = self._update_safety_distribution_realistic(\n",
        "            current_state.safety_grade_dist, schools_improved, self.total_target_schools\n",
        "        )\n",
        "\n",
        "        # ì‚¬íšŒ ë§Œì¡±ë„ (ì˜ˆì‚° ì‚¬ìš©ë¥ ê³¼ ê°€ì‹œì  ì„±ê³¼ì— ì˜í–¥)\n",
        "        satisfaction_change = 0\n",
        "        if actual_results['budget_efficiency'] > 80:  # ì˜ˆì‚° íš¨ìœ¨ì  ì‚¬ìš©\n",
        "            satisfaction_change += 3\n",
        "        if schools_improved > self.total_target_schools * 0.5:  # ì ˆë°˜ ì´ìƒ ê°œì„ \n",
        "            satisfaction_change += 5\n",
        "        if actual_results['neglected_schools'] > self.total_target_schools * 0.3:  # 30% ì´ìƒ ë°©ì¹˜\n",
        "            satisfaction_change -= 8\n",
        "\n",
        "        new_satisfaction = max(0, min(100, current_state.social_satisfaction + satisfaction_change))\n",
        "\n",
        "        # ìœ ì§€ë¹„ìš© (ëˆ„ì  íˆ¬ìì•¡ì˜ 3%)\n",
        "        annual_maintenance = actual_results['total_cost_used'] * 0.03\n",
        "\n",
        "        return TimeSeriesState(\n",
        "            year=current_state.year + years_elapsed,\n",
        "            env_risk_level=new_risk,\n",
        "            safety_grade_dist=new_safety_dist,\n",
        "            budget_efficiency=actual_results['budget_efficiency'],\n",
        "            equity_score=current_state.equity_score,\n",
        "            social_satisfaction=new_satisfaction,\n",
        "            total_investment=current_state.total_investment + actual_results['total_cost_used'],\n",
        "            schools_improved=schools_improved,\n",
        "            maintenance_cost=current_state.maintenance_cost + annual_maintenance,\n",
        "            unexpected_events=self._generate_realistic_events(years_elapsed, actual_results),\n",
        "            schools_neglected=actual_results['neglected_schools']\n",
        "        )\n",
        "\n",
        "    def _get_policy_environmental_effect(self, policy_type: str, years_elapsed: int) -> float:\n",
        "        \"\"\"ì •ì±…ë³„ í™˜ê²½ ê°œì„  íš¨ê³¼ (í˜„ì‹¤ì )\"\"\"\n",
        "\n",
        "        base_effects = {\n",
        "            'ê³µê¸°ì²­ì •ê¸°': 8.0,      # í•™êµë‹¹ 8ì  ê°œì„ \n",
        "            'ê±´ë¬¼ê°œì„ ': 12.0,       # í•™êµë‹¹ 12ì  ê°œì„  (í•˜ì§€ë§Œ ì‹œê°„ í•„ìš”)\n",
        "            'ë…¹ì§€ì¡°ì„±': 4.0,        # í•™êµë‹¹ 4ì  ê°œì„ \n",
        "            'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 3.0,   # í•™êµë‹¹ 3ì  ê°œì„  (ê°„ì ‘ì )\n",
        "            'ë³µì§€ì§€ì›': 1.0         # í•™êµë‹¹ 1ì  ê°œì„  (ë§¤ìš° ê°„ì ‘ì )\n",
        "        }\n",
        "\n",
        "        base_effect = base_effects.get(policy_type, 0)\n",
        "\n",
        "        # ì‹œê°„ì— ë”°ë¥¸ íš¨ê³¼ ì¡°ì •\n",
        "        if policy_type == 'ê±´ë¬¼ê°œì„ ':\n",
        "            # ê±´ë¬¼ê°œì„ ì€ ì´ˆê¸°ì— íš¨ê³¼ ë‚®ê³  ì‹œê°„ì´ ì§€ë‚˜ì•¼ íš¨ê³¼ ë‚˜íƒ€ë‚¨\n",
        "            if years_elapsed <= 2:\n",
        "                base_effect *= 0.3  # ì´ˆê¸° 2ë…„ê°„ì€ 30% íš¨ê³¼ë§Œ\n",
        "            elif years_elapsed <= 5:\n",
        "                base_effect *= 0.8  # 3-5ë…„ì°¨ëŠ” 80% íš¨ê³¼\n",
        "\n",
        "        elif policy_type == 'ë…¹ì§€ì¡°ì„±':\n",
        "            # ë…¹ì§€ì¡°ì„±ì€ ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ íš¨ê³¼ ì¦ê°€\n",
        "            growth_factor = min(1.5, 1 + (years_elapsed - 1) * 0.1)\n",
        "            base_effect *= growth_factor\n",
        "\n",
        "        elif policy_type == 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§':\n",
        "            # ê¸°ìˆ  ë…¸í›„í™”ë¡œ ì‹œê°„ì´ ì§€ë‚˜ë©´ íš¨ê³¼ ê°ì†Œ\n",
        "            decay_factor = max(0.5, 1 - (years_elapsed - 1) * 0.1)\n",
        "            base_effect *= decay_factor\n",
        "\n",
        "        return base_effect\n",
        "\n",
        "    def _update_safety_distribution_realistic(self, current_dist: Dict[str, int],\n",
        "                                            schools_improved: int, total_target: int) -> Dict[str, int]:\n",
        "        \"\"\"í˜„ì‹¤ì  ì•ˆì „ë“±ê¸‰ ë¶„í¬ ì—…ë°ì´íŠ¸\"\"\"\n",
        "\n",
        "        new_dist = current_dist.copy()\n",
        "\n",
        "        if schools_improved > 0:\n",
        "            # ê°œì„  ë¹„ìœ¨ì— ë”°ë¼ D/Eê¸‰ í•™êµ ì¼ë¶€ê°€ Cê¸‰ìœ¼ë¡œ í–¥ìƒ\n",
        "            improvement_rate = min(0.8, schools_improved / total_target)  # ìµœëŒ€ 80% ê°œì„ \n",
        "\n",
        "            d_grade_schools = new_dist.get('D', 0)\n",
        "            e_grade_schools = new_dist.get('E', 0)\n",
        "\n",
        "            # Eê¸‰ â†’ Dê¸‰\n",
        "            e_to_d = int(e_grade_schools * improvement_rate * 0.6)  # 60% ê°œì„ ë¥ \n",
        "            new_dist['E'] = max(0, e_grade_schools - e_to_d)\n",
        "            new_dist['D'] = d_grade_schools + e_to_d\n",
        "\n",
        "            # Dê¸‰ â†’ Cê¸‰\n",
        "            d_to_c = int((d_grade_schools + e_to_d) * improvement_rate * 0.4)  # 40% ê°œì„ ë¥ \n",
        "            new_dist['D'] = max(0, new_dist['D'] - d_to_c)\n",
        "            new_dist['C'] = new_dist.get('C', 0) + d_to_c\n",
        "\n",
        "        return new_dist\n",
        "\n",
        "    def _generate_realistic_events(self, years_elapsed: int, actual_results: Dict) -> List[str]:\n",
        "        \"\"\"í˜„ì‹¤ì  ëŒë°œ ìƒí™© ìƒì„±\"\"\"\n",
        "\n",
        "        events = []\n",
        "\n",
        "        # ì˜ˆì‚° ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ë¬¸ì œ\n",
        "        if actual_results['neglected_schools'] > 5:\n",
        "            events.append(f\"ì˜ˆì‚° ë¶€ì¡±ìœ¼ë¡œ {actual_results['neglected_schools']}ê°œêµ ê°œì„  ì§€ì—°\")\n",
        "\n",
        "        # ì—°ì°¨ë³„ ì´ìŠˆ\n",
        "        if years_elapsed >= 3:\n",
        "            if actual_results['budget_unused'] > 5_000_000_000:\n",
        "                events.append(\"ì˜ˆì‚° ì—¬ìœ ë¶„ìœ¼ë¡œ ì¶”ê°€ ì‚¬ì—… ê²€í†  ê°€ëŠ¥\")\n",
        "\n",
        "        if years_elapsed >= 4:\n",
        "            events.append(\"ê¸°ì¡´ ì„¤ì¹˜ ì‹œì„¤ ìœ ì§€ë³´ìˆ˜ ë¹„ìš© ì¦ê°€\")\n",
        "\n",
        "        if years_elapsed == 5:\n",
        "            events.append(\"ì°¨ê¸° 5ê°œë…„ ê³„íš ìˆ˜ë¦½ í•„ìš”\")\n",
        "\n",
        "        return events\n",
        "\n",
        "    def _print_constrained_state_summary(self, state: TimeSeriesState, years_after: int,\n",
        "                                       actual_results: Dict[str, Any]):\n",
        "        \"\"\"ì˜ˆì‚° ì œì•½ ê³ ë ¤í•œ ìƒíƒœ ìš”ì•½ ì¶œë ¥\"\"\"\n",
        "\n",
        "        print(f\"\\nğŸ“Š {years_after}ë…„ í›„ ìƒíƒœ ìš”ì•½:\")\n",
        "        print(f\"   ğŸŒ¡ï¸ í™˜ê²½ìœ„í—˜ë„: {state.env_risk_level:.1f} ({self.current_state.env_risk_level:.1f} â†’ {state.env_risk_level:.1f})\")\n",
        "\n",
        "        # ìœ„í—˜í•™êµ ë³€í™”\n",
        "        current_danger = self.current_state.safety_grade_dist.get('D', 0) + self.current_state.safety_grade_dist.get('E', 0)\n",
        "        new_danger = state.safety_grade_dist.get('D', 0) + state.safety_grade_dist.get('E', 0)\n",
        "        print(f\"   ğŸ¥ ìœ„í—˜í•™êµ(D/Eê¸‰): {new_danger}ê°œ ({current_danger}ê°œ â†’ {new_danger}ê°œ)\")\n",
        "\n",
        "        print(f\"   ğŸ’° ëˆ„ì  íˆ¬ìì•¡: {state.total_investment:,.0f}ì›\")\n",
        "        print(f\"   ğŸ”§ ì—°ê°„ ìœ ì§€ë¹„: {state.maintenance_cost:,.0f}ì›\")\n",
        "        print(f\"   ğŸ˜Š ì‚¬íšŒ ë§Œì¡±ë„: {state.social_satisfaction:.1f}/100\")\n",
        "        print(f\"   ğŸ« ê°œì„  ì™„ë£Œ í•™êµ: {state.schools_improved}ê°œ\")\n",
        "\n",
        "        # ì˜ˆì‚° ì œì•½ ê´€ë ¨ ì •ë³´\n",
        "        if state.schools_neglected > 0:\n",
        "            print(f\"   âš ï¸ ë°©ì¹˜ í•™êµ: {state.schools_neglected}ê°œ (ì˜ˆì‚° ë¶€ì¡±)\")\n",
        "\n",
        "        if actual_results['budget_unused'] > 1_000_000_000:\n",
        "            print(f\"   ğŸ’¸ ì˜ˆì‚° ì—¬ìœ : {actual_results['budget_unused']:,.0f}ì›\")\n",
        "\n",
        "        print(f\"   ğŸ“ˆ ì˜ˆì‚° ì‚¬ìš©ë¥ : {actual_results['budget_efficiency']:.1f}%\")\n",
        "\n",
        "        if state.unexpected_events:\n",
        "            print(f\"   ğŸ“¢ ì£¼ìš” ì´ìŠˆ: {', '.join(state.unexpected_events)}\")\n",
        "\n",
        "    def compare_policies(self, best_policy: Dict[str, float], worst_policy: Dict[str, float]) -> None:\n",
        "        \"\"\"í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ í•˜ì—ì„œ ì •ì±… ë¹„êµ ë¶„ì„\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ’° í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ í•˜ì—ì„œ ìµœì ì •ì±… vs ìµœì•…ì •ì±… ë¹„êµ\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # ìµœì ì •ì±… ì‹œë®¬ë ˆì´ì…˜\n",
        "        print(\"\\nğŸ† **ìµœì ì •ì±… ì ìš© ì‹œë‚˜ë¦¬ì˜¤ (ì˜ˆì‚° ì œì•½ ì ìš©)**\")\n",
        "        best_timeline = self.simulate_policy_timeline(best_policy, \"ìµœì ì •ì±…\")\n",
        "\n",
        "        # ìµœì•…ì •ì±… ì‹œë®¬ë ˆì´ì…˜\n",
        "        print(\"\\nğŸ—‘ï¸ **ìµœì•…ì •ì±… ì ìš© ì‹œë‚˜ë¦¬ì˜¤ (ì˜ˆì‚° ì œì•½ ì ìš©)**\")\n",
        "        worst_timeline = self.simulate_policy_timeline(worst_policy, \"ìµœì•…ì •ì±…\")\n",
        "\n",
        "        # ë¹„êµ ë¶„ì„\n",
        "        self._print_realistic_comparison_analysis(best_timeline, worst_timeline)\n",
        "\n",
        "    def _print_realistic_comparison_analysis(self, best_timeline: Dict, worst_timeline: Dict):\n",
        "        \"\"\"í˜„ì‹¤ì  ë¹„êµ ë¶„ì„ ê²°ê³¼ ì¶œë ¥\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ“Š **í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ í•˜ì—ì„œ ë¹„êµ ë¶„ì„ ê²°ê³¼**\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        for year_offset in [1, 5]:\n",
        "            year = self.baseline_year + year_offset\n",
        "            best_state = best_timeline[year]\n",
        "            worst_state = worst_timeline[year]\n",
        "\n",
        "            print(f\"\\nğŸ“… **{year_offset}ë…„ í›„ ({year}ë…„) í˜„ì‹¤ì  ë¹„êµ:**\")\n",
        "            print(f\"{'í•­ëª©':<20} {'ìµœì ì •ì±…':<15} {'ìµœì•…ì •ì±…':<15} {'ì°¨ì´':<15}\")\n",
        "            print(\"-\" * 70)\n",
        "\n",
        "            # í•µì‹¬ ì§€í‘œë“¤\n",
        "            items = [\n",
        "                ('í™˜ê²½ìœ„í—˜ë„', 'env_risk_level', '.1f'),\n",
        "                ('ê°œì„ ì™„ë£Œí•™êµ', 'schools_improved', 'd'),\n",
        "                ('ë°©ì¹˜í•™êµ', 'schools_neglected', 'd'),\n",
        "                ('ì‚¬íšŒë§Œì¡±ë„', 'social_satisfaction', '.1f'),\n",
        "                ('ëˆ„ì íˆ¬ì(ì–µì›)', 'total_investment', lambda x: f\"{x/1_000_000_000:.0f}\"),\n",
        "                ('ìœ ì§€ë¹„(ì–µì›)', 'maintenance_cost', lambda x: f\"{x/1_000_000_000:.1f}\")\n",
        "            ]\n",
        "\n",
        "            for name, attr, fmt in items:\n",
        "                best_val = getattr(best_state, attr)\n",
        "                worst_val = getattr(worst_state, attr)\n",
        "\n",
        "                if callable(fmt):\n",
        "                    best_str = fmt(best_val)\n",
        "                    worst_str = fmt(worst_val)\n",
        "                    diff_str = fmt(best_val - worst_val)\n",
        "                else:\n",
        "                    best_str = f\"{best_val:{fmt}}\"\n",
        "                    worst_str = f\"{worst_val:{fmt}}\"\n",
        "                    diff_str = f\"{best_val - worst_val:{fmt}}\"\n",
        "\n",
        "                print(f\"{name:<20} {best_str:<15} {worst_str:<15} {diff_str:<15}\")\n",
        "\n",
        "        # í•µì‹¬ ì¸ì‚¬ì´íŠ¸\n",
        "        best_5yr = best_timeline[self.baseline_year + 5]\n",
        "        worst_5yr = worst_timeline[self.baseline_year + 5]\n",
        "\n",
        "        print(f\"\\nğŸ” **í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (5ë…„ ê¸°ì¤€):**\")\n",
        "\n",
        "        # í•™êµ ê°œì„  íš¨ìœ¨ì„±\n",
        "        schools_diff = best_5yr.schools_improved - worst_5yr.schools_improved\n",
        "        if schools_diff > 0:\n",
        "            print(f\"âœ… ìµœì ì •ì±…ì´ {schools_diff}ê°œêµ ë” ê°œì„ \")\n",
        "        elif schools_diff < 0:\n",
        "            print(f\"âš ï¸ ìµœì•…ì •ì±…ì´ {-schools_diff}ê°œêµ ë” ê°œì„  (ë‹¨ê¸° ì§‘ì¤‘ íš¨ê³¼)\")\n",
        "\n",
        "        # ë°©ì¹˜ í•™êµ ì°¨ì´\n",
        "        neglected_diff = worst_5yr.schools_neglected - best_5yr.schools_neglected\n",
        "        if neglected_diff > 0:\n",
        "            print(f\"ğŸš¨ ìµœì•…ì •ì±…ì€ {neglected_diff}ê°œêµ ë” ë°©ì¹˜ (ì˜ˆì‚° ì§‘ì¤‘ì˜ ë¶€ì‘ìš©)\")\n",
        "\n",
        "        # ë¹„ìš© íš¨ìœ¨ì„±\n",
        "        best_cost_per_school = best_5yr.total_investment / best_5yr.schools_improved if best_5yr.schools_improved > 0 else 0\n",
        "        worst_cost_per_school = worst_5yr.total_investment / worst_5yr.schools_improved if worst_5yr.schools_improved > 0 else 0\n",
        "\n",
        "        print(f\"\\nğŸ’° **ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„:**\")\n",
        "        print(f\"   ìµœì ì •ì±…: í•™êµë‹¹ {best_cost_per_school:,.0f}ì›\")\n",
        "        print(f\"   ìµœì•…ì •ì±…: í•™êµë‹¹ {worst_cost_per_school:,.0f}ì›\")\n",
        "\n",
        "        if best_cost_per_school > 0 and worst_cost_per_school > 0:\n",
        "            efficiency_ratio = worst_cost_per_school / best_cost_per_school\n",
        "            print(f\"   íš¨ìœ¨ì„± ì°¨ì´: ìµœì•…ì •ì±…ì´ {efficiency_ratio:.1f}ë°° ë” ë¹„ìŒˆ\")\n",
        "\n",
        "        # ì‚¬íšŒì  ì˜í–¥\n",
        "        satisfaction_diff = best_5yr.social_satisfaction - worst_5yr.social_satisfaction\n",
        "        print(f\"\\nğŸ˜Š **ì‚¬íšŒì  ì˜í–¥:**\")\n",
        "        print(f\"   ë§Œì¡±ë„ ì°¨ì´: {satisfaction_diff:+.1f}ì \")\n",
        "\n",
        "        if best_5yr.schools_neglected > 0 or worst_5yr.schools_neglected > 0:\n",
        "            print(f\"   ğŸ“¢ ì •ì±… ê°ˆë“± ìš”ì†Œ:\")\n",
        "            if best_5yr.schools_neglected > 0:\n",
        "                print(f\"     - ìµœì ì •ì±…ë„ {best_5yr.schools_neglected}ê°œêµ ë°©ì¹˜ â†’ í˜•í‰ì„± ë…¼ë€ ê°€ëŠ¥\")\n",
        "            if worst_5yr.schools_neglected > 0:\n",
        "                print(f\"     - ìµœì•…ì •ì±…ì€ {worst_5yr.schools_neglected}ê°œêµ ë°©ì¹˜ â†’ ì‹¬ê°í•œ í˜•í‰ì„± ë¬¸ì œ\")\n",
        "\n",
        "# =============================================================================\n",
        "# ğŸ”„ ê¸°ì¡´ ì‹œë®¬ë ˆì´í„°ì— ì‹¤ì œ ë°ì´í„° íš¨ê³¼ ì ìš©\n",
        "# =============================================================================\n",
        "\n",
        "def create_data_driven_timeline_simulator(comprehensive_results: Dict) -> 'PolicyTimeSeriesSimulator':\n",
        "    \"\"\"ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ íƒ€ì„ë¼ì¸ ì‹œë®¬ë ˆì´í„° ìƒì„±\"\"\"\n",
        "\n",
        "    if 'data_foundation' not in comprehensive_results:\n",
        "        print(\"âŒ ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "\n",
        "    df = comprehensive_results['data_foundation']['original_data']\n",
        "    data_summary = comprehensive_results['data_foundation']['data_summary']\n",
        "\n",
        "    # ì‹¤ì œ ë°ì´í„° íš¨ê³¼ ê³„ì‚°ê¸°\n",
        "    real_calculator = RealDataBasedEffectCalculator(df, data_summary)\n",
        "    real_effects = real_calculator.get_policy_effects_from_real_data()\n",
        "\n",
        "    # ì˜ˆì‚° ì œì•½ ì ìš© ì‹œë®¬ë ˆì´í„° ìƒì„±\n",
        "    simulator = PolicyTimeSeriesSimulator(comprehensive_results)\n",
        "\n",
        "    print(\"âœ… ì‹¤ì œ ë°ì´í„° + ì˜ˆì‚° ì œì•½ ê¸°ë°˜ ì‹œë®¬ë ˆì´í„° ìƒì„± ì™„ë£Œ\")\n",
        "    return simulator\n",
        "\n",
        "def run_real_data_timeline_analysis(comprehensive_results: Dict):\n",
        "    \"\"\"ì‹¤ì œ ë°ì´í„° + ì˜ˆì‚° ì œì•½ ê¸°ë°˜ ì‹œê°„ë³„ ë¶„ì„\"\"\"\n",
        "\n",
        "    print(\"ğŸš€ ì‹¤ì œ ì„œìš¸ì‹œ ë°ì´í„° + ì˜ˆì‚° ì œì•½ ê¸°ë°˜ ì‹œê°„ë³„ ì •ì±… íš¨ê³¼ ë¶„ì„\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì‹œë®¬ë ˆì´í„° ìƒì„±\n",
        "    real_simulator = create_data_driven_timeline_simulator(comprehensive_results)\n",
        "\n",
        "    if not real_simulator:\n",
        "        print(\"âŒ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ë¶ˆê°€\")\n",
        "        return\n",
        "\n",
        "    # ìµœì ì •ì±…ê³¼ ìµœì•…ì •ì±…\n",
        "    best_node = comprehensive_results['simulation_results']['best_paths'][0]\n",
        "    best_policy = best_node.policy\n",
        "\n",
        "    worst_policy = {'ê±´ë¬¼ê°œì„ ': 100, 'ê³µê¸°ì²­ì •ê¸°': 0, 'ë…¹ì§€ì¡°ì„±': 0, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 0, 'ë³µì§€ì§€ì›': 0}\n",
        "\n",
        "    print(f\"ğŸ† ìµœì ì •ì±… (ì‹¤ì œ ë°ì´í„° + ì˜ˆì‚° ì œì•½): {best_node.policy_description}\")\n",
        "    print(f\"ğŸ—‘ï¸ ìµœì•…ì •ì±… (ì‹¤ì œ ë°ì´í„° + ì˜ˆì‚° ì œì•½): ê±´ë¬¼ê°œì„  ë‹¨ì¼ ì§‘ì¤‘\")\n",
        "\n",
        "    # ì˜ˆì‚° ì œì•½ íš¨ê³¼ ë¯¸ë¦¬ ê³„ì‚°\n",
        "    print(f\"\\nğŸ’° ì˜ˆì‚° ì œì•½ íš¨ê³¼ ë¯¸ë¦¬ë³´ê¸°:\")\n",
        "\n",
        "    # ìµœì•…ì •ì±…ì˜ ì˜ˆì‚° ë¶€ì¡± ë¬¸ì œ\n",
        "    total_budget_5yr = 200_000_000_000  # 2000ì–µì›\n",
        "    building_cost_per_school = 150_000_000  # 1.5ì–µì›\n",
        "    target_schools = real_simulator.total_target_schools\n",
        "\n",
        "    needed_budget_worst = building_cost_per_school * target_schools\n",
        "    print(f\"   ìµœì•…ì •ì±… í•„ìš” ì˜ˆì‚°: {needed_budget_worst:,.0f}ì›\")\n",
        "    print(f\"   ì‹¤ì œ ê°€ìš© ì˜ˆì‚°: {total_budget_5yr:,.0f}ì›\")\n",
        "\n",
        "    if needed_budget_worst > total_budget_5yr:\n",
        "        max_schools_worst = int(total_budget_5yr / building_cost_per_school)\n",
        "        neglected_worst = target_schools - max_schools_worst\n",
        "        print(f\"   âš ï¸ ìµœì•…ì •ì±…: {max_schools_worst}ê°œêµë§Œ ê°œì„  ê°€ëŠ¥, {neglected_worst}ê°œêµ ë°©ì¹˜!\")\n",
        "\n",
        "    # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¹„êµ\n",
        "    real_simulator.compare_policies(best_policy, worst_policy)\n",
        "\n",
        "# =============================================================================\n",
        "# ğŸ¯ ê°„í¸ ì‹¤í–‰ í•¨ìˆ˜ë“¤\n",
        "# =============================================================================\n",
        "\n",
        "def quick_timeline_demo():\n",
        "    \"\"\"\n",
        "    ë¹ ë¥¸ ë°ëª¨ìš© - ì‹¤ì œ ë°ì´í„° ì—†ì´ë„ ì‹œê°„ë³„ ë¶„ì„ ì²´í—˜ ê°€ëŠ¥\n",
        "    \"\"\"\n",
        "    print(\"ğŸš€ í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ ì‹œë®¬ë ˆì´ì…˜ ë°ëª¨\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # ê°€ìƒì˜ ê²°ê³¼ ìƒì„± (ë°ëª¨ìš©)\n",
        "    demo_results = {\n",
        "        'simulation_results': {\n",
        "            'best_paths': [type('Node', (), {\n",
        "                'policy': {'ê³µê¸°ì²­ì •ê¸°': 30, 'ê±´ë¬¼ê°œì„ ': 25, 'ë…¹ì§€ì¡°ì„±': 20, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 15, 'ë³µì§€ì§€ì›': 10},\n",
        "                'policy_description': 'ê· í˜•ë°œì „í˜• ìµœì ì •ì±… (ë°ëª¨)'\n",
        "            })()],\n",
        "            'simulator': type('Simulator', (), {\n",
        "                'data_summary': {\n",
        "                    'avg_risk': 45.0,\n",
        "                    'safety_dist': {'A': 100, 'B': 200, 'C': 500, 'D': 100, 'E': 57},\n",
        "                    'total_schools': 957,\n",
        "                    'danger_schools': 157\n",
        "                }\n",
        "            })()\n",
        "        },\n",
        "        'priority_analysis': {\n",
        "            'critical_schools': pd.DataFrame({\n",
        "                'ìš°ì„ ìˆœìœ„ë“±ê¸‰': ['ê¸´ê¸‰ê°œì…'] * 7 + ['ìš°ì„ ê°œì„ '] * 13\n",
        "            })\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ ë¶„ì„ ì‹¤í–‰\n",
        "    simulator = PolicyTimeSeriesSimulator(demo_results)\n",
        "\n",
        "    best_policy = {'ê³µê¸°ì²­ì •ê¸°': 30, 'ê±´ë¬¼ê°œì„ ': 25, 'ë…¹ì§€ì¡°ì„±': 20, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 15, 'ë³µì§€ì§€ì›': 10}\n",
        "    worst_policy = {'ê±´ë¬¼ê°œì„ ': 100, 'ê³µê¸°ì²­ì •ê¸°': 0, 'ë…¹ì§€ì¡°ì„±': 0, 'ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§': 0, 'ë³µì§€ì§€ì›': 0}\n",
        "\n",
        "    simulator.compare_policies(best_policy, worst_policy)\n",
        "\n",
        "# =============================================================================\n",
        "# ğŸ¯ ì‚¬ìš©ë²• ê°€ì´ë“œ\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸ“Š **í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ ê¸°ë°˜ ì‹œê°„ë³„ ì •ì±… íš¨ê³¼ ë¶„ì„**\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\nğŸ”¥ **ë°©ë²• 1: ê¸°ì¡´ ê²°ê³¼ í™œìš© (ê¶Œì¥)**\")\n",
        "    print(\"1ï¸âƒ£ ë¨¼ì € ë©”ì¸ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰:\")\n",
        "    print(\"   comprehensive_results = run_comprehensive_analysis_final(\")\n",
        "    print(\"       'ìƒë°˜ê¸°.csv', 'í•˜ë°˜ê¸°.csv'\")\n",
        "    print(\"   )\")\n",
        "    print()\n",
        "    print(\"2ï¸âƒ£ ê·¸ ê²°ê³¼ë¡œ í˜„ì‹¤ì  ì‹œê°„ë³„ ë¶„ì„:\")\n",
        "    print(\"   run_real_data_timeline_analysis(comprehensive_results)\")\n",
        "\n",
        "    print(\"\\nğŸ® **ë°©ë²• 2: ë°ëª¨ ì²´í—˜**\")\n",
        "    print(\"   quick_timeline_demo()  # í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ ë°ëª¨\")\n",
        "\n",
        "    print(\"\\nğŸ’¡ **ì£¼ìš” ê°œì„ ì‚¬í•­:**\")\n",
        "    print(\"âœ… ì„œìš¸ì‹œêµìœ¡ì²­ ì‹¤ì œ ì˜ˆì‚° í•œë„ ì ìš© (5ë…„ê°„ 2000ì–µì›)\")\n",
        "    print(\"âœ… ì •ì±…ë³„ ì‹¤ì œ ë¹„ìš© ì°¨ì´ ë°˜ì˜\")\n",
        "    print(\"âœ… ì˜ˆì‚° ë¶€ì¡±ì‹œ ì¼ë¶€ í•™êµë§Œ ê°œì„ í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë°©ì¹˜\")\n",
        "    print(\"âœ… ê±´ë¬¼ê°œì„  100% = 30ì–µì› í•„ìš” vs ì‹¤ì œ 20ì–µì› â†’ 13ê°œêµë§Œ ê°€ëŠ¥\")\n",
        "    print(\"âœ… ìµœì ì •ì±… = ë‹¤ì–‘í•œ ì •ì±…ìœ¼ë¡œ ë” ë§ì€ í•™êµ ì»¤ë²„\")\n",
        "    print(\"âœ… AttributeError ìˆ˜ì • ì™„ë£Œ\")\n",
        "\n",
        "    # print(\"\\nğŸš€ **ì¦‰ì‹œ ì‹¤í–‰ (ë°ëª¨):**\")\n",
        "    # quick_timeline_demo()\n",
        "\n",
        "\n",
        "    # ìˆ˜ì •ëœ í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ ë¶„ì„\n",
        "    run_real_data_timeline_analysis(comprehensive_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Jn_lLbMDVr",
        "outputId": "fb093c7b-16ed-485d-a8de-e6d17ed335ee"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š **í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ ê¸°ë°˜ ì‹œê°„ë³„ ì •ì±… íš¨ê³¼ ë¶„ì„**\n",
            "======================================================================\n",
            "\n",
            "ğŸ”¥ **ë°©ë²• 1: ê¸°ì¡´ ê²°ê³¼ í™œìš© (ê¶Œì¥)**\n",
            "1ï¸âƒ£ ë¨¼ì € ë©”ì¸ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰:\n",
            "   comprehensive_results = run_comprehensive_analysis_final(\n",
            "       'ìƒë°˜ê¸°.csv', 'í•˜ë°˜ê¸°.csv'\n",
            "   )\n",
            "\n",
            "2ï¸âƒ£ ê·¸ ê²°ê³¼ë¡œ í˜„ì‹¤ì  ì‹œê°„ë³„ ë¶„ì„:\n",
            "   run_real_data_timeline_analysis(comprehensive_results)\n",
            "\n",
            "ğŸ® **ë°©ë²• 2: ë°ëª¨ ì²´í—˜**\n",
            "   quick_timeline_demo()  # í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ ë°ëª¨\n",
            "\n",
            "ğŸ’¡ **ì£¼ìš” ê°œì„ ì‚¬í•­:**\n",
            "âœ… ì„œìš¸ì‹œêµìœ¡ì²­ ì‹¤ì œ ì˜ˆì‚° í•œë„ ì ìš© (5ë…„ê°„ 2000ì–µì›)\n",
            "âœ… ì •ì±…ë³„ ì‹¤ì œ ë¹„ìš© ì°¨ì´ ë°˜ì˜\n",
            "âœ… ì˜ˆì‚° ë¶€ì¡±ì‹œ ì¼ë¶€ í•™êµë§Œ ê°œì„ í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë°©ì¹˜\n",
            "âœ… ê±´ë¬¼ê°œì„  100% = 30ì–µì› í•„ìš” vs ì‹¤ì œ 20ì–µì› â†’ 13ê°œêµë§Œ ê°€ëŠ¥\n",
            "âœ… ìµœì ì •ì±… = ë‹¤ì–‘í•œ ì •ì±…ìœ¼ë¡œ ë” ë§ì€ í•™êµ ì»¤ë²„\n",
            "âœ… AttributeError ìˆ˜ì • ì™„ë£Œ\n",
            "ğŸš€ ì‹¤ì œ ì„œìš¸ì‹œ ë°ì´í„° + ì˜ˆì‚° ì œì•½ ê¸°ë°˜ ì‹œê°„ë³„ ì •ì±… íš¨ê³¼ ë¶„ì„\n",
            "================================================================================\n",
            "ğŸ“Š ì‹¤ì œ ë°ì´í„°ì—ì„œ ì˜ˆì‚°-ì„±ê³¼ ê´€ê³„ ì§ì ‘ ê³„ì‚°...\n",
            "   ì‹¤ì œ ì˜ˆì‚°ë¶„ìœ„ë³„ í™˜ê²½ìœ„í—˜ë„:\n",
            "   1ë¶„ìœ„: í™˜ê²½ìœ„í—˜ë„ 3.9, ì˜ˆì‚° 655,957,451ì›, ìœ„í—˜í•™êµ 9.9%\n",
            "   2ë¶„ìœ„: í™˜ê²½ìœ„í—˜ë„ 3.6, ì˜ˆì‚° 818,964,778ì›, ìœ„í—˜í•™êµ 8.4%\n",
            "   3ë¶„ìœ„: í™˜ê²½ìœ„í—˜ë„ 3.8, ì˜ˆì‚° 951,181,239ì›, ìœ„í—˜í•™êµ 8.9%\n",
            "   4ë¶„ìœ„: í™˜ê²½ìœ„í—˜ë„ 3.5, ì˜ˆì‚° 1,113,594,185ì›, ìœ„í—˜í•™êµ 5.8%\n",
            "   5ë¶„ìœ„: í™˜ê²½ìœ„í—˜ë„ 3.6, ì˜ˆì‚° 1,508,810,865ì›, ìœ„í—˜í•™êµ 4.7%\n",
            "   ğŸ“ˆ ì‹¤ì œ ë°ì´í„°: 1ì–µì› ì¶”ê°€íˆ¬ì ì‹œ í™˜ê²½ìœ„í—˜ë„ 0.03ì  ê°œì„ \n",
            "   ì‹¤ì œ ì•ˆì „ë“±ê¸‰ë³„ í˜„í™©:\n",
            "   Aê¸‰: 338.0ê°œêµ, í‰ê· ì˜ˆì‚° 1,024,728,007ì›, í™˜ê²½ìœ„í—˜ë„ 2.7\n",
            "   Bê¸‰: 458.0ê°œêµ, í‰ê· ì˜ˆì‚° 1,021,515,466ì›, í™˜ê²½ìœ„í—˜ë„ 3.8\n",
            "   Cê¸‰: 89.0ê°œêµ, í‰ê· ì˜ˆì‚° 958,693,404ì›, í™˜ê²½ìœ„í—˜ë„ 4.8\n",
            "   Dê¸‰: 66.0ê°œêµ, í‰ê· ì˜ˆì‚° 923,508,838ì›, í™˜ê²½ìœ„í—˜ë„ 5.7\n",
            "   Eê¸‰: 6.0ê°œêµ, í‰ê· ì˜ˆì‚° 990,408,222ì›, í™˜ê²½ìœ„í—˜ë„ 10.6\n",
            "   ğŸ’° Eê¸‰â†’Dê¸‰ ê°œì„  ì‹¤ì œ ì˜ˆì‚° ì°¨ì´: -66,899,384ì›\n",
            "   ğŸ’° Dê¸‰â†’Cê¸‰ ê°œì„  ì‹¤ì œ ì˜ˆì‚° ì°¨ì´: 35,184,566ì›\n",
            "ğŸŒ¡ï¸ ì‹¤ì œ í™˜ê²½ìœ„í—˜ë„ íŒ¨í„´ ì§ì ‘ ë¶„ì„...\n",
            "   ì‹¤ì œ ìœ„í—˜ë„ êµ¬ê°„ë³„ í˜„í™©:\n",
            "   ì €ìœ„í—˜: 957ê°œêµ, í‰ê· ì˜ˆì‚° 1,009,853,600ì›, íš¨ìœ¨ì„± 34.4, ì£¼ìš”ë“±ê¸‰ B\n",
            "   ì¤‘ìœ„í—˜: 0ê°œêµ, í‰ê· ì˜ˆì‚° nanì›, íš¨ìœ¨ì„± nan, ì£¼ìš”ë“±ê¸‰ C\n",
            "   ê³ ìœ„í—˜: 0ê°œêµ, í‰ê· ì˜ˆì‚° nanì›, íš¨ìœ¨ì„± nan, ì£¼ìš”ë“±ê¸‰ C\n",
            "   ë§¤ìš°ìœ„í—˜: 0ê°œêµ, í‰ê· ì˜ˆì‚° nanì›, íš¨ìœ¨ì„± nan, ì£¼ìš”ë“±ê¸‰ C\n",
            "   ì§€ì—­ë³„ ì‹¤ì œ ì„±ê³¼ (ìƒìœ„ 5ê°œ):\n",
            "   ë„ë´‰êµ¬: í™˜ê²½ìœ„í—˜ë„ 3.1, ì˜ˆì‚° 906,271,772ì›, ìœ„í—˜í•™êµ 0.0%\n",
            "   ë…¸ì›êµ¬: í™˜ê²½ìœ„í—˜ë„ 3.2, ì˜ˆì‚° 929,783,938ì›, ìœ„í—˜í•™êµ 0.0%\n",
            "   ì„±ë™êµ¬: í™˜ê²½ìœ„í—˜ë„ 3.3, ì˜ˆì‚° 925,738,757ì›, ìœ„í—˜í•™êµ 0.0%\n",
            "   êµ¬ë¡œêµ¬: í™˜ê²½ìœ„í—˜ë„ 3.3, ì˜ˆì‚° 1,032,557,478ì›, ìœ„í—˜í•™êµ 4.3%\n",
            "   ì¤‘ë‘êµ¬: í™˜ê²½ìœ„í—˜ë„ 3.4, ì˜ˆì‚° 1,007,771,846ì›, ìœ„í—˜í•™êµ 2.6%\n",
            "ğŸ’¸ ì‹¤ì œ ê°œì„  ë¹„ìš© ì§ì ‘ ê³„ì‚°...\n",
            "   ğŸš¨ ìœ„í—˜í•™êµ í˜„í™©: 72ê°œêµ\n",
            "   ğŸ’° ìœ„í—˜í•™êµ í‰ê· ì˜ˆì‚°: 929,083,787ì›\n",
            "   ğŸ’° ì•ˆì „í•™êµ í‰ê· ì˜ˆì‚°: 1,022,879,585ì›\n",
            "   ğŸ’¸ ê°œì„  í•„ìš” ì˜ˆì‚°: 93,795,798ì›\n",
            "   ğŸŒ¡ï¸ ìœ„í—˜ë„ ê²©ì°¨: 2.8ì \n",
            "   ğŸ“Š ì‹¤ì œ ë°ì´í„°: í™˜ê²½ìœ„í—˜ë„ 1ì  ê°œì„ ì— 33,409,728ì› í•„ìš”\n",
            "   ì˜ˆì‚° íš¨ìœ¨ì„±ë³„ ì‹¤ì œ ì„±ê³¼:\n",
            "   ì €íš¨ìœ¨: í™˜ê²½ìœ„í—˜ë„ 3.7, ì˜ˆì‚° 955,013,557ì›, ìš°ìˆ˜í•™êµ 82.0%\n",
            "   ì¤‘íš¨ìœ¨: í™˜ê²½ìœ„í—˜ë„ 3.6, ì˜ˆì‚° 1,329,884,424ì›, ìš°ìˆ˜í•™êµ 90.0%\n",
            "   ê³ íš¨ìœ¨: í™˜ê²½ìœ„í—˜ë„ nan, ì˜ˆì‚° nanì›, ìš°ìˆ˜í•™êµ nan%\n",
            "   ìµœê³ íš¨ìœ¨: í™˜ê²½ìœ„í—˜ë„ nan, ì˜ˆì‚° nanì›, ìš°ìˆ˜í•™êµ nan%\n",
            "ğŸ¯ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì •ì±…ë³„ íš¨ê³¼ ì‚°ì¶œ...\n",
            "   ê³µê¸°ì²­ì •ê¸°: ì—°ê°„ 0.7ì  ê°œì„ , ê°ì‡ ìœ¨ 0.10, ë§Œì¡±ë„ 6.0\n",
            "   ê±´ë¬¼ê°œì„ : ì—°ê°„ 3.6ì  ê°œì„ , ê°ì‡ ìœ¨ 0.02, ë§Œì¡±ë„ 2.0\n",
            "   ë…¹ì§€ì¡°ì„±: ì—°ê°„ 1.2ì  ê°œì„ , ê°ì‡ ìœ¨ -0.03, ë§Œì¡±ë„ 7.0\n",
            "   ìŠ¤ë§ˆíŠ¸ëª¨ë‹ˆí„°ë§: ì—°ê°„ 0.9ì  ê°œì„ , ê°ì‡ ìœ¨ 0.12, ë§Œì¡±ë„ 3.0\n",
            "   ë³µì§€ì§€ì›: ì—°ê°„ 0.1ì  ê°œì„ , ê°ì‡ ìœ¨ 0.05, ë§Œì¡±ë„ 9.0\n",
            "ğŸ’° í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½: 5ë…„ê°„ 200,000,000,000ì›\n",
            "ğŸ¯ ëŒ€ìƒ í•™êµ: ê¸´ê¸‰ 0ê°œ, ìš°ì„  2ê°œ\n",
            "âœ… ì‹¤ì œ ë°ì´í„° + ì˜ˆì‚° ì œì•½ ê¸°ë°˜ ì‹œë®¬ë ˆì´í„° ìƒì„± ì™„ë£Œ\n",
            "ğŸ† ìµœì ì •ì±… (ì‹¤ì œ ë°ì´í„° + ì˜ˆì‚° ì œì•½): ì˜ˆì‚° ëŒ€ë¹„ íš¨ê³¼ ìµœëŒ€í™” ì „ëµ (ë¹„ìš©íš¨ê³¼ë¹„ ë¶„ì„ ê¸°ë°˜) (ê³µê¸°ì§ˆê°œì„ +ì¹œí™˜ê²½ì¡°ì„±+ì§€ëŠ¥í˜•ê´€ë¦¬+êµìœ¡ë³µì§€ ì¤‘ì‹¬)\n",
            "ğŸ—‘ï¸ ìµœì•…ì •ì±… (ì‹¤ì œ ë°ì´í„° + ì˜ˆì‚° ì œì•½): ê±´ë¬¼ê°œì„  ë‹¨ì¼ ì§‘ì¤‘\n",
            "\n",
            "ğŸ’° ì˜ˆì‚° ì œì•½ íš¨ê³¼ ë¯¸ë¦¬ë³´ê¸°:\n",
            "   ìµœì•…ì •ì±… í•„ìš” ì˜ˆì‚°: 3,000,000,000ì›\n",
            "   ì‹¤ì œ ê°€ìš© ì˜ˆì‚°: 200,000,000,000ì›\n",
            "\n",
            "================================================================================\n",
            "ğŸ’° í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ í•˜ì—ì„œ ìµœì ì •ì±… vs ìµœì•…ì •ì±… ë¹„êµ\n",
            "================================================================================\n",
            "\n",
            "ğŸ† **ìµœì ì •ì±… ì ìš© ì‹œë‚˜ë¦¬ì˜¤ (ì˜ˆì‚° ì œì•½ ì ìš©)**\n",
            "ğŸ“Š ìµœì ì •ì±… ì •ì±… ì‹œê°„ ê²½ê³¼ ì‹œë®¬ë ˆì´ì…˜ (í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½)\n",
            "======================================================================\n",
            "\n",
            "ğŸ”® 1ë…„ í›„ (2024ë…„) ì˜ˆì¸¡ ì¤‘...\n",
            "\n",
            "ğŸ“Š 1ë…„ í›„ ìƒíƒœ ìš”ì•½:\n",
            "   ğŸŒ¡ï¸ í™˜ê²½ìœ„í—˜ë„: 4.1 (3.7 â†’ 4.1)\n",
            "   ğŸ¥ ìœ„í—˜í•™êµ(D/Eê¸‰): 51ê°œ (72ê°œ â†’ 51ê°œ)\n",
            "   ğŸ’° ëˆ„ì  íˆ¬ìì•¡: 2,300,000,000ì›\n",
            "   ğŸ”§ ì—°ê°„ ìœ ì§€ë¹„: 69,000,000ì›\n",
            "   ğŸ˜Š ì‚¬íšŒ ë§Œì¡±ë„: 65.0/100\n",
            "   ğŸ« ê°œì„  ì™„ë£Œ í•™êµ: 20ê°œ\n",
            "   ğŸ’¸ ì˜ˆì‚° ì—¬ìœ : 37,700,000,000ì›\n",
            "   ğŸ“ˆ ì˜ˆì‚° ì‚¬ìš©ë¥ : 5.8%\n",
            "\n",
            "ğŸ”® 5ë…„ í›„ (2028ë…„) ì˜ˆì¸¡ ì¤‘...\n",
            "\n",
            "ğŸ“Š 5ë…„ í›„ ìƒíƒœ ìš”ì•½:\n",
            "   ğŸŒ¡ï¸ í™˜ê²½ìœ„í—˜ë„: 6.1 (3.7 â†’ 6.1)\n",
            "   ğŸ¥ ìœ„í—˜í•™êµ(D/Eê¸‰): 51ê°œ (72ê°œ â†’ 51ê°œ)\n",
            "   ğŸ’° ëˆ„ì  íˆ¬ìì•¡: 2,300,000,000ì›\n",
            "   ğŸ”§ ì—°ê°„ ìœ ì§€ë¹„: 69,000,000ì›\n",
            "   ğŸ˜Š ì‚¬íšŒ ë§Œì¡±ë„: 65.0/100\n",
            "   ğŸ« ê°œì„  ì™„ë£Œ í•™êµ: 20ê°œ\n",
            "   ğŸ’¸ ì˜ˆì‚° ì—¬ìœ : 197,700,000,000ì›\n",
            "   ğŸ“ˆ ì˜ˆì‚° ì‚¬ìš©ë¥ : 1.1%\n",
            "   ğŸ“¢ ì£¼ìš” ì´ìŠˆ: ì˜ˆì‚° ì—¬ìœ ë¶„ìœ¼ë¡œ ì¶”ê°€ ì‚¬ì—… ê²€í†  ê°€ëŠ¥, ê¸°ì¡´ ì„¤ì¹˜ ì‹œì„¤ ìœ ì§€ë³´ìˆ˜ ë¹„ìš© ì¦ê°€, ì°¨ê¸° 5ê°œë…„ ê³„íš ìˆ˜ë¦½ í•„ìš”\n",
            "\n",
            "ğŸ—‘ï¸ **ìµœì•…ì •ì±… ì ìš© ì‹œë‚˜ë¦¬ì˜¤ (ì˜ˆì‚° ì œì•½ ì ìš©)**\n",
            "ğŸ“Š ìµœì•…ì •ì±… ì •ì±… ì‹œê°„ ê²½ê³¼ ì‹œë®¬ë ˆì´ì…˜ (í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½)\n",
            "======================================================================\n",
            "\n",
            "ğŸ”® 1ë…„ í›„ (2024ë…„) ì˜ˆì¸¡ ì¤‘...\n",
            "\n",
            "ğŸ“Š 1ë…„ í›„ ìƒíƒœ ìš”ì•½:\n",
            "   ğŸŒ¡ï¸ í™˜ê²½ìœ„í—˜ë„: 4.1 (3.7 â†’ 4.1)\n",
            "   ğŸ¥ ìœ„í—˜í•™êµ(D/Eê¸‰): 51ê°œ (72ê°œ â†’ 51ê°œ)\n",
            "   ğŸ’° ëˆ„ì  íˆ¬ìì•¡: 3,000,000,000ì›\n",
            "   ğŸ”§ ì—°ê°„ ìœ ì§€ë¹„: 90,000,000ì›\n",
            "   ğŸ˜Š ì‚¬íšŒ ë§Œì¡±ë„: 65.0/100\n",
            "   ğŸ« ê°œì„  ì™„ë£Œ í•™êµ: 20ê°œ\n",
            "   ğŸ’¸ ì˜ˆì‚° ì—¬ìœ : 37,000,000,000ì›\n",
            "   ğŸ“ˆ ì˜ˆì‚° ì‚¬ìš©ë¥ : 7.5%\n",
            "\n",
            "ğŸ”® 5ë…„ í›„ (2028ë…„) ì˜ˆì¸¡ ì¤‘...\n",
            "\n",
            "ğŸ“Š 5ë…„ í›„ ìƒíƒœ ìš”ì•½:\n",
            "   ğŸŒ¡ï¸ í™˜ê²½ìœ„í—˜ë„: 6.0 (3.7 â†’ 6.0)\n",
            "   ğŸ¥ ìœ„í—˜í•™êµ(D/Eê¸‰): 51ê°œ (72ê°œ â†’ 51ê°œ)\n",
            "   ğŸ’° ëˆ„ì  íˆ¬ìì•¡: 3,000,000,000ì›\n",
            "   ğŸ”§ ì—°ê°„ ìœ ì§€ë¹„: 90,000,000ì›\n",
            "   ğŸ˜Š ì‚¬íšŒ ë§Œì¡±ë„: 65.0/100\n",
            "   ğŸ« ê°œì„  ì™„ë£Œ í•™êµ: 20ê°œ\n",
            "   ğŸ’¸ ì˜ˆì‚° ì—¬ìœ : 197,000,000,000ì›\n",
            "   ğŸ“ˆ ì˜ˆì‚° ì‚¬ìš©ë¥ : 1.5%\n",
            "   ğŸ“¢ ì£¼ìš” ì´ìŠˆ: ì˜ˆì‚° ì—¬ìœ ë¶„ìœ¼ë¡œ ì¶”ê°€ ì‚¬ì—… ê²€í†  ê°€ëŠ¥, ê¸°ì¡´ ì„¤ì¹˜ ì‹œì„¤ ìœ ì§€ë³´ìˆ˜ ë¹„ìš© ì¦ê°€, ì°¨ê¸° 5ê°œë…„ ê³„íš ìˆ˜ë¦½ í•„ìš”\n",
            "\n",
            "================================================================================\n",
            "ğŸ“Š **í˜„ì‹¤ì  ì˜ˆì‚° ì œì•½ í•˜ì—ì„œ ë¹„êµ ë¶„ì„ ê²°ê³¼**\n",
            "================================================================================\n",
            "\n",
            "ğŸ“… **1ë…„ í›„ (2024ë…„) í˜„ì‹¤ì  ë¹„êµ:**\n",
            "í•­ëª©                   ìµœì ì •ì±…            ìµœì•…ì •ì±…            ì°¨ì´             \n",
            "----------------------------------------------------------------------\n",
            "í™˜ê²½ìœ„í—˜ë„                4.1             4.1             -0.0           \n",
            "ê°œì„ ì™„ë£Œí•™êµ               20              20              0              \n",
            "ë°©ì¹˜í•™êµ                 0               0               0              \n",
            "ì‚¬íšŒë§Œì¡±ë„                65.0            65.0            0.0            \n",
            "ëˆ„ì íˆ¬ì(ì–µì›)             2               3               -1             \n",
            "ìœ ì§€ë¹„(ì–µì›)              0.1             0.1             -0.0           \n",
            "\n",
            "ğŸ“… **5ë…„ í›„ (2028ë…„) í˜„ì‹¤ì  ë¹„êµ:**\n",
            "í•­ëª©                   ìµœì ì •ì±…            ìµœì•…ì •ì±…            ì°¨ì´             \n",
            "----------------------------------------------------------------------\n",
            "í™˜ê²½ìœ„í—˜ë„                6.1             6.0             0.1            \n",
            "ê°œì„ ì™„ë£Œí•™êµ               20              20              0              \n",
            "ë°©ì¹˜í•™êµ                 0               0               0              \n",
            "ì‚¬íšŒë§Œì¡±ë„                65.0            65.0            0.0            \n",
            "ëˆ„ì íˆ¬ì(ì–µì›)             2               3               -1             \n",
            "ìœ ì§€ë¹„(ì–µì›)              0.1             0.1             -0.0           \n",
            "\n",
            "ğŸ” **í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (5ë…„ ê¸°ì¤€):**\n",
            "\n",
            "ğŸ’° **ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„:**\n",
            "   ìµœì ì •ì±…: í•™êµë‹¹ 115,000,000ì›\n",
            "   ìµœì•…ì •ì±…: í•™êµë‹¹ 150,000,000ì›\n",
            "   íš¨ìœ¨ì„± ì°¨ì´: ìµœì•…ì •ì±…ì´ 1.3ë°° ë” ë¹„ìŒˆ\n",
            "\n",
            "ğŸ˜Š **ì‚¬íšŒì  ì˜í–¥:**\n",
            "   ë§Œì¡±ë„ ì°¨ì´: +0.0ì \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLF51SSms1cO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}